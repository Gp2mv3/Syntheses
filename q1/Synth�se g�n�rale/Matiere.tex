\documentclass{report}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[francais]{babel}
\usepackage{xcolor}
\usepackage{array}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancybox}
\usepackage{float}
\usepackage{colortbl}
\usepackage{makecell}
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{qtree}
%\usepackage[top=2.5cm, bottom=2.5cm, left=3cm, right=3cm]{geometry}
\setcounter{tocdepth}{1}
\pagestyle{headings}
\makeatletter
\renewcommand\chapter{\par%
  \thispagestyle{plain}%
  \global\@topnum\z@
  \@afterindentfalse
  \secdef\@chapter\@schapter}
\makeatother
\titleformat{\chapter}{%
\centering\normalfont\huge\bfseries}{\thechapter}{1em}{}
\titlespacing*{\chapter} {0pt}{3.5ex plus 1ex minus .2ex}{2.3ex plus .2ex}
\makeatletter
\def\thickhrulefill{\leavevmode \leaders \hrule height 1pt\hfill \kern \z@}
\renewcommand{\maketitle}{\begin{titlepage}%
    \let\footnotesize\small
    \let\footnoterule\relax
    \parindent \z@
    \reset@font
    \null
    \vskip 10\p@
    \hbox{\mbox{
        \hspace{4pt}
        \fbox{\includegraphics[width=15em]{epl-logo.jpg}}
        \hspace{4pt}
        }
      \vrule depth 0.9\textheight
      \mbox{\hspace{2em}}
      \vtop{
       
        
        \vskip 80\p@
        \begin{flushleft}
          \huge \bfseries \@title \par
        \end{flushleft}
        \vskip 100\p@
        \begin{flushleft}
        \Large \@author \par
         
        \end{flushleft}
         \vskip 200\p@
        \begin{center}
       
          \small \bfseries \@date \par
        \end{center}
        \vfil
        }}
  \end{titlepage}
  \setcounter{footnote}{0}
}
\author{Guillaume \bsc{françois} }
\title{{\color{blue}Session de Janvier}\\FSAB11}
\date{\today}
\begin{document}

\renewcommand{\labelitemi}{$\qquad \star$}
\maketitle
\tableofcontents
\part{\color{darkgray}Organisation}
\section{\color{darkgray}Matière}
\begin{tabular}{l|cc}
\textbf{{\Large Matière}}&\textbf{{\Large Théorie}}&\textbf{{\Large Exercices}}\\
\hline\\
\underline{\textbf{\texttt{Mathématiques}}}\\
\textbf{\emph{{\color{violet}Analyse}}}\\
\ Fondements&\ 1.$\textcircled{}$&\ 2.$\textcircled{}$\\
\ Limite et continuité&\ 3.$\textcircled{}$&\ 4.$\textcircled{}$\\
\ Polynôme de Taylor&\ 5.$\textcircled{}$&\ 6.$\textcircled{}$\\
\ Intégration&\ 7.$\textcircled{}$&\ 8.$\textcircled{}$\\
\ Suites et séries&\ 9.$\textcircled{}$&10.$\textcircled{}$\\
\ Equations différentielles&11.$\textcircled{}$&12.$\textcircled{}$\\
\textbf{\emph{{\color{cyan}Algèbre}}}\\
\ Espaces vectoriels&13.$\textcircled{}$&14.$\textcircled{}$\\
\ Systèmes linéaires&15.$\textcircled{}$&16.$\textcircled{}$\\
\ Calcul matriciel&17.$\textcircled{}$&18.$\textcircled{}$\\
\ Applications linéaires&19.$\textcircled{}$&20.$\textcircled{}$\\
\textbf{\emph{{\color{blue}Maths discrètes}}}\\
\ Ensembles&21.$\textcircled{}$&22.$\textcircled{}$\\
\ Dénombrement&23.$\textcircled{}$&24.$\textcircled{}$\\
\ Equations de réccurence&25.$\textcircled{}$&26.$\textcircled{}$\\
\ Graphes&27.$\textcircled{}$&28.$\textcircled{}$\\
\\
\underline{\textbf{\texttt{Physique}}}\\
\textbf{\emph{{\color{orange}Mécanique}}}\\
\ Formules&29.$\textcircled{}$&30.$\textcircled{}$\\
\ Lois de Newton&31.$\textcircled{}$&32.$\textcircled{}$\\
\ Conditions d'équilibre&33.$\textcircled{}$&34.$\textcircled{}$\\
\ Mouvements&35.$\textcircled{}$&36.$\textcircled{}$\\
\ Résistance d'un fluide&37.$\textcircled{}$&38.$\textcircled{}$\\
\ Energie potentielle et cinétique&39.$\textcircled{}$&40.$\textcircled{}$\\
\ Momentum, impulsion \& collisions&41.$\textcircled{}$&42.$\textcircled{}$\\
\textbf{\emph{{\color{purple}Electricité}}}\\
\ Electrostatique&43.$\textcircled{}$&44.$\textcircled{}$\\
\ Courant continu&45.$\textcircled{}$&46.$\textcircled{}$\\
\ Courant alternatif&47.$\textcircled{}$&48.$\textcircled{}$\\
\\

\underline{\textbf{\texttt{Infomatique}}}\\
\textbf{\emph{{\color{brown}Révisions}}}\\
\ Exceptions&49.$\textcircled{}$&50.$\textcircled{}$\\
\ Flux&51.$\textcircled{}$&52.$\textcircled{}$\\
\\
\end{tabular}
\newpage
\section{\color{darkgray}Calendrier}
Semaine 1:\\
\begin{center}
\begin{tabular}{p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}}
\rowcolor{lightgray}&\textbf{\texttt{Lundi (19/12)}}&\textbf{\texttt{Mardi (20/12)}}&\textbf{\texttt{Mercredi (21/12)}}&\textbf{\texttt{jeudi (22/12)}}&\textbf{\texttt{Vendredi (23/12)}}\\
\hline
&&&&&\\
\textbf{{\Large A.M.}}&&&&&{\color{cyan}\shadowbox{17}}\\
\hline
&&&&&\\
\textbf{{\Large P.M.}}&&&&{\color{cyan}\shadowbox{13}} {\color{cyan}\shadowbox{15}}&{\color{cyan}\shadowbox{19}} {\color{violet}\shadowbox{11}}\\
\end{tabular}
\end{center}
\begin{center}
\begin{tabular}{p{2cm}|p{2cm}|p{2cm}}
\rowcolor{lightgray}&\textbf{\texttt{Samedi (24/12)}}&\textbf{\texttt{Dimanche (25/12)}}\\
\hline
&&\\
\textbf{{\Large A.M.}}&{\color{violet}\shadowbox{1}}{\color{violet}\shadowbox{3}}{\color{violet}\shadowbox{5}}&{\color{darkgray}\shadowbox{54}}{\color{darkgray}\shadowbox{58}}\\
\hline
&\textsc{\textbf{noël}}&\\
\textbf{{\Large P.M.}}&{\color{violet}\shadowbox{7}}{\color{violet}\shadowbox{9}}&{\color{darkgray}\shadowbox{55}}{\color{darkgray}\shadowbox{56}}{\color{darkgray}\shadowbox{57}}\\
\end{tabular}
\end{center}
Semaine 2\\
\begin{center}
\begin{tabular}{p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}}
\rowcolor{lightgray}&\textbf{\texttt{Lundi (26/12)}}&\textbf{\texttt{Mardi (27/12)}}&\textbf{\texttt{Mercredi (28/12)}}&\textbf{\texttt{jeudi (29/12)}}&\textbf{\texttt{Vendredi (30/12)}}\\
\hline
&&&&&\\
\textbf{{\Large A.M.}}&{\color{blue}\shadowbox{21}}&{\color{blue}\shadowbox{25}}&{\color{orange}\shadowbox{29}}{\color{orange}\shadowbox{31}}{\color{orange}\shadowbox{33}}&{\color{orange}\shadowbox{39}}{\color{orange}\shadowbox{41}}&\\
\hline
&&&&&\\
\textbf{{\Large P.M.}}&{\color{blue}\shadowbox{23}}&{\color{blue}\shadowbox{27}}&{\color{orange}\shadowbox{35}}{\color{orange}\shadowbox{37}}&{\color{purple}\shadowbox{43}}{\color{purple}\shadowbox{45}}{\color{purple}\shadowbox{47}}&\\
\end{tabular}
\end{center}
\begin{center}
\begin{tabular}{p{2cm}|p{2cm}|p{2cm}}
\rowcolor{lightgray}&\textbf{\texttt{Samedi (31/12)}}&\textbf{\texttt{Dimanche (1/01)}}\\
\hline
&&\\
\textbf{{\Large A.M.}}&&\\
\hline
&&\\
\textbf{{\Large P.M.}}&\textsc{\textbf{new year}}&\\
\end{tabular}
\end{center}
\newpage
Semaine 3:\\
\begin{center}
\begin{tabular}{p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}}
\rowcolor{lightgray}&\textbf{\texttt{Lundi (2/01)}}&\textbf{\texttt{Mardi (3/01)}}&\textbf{\texttt{Mercredi (4/01)}}&\textbf{\texttt{jeudi (5/01)}}&\textbf{\texttt{Vendredi (6/01)}}\\
\hline
&&&&&\\
\textbf{{\Large A.M.}}&&&&&\\
\hline
&&&&&\\
\textbf{{\Large P.M.}}&&&&&\\
\end{tabular}
\end{center}
\begin{center}
\begin{tabular}{p{2cm}|p{2cm}|p{2cm}}
\rowcolor{lightgray}&\textbf{\texttt{Samedi (7/01)}}&\textbf{\texttt{Dimanche (8/01)}}\\
\hline
&&\\
\textbf{{\Large A.M.}}&&\\
\hline
&&\\
\textbf{{\Large P.M.}}\\
\end{tabular}
\end{center}
Semaine 4:\\
\begin{center}
\begin{tabular}{p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}}
\rowcolor{lightgray}&\textbf{\texttt{Lundi (9/01)}}&\textbf{\texttt{Mardi (10/01)}}&\textbf{\texttt{Mercredi (11/01)}}&\textbf{\texttt{jeudi (12/01)}}&\textbf{\texttt{Vendredi (13/01)}}\\
\hline
&&&&&\\
\textbf{{\Large A.M.}}&&&&&\\
\hline
&&&&&\\
\textbf{{\Large P.M.}}&\textsc{\textbf{\underline{physique} (14h-18h)}}&&&\textsc{\textbf{\ \underline{info}\ (14h-18h)}}&\\
\end{tabular}
\end{center}
\begin{center}
\begin{tabular}{p{2cm}|p{2cm}|p{2cm}}
\rowcolor{lightgray}&\textbf{\texttt{Samedi (14/01)}}&\textbf{\texttt{Dimanche (15/01)}}\\
\hline
&&\\
\textbf{{\Large A.M.}}&&\\
\hline
&&\\
\textbf{{\Large P.M.}}\\
\end{tabular}
\end{center}
Semaine 5:\\
\begin{center}
\begin{tabular}{p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}}
\rowcolor{lightgray}&\textbf{\texttt{Lundi (16/01)}}&\textbf{\texttt{Mardi (17/01)}}&\textbf{\texttt{Mercredi (18/01)}}&\textbf{\texttt{jeudi (19/01)}}&\textbf{\texttt{Vendredi (20/01)}}\\
\hline
&&&&&\\
\textbf{\Large A.M.}&&\textsc{\textbf{\underline{maths} (8h30-12h30)}}&&&\\
\hline
&&&&&\\
\textbf{{\Large P.M.}}&&&&&\textsc{\textbf{ vacances}}\\
\end{tabular}
\end{center}

\part{\color{violet}Analyse}
\chapter{\color{violet}Fondements}
\section{Démonstrations}
\begin{itemize}
\item Implication
\item Contraposition
\item Equivalence
\item Contradiction (absurde)
\item Récurrence (induction)
\end{itemize}
\section{Relations}
\begin{itemize}
\item Réflexive ($xRx$)
\item Symétrique ($xRy \Rightarrow yRx$)
\item Transitive ($ xRy\ et\ yRz \Rightarrow xRz$)
\item Antisymétrique ($si\ xRy\ et\ yRx \Rightarrow x = y$)
\end{itemize}
\ \\
\begin{itemize}
\item Equivalence $\Rightarrow$ Symétrique, réflexive, transitive
\item Ordre partiel $\Rightarrow$ Antisymétrique, réflexive, transitive
\item Orde total $\Rightarrow$ $\forall x, y \in A \text{on a }xRy\text{ OU }yRx$
\end{itemize}
\chapter{\color{violet}Limite et continuité}
\section{Limite $L$ au point $x_0$}
\[ \forall \varepsilon > 0, \exists \delta > 0 \text{ tel que } \forall x \in A\text{, si }|x - x_0| \leq \delta \text{ alors } |f(x) - L| \leq \varepsilon.\]
\section{Continuité au point $x_0$}
\[ \forall \varepsilon > 0, \exists \delta > 0 \text{ tel que } \forall x \in A\text{, si }|x - x_0| \leq \delta \text{ alors } |f(x) - f(x_0)| \leq \varepsilon.\]
\section{Dérivabilité au point $x_0$}
\[f : A \rightarrow \mathbb{R} \text{ est dérivable si }\lim_{\substack{x \rightarrow x_0}} \frac{f(x) - f(a)}{x - a} \text{ existe.}\]

\section{Théorème des valeurs intermédiaires}
Soit $f : [a,b] \rightarrow \mathbb{R}$ continue.\\
Si $f(a) \leq y \leq f(b)$ ou $f(b) \leq y \leq f(a)\text{ alors }\exists c \in [a,b] \text{ tel que } y = f(c)$.

\section{Théorème des bornes atteintes}
Une fonction continue sur un intervalle fermé, bornée atteint ses bornes. C'est à dire qu'il existe $q, p \in [a,b] \text{ tel que } \\
f(q) = supremum\ f\text{ sur } [a,b]\\
\text{ et que } f(p) = infimum\ f \text{ sur } [a,b].$
\section{Théorème de Rolle}
Soit $f$ continue sur $ [a,b] \rightarrow \mathbb{R}$ et dérivable sur $]a,b[$.\\
Si $f(a) = f(b)$ alors il existe un $c \in ]a,b[$ tel que $f'(c) = 0$.

\section{Théorème des accroissements finis}
Soit $f$ continue sur $ [a,b] \rightarrow \mathbb{R}$ et dérivable sur $]a,b[$.\\
Alors il existe un $c \in ]a,b[$ tel que $f'(c) = \frac{f(b) - f(a)}{b - a}$.

\section{Théorème de la valeur constante}
Soit $f$ continue sur $ [a,b] \rightarrow \mathbb{R}$.\\
Si $f$ est dérivable sur $]a,b[$ et que $f'(c) = 0 \forall x \in ]a,b[$. alors $f$ est constante.

\chapter{\color{violet}Polynôme de Taylor}
\section{Définition}
Etant donné une fonction $f : A \rightarrow \mathbb{R}$, un naturel $n \geq 1$ et un point $a$ appartenant à \emph{l' intérieur} de $A$ en lequel $f$ est $n$ fois dérivable, le polynôme de Taylor d'ordre $n$ de $f$ autour du point $a$ est:
\[T_n^{f.a}(x) = \sum_{k = 0}^n \frac{f^{(k)}(a)}{k!}(x - a)^k\]

\section{Théorème de Taylor}
Soit une fonction $f : A \rightarrow \mathbb{R}$, un point $a$ appartenant à \emph{l' intérieur} de $A$, et un naturel $n \geq 1$.\\
Si $f$ est $n$ fois dérivable en $a$, alors:
\[\lim_{\substack{x \rightarrow a}} \frac{f(x) - T_n^{f.a}(x)}{(x - a)^n} = 0\]

\section{Réciproque de Taylor}
Soit une fonction $f : A \rightarrow \mathbb{R}$, un point $a$ appartenant à \emph{l' intérieur} de $A$, et un naturel $n \geq 1$.\\
Si $f$ est $n$ fois dérivable en $a$, et si \\
$P_n(x)$ est un polynôme de degré inférieur où égal à $n$, vérifiant: \[\lim_{\substack{x \rightarrow a}} \frac{f(x) - P_n(x)}{(x - a)^n} = 0\]
 alors \[P_n(x) = T_n^{f.a}(x)\]
\section{Théorème du reste}
Soit une fonction $f : A \rightarrow \mathbb{R}$, un point appartenant à \emph{l' intérieur} de $A$, un intervalle ouvert $I$ tel que $a \in I$ et $I\subset A$ et un naturel $n \geq 1$.\\
Si $f$ est $n + 1$ fois dérivable sur $I$, alors pour $\forall x \in I \backslash \{a\}$, il existe un point $c$ compris strictement entre $a$ et $x$ tel que:
\[f(x) = T_n^{f.a}(x) + \frac{f^{n+1}(c)(x - a)^{n+1}}{(n + 1)!}\]
\section{Dérivée de Taylor}
\[T_n^{f.a}'(x) = \frac{f^{n+1}(a)(x - a)^{n}}{n!}\]

\chapter{\color{violet}Intégration}
\section{implications}
\begin{itemize}
\item Si $f$ est intégrable alors $f$ est bornée.
\item Si $f$ est continue alors elle est intégrable.
\end{itemize}

\section{Théorème de la moyenne}
Soit une fonction continue donc intégrable de ${a,b] \rightarrow \mathbb{R}$.
Alors $\exists c \in [a,b]$ tel que $f(c) = \mu{(f)}$ c'est-à-dire:
\[\int_a^b f(x) dx = (b - a)f(c)\]
\section{Théorème fondamental (1)}
Soit une fonction continue sur$[a,b] \rightarrow \mathbb{R}$ et $p \in [a,b]$,\\
alors la fonction $F : [a,b] \rightarrow \mathbb{R} : x \rightarrow F(x)$\\
telle que
\[F(x) = \int_p^x f(t) dt\] 
est une primitive de $f$.

\section{Théorème fondamental (2)}
Soit $f$ continue $f : I \rightarrow \mathbb{R}$\\
Si $F$ est une primitive de $f$ sur $I$, alors
\[\int_p^q f(t) dt = F(q) - F(p) \qquad{\qquad}\text{ avec } p,q \in I\]

\section{Corollaire du théorème fondamental}
Soient $I$ et $J$, 2 interalles, $f$ une fonction continue de $I \rightarrow \mathbb{R}$ et 2 fonctions $U : J \rightarrow \mathbb{R}$ et $V : J \rightarrow \mathbb{R}$ dérivables,  telles que $U(J) \subset I$ et $V(J) \subset I$.\\
La fonction $H : J \rightarrow \mathbb{R} : x \rightarrow H(x) = \int_{U(x)}^{V(x) f(t) dt$ est dérivable et sa dérivée est donnée par:
\[H'(x) = f(V(x)).V'(x) - f(U(x)).U'(x)\]

\chapter{\color{violet}Suites et séries}
\section{Convergence d'une série}
On dit que la série $\sum a_n$ converge vers la somme $S$ lorsque \[\sum_{n =0}^{\infty} a_n = S\]
Une série numérique est convergente si et seulement si la suite des sommes partielles est
convergente.
\section{Convergence absolue}
La série $\sum a_n$ est absolument convergente lorsque $\sum |a_n|$ converge.

\section{Suites géométriques}
\[\sum_{n = 1}^{\infty} ar^{n-1}\]
Où $r$ est appelée la \emph{raison} de la série.\\
Si $a =0$,\\
 $\star$ La série converge vers 0.\\\\
Sinon,
\begin{itemize}
\item Si $|r| < 1 \rightarrow$ La série converge vers $\frac{a}{1 - r}$.
\item Si $r \geq 1 \rightarrow$ La série converge vers $\pm \infty$ en fonction du signe de $a$.
\item Si $r \leq 1 \rightarrow$ La série diverge.
\end{itemize}
\[S_n = a\frac{(1 - r^n)}{1- r}\]
\section{Séries téléscopantes}
Une série est dite  \emph{téléscopante} lorsque ses sommes partielles se simplifient entre elles.\\
On peut donc exprimer la série $\sum a_n$ comme $\sum b_n ? b_{n+1}$.\\
Exemple à retenir:
\[\sum_{n = 1}^{\infty} \frac{1}{n(n + 1)} = \sum_{n =1}^{\infty} \frac{1}{n} - \frac{1}{n + 1}\]
\section{Série harmonique}
\[\sum_{n = 1}^{\infty} \frac{1}{n}\]
\begin{itemize}
\item La série harmonique diverge.
\end{itemize}

\section{P-séries}
\[\sum_{n = 1}^{\infty} \frac{1}{n^p}\]
\begin{itemize}
\item La série converge pour $p$ > 1.
\item La série diverge pour $p$ < 1.
\end{itemize}

\section{Séries entières (Power series)}
\[\sum_{n =0}^{\infty}  a_n(x - c)^n\]
\begin{itemize}
\item $a_n$ est une suite de réels appelés coefficients de la série entière.
\item $c$ est un réel appelé centre de convergence de la série.
\end{itemize}
L' ensemble des valeurs de $x$ pour lesquelles la série converge est un intervalle centré en $ x = c$ appelé intervalle de convergence,
 et est égal à $] c - R, c+ R[ $, avec:
\[\frac{1}{R} = \lim_{n \to \infty} \left| \frac{a_n + 1}{a_n} \right| = \lim_{n \to \infty} \sqrt[n]{|a_n|}\]
\section{Test de divergence}
$\qquad \star$ si $\lim_{n \to \infty}a_n \neq 0$ où n'existe pas, alors la série $\sum_{n = 1}^{\infty}a_n$  diverge.
\section{Test de l'intégrale}
Soit $(a_n)$ une suite à termes positifs.
On suppose que $(a_n) = f(n)$, où $f$ est une fonction continue, positive, décroissante $\forall x > N_0$.\\
Alors la série $\sum_{n =N_0}^{\infty} a_n$ et $\int_{N_0}^{\infty} f(x) dx$ converge ou diverge en même temps.

\section{Test de comparaison}
Si il existe une série convergente $\sum_{n =N_0}^{\infty} b_n$, un $n_0 \in \mathbb{N}$ et un $c > 0$ tel que :\\
$\forall b_n \geq 0$ et $a_n \leq c.b_n$.\\
Alors la série $\sum a_n$ converge aussi.

\section{Test du quotient}
Calculer si elle existe,
\[\lim_{n \to \infty} \frac{|a_{(n+1)}|}{|a_n|} = C\]
\begin{itemize}
\item Si $C > 1$, la série diverge.
\item Si $C < 1$, la série converge.
\end{itemize}
\section{Test de la racine}
Calculer si elle existe,
\[\lim_{n \to \infty} \sqrt[n]{|a_n|} = D\]
\begin{itemize}
\item Si $D > 1$, la série diverge.
\item Si $D < 1$, la série converge.
\end{itemize}



\chapter{\color{violet}Equations différentielles}
\section{Classification}
\Tree [.{Equations différentielles}
			[.{Ordre > 1} {\color{violet}...} ]  
		  [.{Ordre 1}  
		  	[.Linéaire 
				[.Homogène {\color{violet}$y' + a(x)y = 0$} ]
				[.Non-homogène {\color{violet}$y' + a(x)y = b(x)$} ] ]
		  	[.Non-linéaire 
				[.{Variables séparables} {\color{violet}$y' = a(x)b(y)$} ] 
				[.{Variables non-séparables} {\color{violet}...} ]  ]   ] ]
		  
	

\section{Définition}
Une équation différentielle est une équation qui a pour inconnue une \emph{fonction} dont une ou plusieurs \emph{dérivées} apparaissent dans l'équation.
\section[Linéaire homogène de premier ordre]{Equation différentielle linéaire homogène de premier ordre}
\begin{eqnarray*}
y' +a(x)y &=& 0\\
\frac{1}{y}\frac{dy}{dx} &=& -a(x)\\
\int{ \frac{1}{y} dy}&=& - \int{a(x) dx}\\
\ln{|y|} &=& - \int_k^x{a(x) dx} + C\\
y(x) &=& -ke^{-\int{a(x) dx}}
\end{eqnarray*}
Avec $k$ une valeur réelle.
\section[Linéaire non-homogène de premier ordre]{Equation différentielle linéaire non-homogène de premier ordre}
\subsection{Première méthode}
La solution générale de ce genre d' équation est égale à la somme de la solution générale de l'équation homogène associée ($y_h$) et d'une solution particulière de l'équation non-homogène ($y_p$).
\[y = y_h + y_p\]
\begin{center}
\begin{tabular}{p{6cm}|p{6cm}}
\textbf{Forme de $b(x)$}&\textbf{Forme de $y_p$}\\
\hline\\
Polynôme de degré $n$&Polynôme de degré $n$ si $a(x) \neq 0 \qquad$ Polynôme de degré $n+1$ si $a(x) = 0$
&\\
$k_1\cos{\theta}x + k_2\sin{\theta}x$&$l_1\cos{\theta}x + l_2\cos{\theta}x$\\
&\\
$e^{\lambda{x}}P(x)$&$e^{\lambda{x}}Q(x)$\\
$P(x)$ un polynôme de degré $n$ et $\lambda$ un réel ou un complexe.&$Q(x)$ un polynôme de degré $n$ ou $n + 1$\\
&\\
Constante, de même que $a(x)$&$B/A$
\end{tabular}
\end{center}
\subsection{Deuxième méthode}
Résoudre l'équation homogène associée.
\[y_h = ke^{-\int{a(x) dx}}\]
Supposer que si k est une fonction de $x$, $y_h$ est une solution de l'équation $y' +a(x)y =b(x)$.
\[(k(x)e^{-\int{a(x) dx}})' + a(x) ke^{-\int{a(x) dx}} = b(x)\]
L'expression se simplifie alors pour donner une expression de k(x).
\section[Non-linéaire de premier ordre à variables séparables]{Equation différentielle non-linéaire de premier ordre à variables séparables}
Se résous de la même manière que les équations différentielles linéaires homogènes de premier ordre.
\begin{eqnarray*}
y'&=& a(x)b(y)\\
\frac{dy}{dx} &=&a(x)b(y)\\
\int{ \frac{1}{b(y)} dy}&=&\int{a(x) dx}\\
\end{eqnarray*}
\section{Problème de Cauchy}
Le problème formé par l'équation différentielle et la condition initiale est appelée \emph{Problème de Cauchy}.\\
$$
\left\{
\begin{array}{r c l}
y'(x) &=& f(x,y)\\
y(x_0) &=& y_0
\end{array}
$$

\part{\color{cyan}Algèbre}
\chapter{\color{cyan}Espaces vectoriels}
\section{Définition}
E est un espace vectoriel sur K si: $\forall x,y \in{E} et \forall \alpha{},\beta{}\in{K}$
\begin{itemize}
\item $x + y = y + x$
\item $(\alpha + \beta)x = \alpha{x} + \beta{x}$
\item $\alpha{(x + y)} = \alpha{x} + \alpha{y}$
\item $x(\alpha{\beta}) = (x\alpha{})\beta{}$
\item $x.1 = x$
\end{itemize}
\section{Sous-espaces vectoriels}
La partie V de l'espace vectoriel E sur un corps K est un sous espace vectoriel si, elle est une partie non vide de E stable par combinaison linéaire.\\
\[\forall{x} \in V \qquad x = \alpha_1v_1 + \alpha_2v_2 + \cdots + \alpha_n, v_n\]
\section{Somme directe}
Tout vecteur x de $V_1 \oplus V_2 \oplus \cdots \oplus V_n$ s'écrit de manière unique comme une somme de vecteurs appartenant à $V_1, V_2, \cdots , V_n$.
\section{SEV engendré}
C' est le plus petit sous-espace vectoriel contenant $v_1, v_2, \cdots ,v_n$.
On le note: \[sev< v_1, v_2, \cdots , v_n >\]
\section{Libre, Génératrice, Base}
$(e_1, e_2, \cdots , e_n)$ est une
\begin{description}
\item[suite génératrice] de E si $sev<v_1, v_2, \cdots , v_n> = E$
\item[suite libre] si$\{\alpha_1e_1, \alpha_2e_2, \cdots , \alpha_ne_n\}\Rightarrow \{\alpha_1 = \alpha_2 = \cdots = \alpha_n = 0\}$
\item[base] de E si elle est à la fois libre et génératrice
\end{description}

Si $(e_1, e_2, \cdots , e_n)$ est une base de E, tout vecteur de E s'écrit de manière unique comme combinaison linéaire de cette suite.
\section{Changement de base}
\[f^{(x)} = P.e^{(x)}\]
La matrice de changement de base P est régulière ( possède une inverse).
\section{Dimension}
Toutes les bases d'un espace vectoriel finement engendré ont le même nombre d'éléments. Ce nombre est appelé \emph{dimension de l'espace vectoriel}.
\[dim(V + W) = dimV + dimW +dim(V \cap W)\]
\section{Rang d'une matrice}

$A \in K^{m\times{n}}$\\
\begin{itemize}
\item \emph{L}(A) = SEV des lignes $\subset K^n$\\
\item \emph{C}(A) = SEV des colonnes $\subset K^m$\\
\end{itemize}
Théorème:\\
\[dim\text{\emph{L}(A)} = \text{\emph{C}(A)} = \text{rang(A)}\]
Si A = BC alors:\\
\begin{itemize}
\item \emph{L}(A) $\subset$ \emph{L}(C)
\item \emph{C}(A) $\subset$ \emph{C}(B)
\end{itemize}
\section{Théorème de Rouché}
Ax = b admet une solution \emph{sis} rang(A) = rang(A | b).
\chapter{\color{cyan}Systèmes linéaires \& calcul matriciel}
\section{Linéarité}
$\forall x,y \in{E} \alpha, \beta \in{K} \text{Si} \quad Ax = b\quad \text{et} \quad Ay = c\quad \text{alors}$
\[ A(\alpha{x} + \beta{y}) = \alpha{b} + \beta{c}\]
\section{Opérations élémentaires}
\begin{description}
\item[Type I] $L_i \rightarrow L_i + \lambda{L_j}$
\item[Type II] $L_i \leftrightarrow L_j$
\item[Type II] $L_i \rightarrow \lambda{L_i} \qquad{(a \neq 0)}$
\end{description}
\section{Opérations par blocs}
\[
\begin{pmatrix}
   a_11 & a_12 &| a_13 \\
   \hline
   a_21 & a_22 &| a_23 \\
   a_31 & a_32 &| a_33 
\end{pmatrix} = \begin{pmatrix}
   A&B \\
  C&D
\end{pmatrix}
\]
Attention à ce que les blocs soient compatibles lors d'opérations.
\section{Transposée}
\[(a_ij)^t = (a_ji)\]
\section{Inverse}
Soit $A\in k^{m\times n}$:\\
Inverse à gauche: $B.A = I \Leftrightarrow rang A  = n$\\
Inverse à droite: $A.C = I \Leftrightarrow rang A  = m$\\
Une matrice est inversible, régulière, non-singulière si elle possède un inverse à gauche et une inverse à droite.
\[B.A = A.B = I\]
La matrice inverse est unique.
\[(A|I) \xrightarrow[élémentaires]{opérations} (I|A^{-1})\]
\subsection{Propriétés}
\begin{itemize}
\item $(AB)^{-1} = A^{-1}B^{-1}$
\item $(AB)^t = B^tA^t$
\item $(A^{-1})^t = (A^t)^{-1}$
\item $det(A^{-1}) = \frac{1}{det(A)}$
\item $det(A) \noq 0$
\item $rang(A) = n$
\end{itemize}
\section{Déterminant}
\begin{itemize}
\item Le déterminant d'une matrice est égal à celui de sa transposée.\\
\item Si une matrice est \emph{singulière} son déterminant est nul.\\
\item \[det(A) = \sum_{l = 1}^{n}(-1)^{l+k}a_{lk}det(A_{lk})\]
\end{itemize}
\section{Matrice des cofacteurs}
\[cof(A) = ((-1)^{i + j}det(A_{i,j})_{i,j}\]
\[A^{-1} = (det(A))^{-1} . (cof(A))^t\]
\chapter{\color{cyan}Applications linéaires}
\section{Notion d?application linéaire}
Soient E et F, des espaces vectoriels sur K
Une application $A : E \rightarrow F$ est dite linéaire si les conditions suivantes sont vérifiées:\\
\[\forall a,y \in E, \alpha ,\beta \in\mathbb{K} : A(\alpha{x} + \beta{y}) = \alpha{A(x)} + \beta{A(y)}\]
Une application linéaire bijective est appelées isomorphisme.
\section{Noyau et image}
Le noyau de l'application linéaire $A: E \rightarrow F$ est un $s.e.v.$ de E tel que:\\
\[KerA = \{x \in E| A(x) = \vec{0}\}\]
L'espace image de A est un $s.e.v.$ de F tel que:\\
\[ImA = \{y \in F | \exists x \in E, A(x) = y\}\]
\section{Propriétés (1)}
\begin{itemize}
\item L'ensemble des solutions pour l'équation linéaire de type $A(x) = b$ est égal à la somme d'une solution particulière et du noyau deA: \[u+KerA = \{u + v | v \in KerA\}\]
\item A est inversible à gauche si il existe $B : F \rightarrow E$ tel que:\[B\circ A = I_E\]
\item A est inversible à droite si il existe $B : F \rightarrow E$ tel que:\[A\circ B = I_F\]
\end{itemize}
\section{Propriétés (2)}
Soit $A : E \rightarrow F$.\\
\[dim KerA + dim ImA = dimE\]\\
\begin{center}
\begin{tabular}{|c c|}
\hline
&\\
A injective&A surjective\\
\[\Updownarrow\]&\[\Updownarrow\]\\
\[KerA = \{0\}\]&\[ImA = F\]\\
\[\Updownarrow\]&\[\Updownarrow\]\\
\[rang A = dim E\]&\[rang A = dim E - dim F\]\\
\[\Updownarrow\]&\[\Updownarrow\]\\
A inversible à gauche&A inversible à droite\\
&\\
\hline
\end{tabular}
\end{center}
\section{Représentation matricielle}
Une application linéaire $A : E \rightarrow F$ peut être représentée par une matrice $_f(A)_e$ dont chaque colonne est formée par l'image d'un vecteur de la base de E, exprimé dans la base de F.

\part{\color{blue}Maths discrètes}
\chapter{\color{blue}Ensembles}
\section{Définitions}
\begin{itemize}
\item \emph{Equipotence}: A et B sont équipotents, noté $A\approx B$, si il existe une bijection de A vers B.\\

\item \emph{Ensemble fini}: Si A \approx \{1, \cdots , n\}$ pour $n \in \mathbb{N}$.\\
$n$ est le \emh{cardinal} de A, noté $|A|$.\\

\item \emph{Ensemble infini}: A est infiniment dénombrable si $A \approx \mathbb{N}$.\\

\end{itemize}
\section{\emph{Power set}}
\subsection*{Définition:}
Pour tout ensemble non-vide A, l'ensemble $P(A)$ est \emph{équipotents} à l'ensemble $\{0, 1\}^{A}$ des fonctions de A vers $\{0, 1\}^{A}$.
\subsection*{Démonstration:}
A tout sous-ensemble B de A, on associe la fonction $f_B : A \rightarrow \{0, 1\}$ définie comme suit:
\[
\left \{
\begin{array}{r c l}
f_B(x) &=& 1 \qquad{\qquad} \text{si } x \in B\\
f_B(x) &=& 0 \qquad{\qquad} \text{si } x \in A\backslah B
\end{array}
\]
La fonction $f_B$ est appelée la fonction caractéristique de B comme sous-ensemble de A.
\section{Principe des tiroirs}
\subsection*{Informel:}
Si $m$ objets sont rangés dans $n$ tiroirs et si $m > n$, alors il y au moins un tiroir qui contient plus d'un objet.
\subsection*{Formel:}
Soient A et B, des ensembles finis non-vides tels que $|A| > |B|$. alors il n'existe pas de fonction injective de A dans B.
\section{Principe d'induction}
Conditions:
\begin{description}
\item[(1)] $P(n_0)$ est vrai;
\item[(2)] Avec $k \in \mathbb{N} , \forall k \geq n_0 \text{, si }P(k)$ est vrai, alors $P(k+1)$ est vrai;
\end{description}
Alors $P(n)$ est vrai pour tout naturel $n \geq n_0$.
\section{Principe d'inclusion et d'exclusion}
\subsection*{Formules:}
\begin{itemize}
\item $|A \cup B| = |A| + |B| - |A \cap B|$
\item $|A\backslash B| \geq |A| - |B|$
\item $|A \Delta B| = |A| + |B| - 2|A \cap B|$
\end{itemize}
\subsection*{Principe:}
Soit S un ensemble fini non-vide, et soient $S_1, S_2, \cdots ,S_N$ des sous-ensembles de S avec $n \geq 1$. On s'intéresse au nombre d'éléments de S qui n'appartiennent à aucun des $S_i$, c'est-à-dire au nombre:
\[\sigma =|S| - \left | \bigcup_{i = 1}^n S_i \right |\]
\subsection*{Généralisation:}
\begin{itemize}
\item $S_I = \bigcap_{i \in I} S_i$
\item $S_{\emptyset} = S$
\item $R_n = \{1, \cdots , n\}$
\end{itemize}
\[\sigma = \sum_{r = 0}^n\left ( (-1)^r \sum_{|I| = r}|S_I| |\right )\]

\section{Règle de la somme}
\[\text{Si }A \cap B = \emptyset \text{, alors }|A \cup B| = |A| + |B| \text{.}\]
\section{Règle du produit}
\[|A \times B| = |A||B|\]
\chapter{\color{blue}Dénombrement}
\section{Binôme de Newton}
\[(x + y)^n = \sum_{k = 0}^n \begin{pmatrix}  n  \\ k \end{pmatrix} x^ky^{n-k}\]
\section{Les fonctions}
Une fonction de A vers B est un triple $(A,B,R)$ tel que $\forall a \in A$ il existe un unique $b \in B : aRb$.\\

On note $B^{A} = \{f | f : A \rightarrow B\}$.\\

\begin{itemize}
\item Rangement des objets de A dans les tiroirs de B.\\
\item Mot de longueur |A| pris dans l'alphabet B.\\
\end{itemize}
Soient A et B finis, $|A| = n , |B| = k$, le nombre de fonctions de A vers B est:
\[k^n\]
\section{Injections}
Une fonction est injective si et seulement si le mot qui la représente ne contient pas deux fois la même lettre.\\

Soient A et B finis, $|A| = n , |B| = k$,
\[In(n \leftarrow k) = [n]_k\]
\section{Surjections}
Une fonction $A \rightarrow C$ est surjective si et seulement si le mot qui la représente contient au moins une fois fois chaque lettres de de C.\\

Si $|A| = n , |C| = k$,
\[Sur(n \rightarrow k) = \sum_{r = 0}^k (-1)^r\begin{pmatrix}  k  \\ r \end{pmatrix} (k - r)^n\]
On trouve ce résultat à l'aide du principe d'inclusion et d'exclusion.
\section{Bijections}
Une fonction bijective ou bijection, est une fonction à la fois injective et surjective.\\
Le nombre de bijections de A vers A est $n!$.
\section{Les dérangements}
Un dérangement sur A est une bijection $f$ sur A telle que:
\[\forall a \in A : f(a) \neq a\]
Le nombre de dérangements d'un n-ensembles est:
\[d_n = \sum_{r = 0}^{r= n} (-1)^r \frac{n!}{r!}\]
\section{Combinaisons}
\begin{center}
\begin{tabular}{p{4cm}|p{5cm}|p{5cm}}
&\textbf{Sans ordre}&\textbf{Avec ordre}\\
\hline
&&\\
\textbf{Sans répétitions}&$B(n,k) = \begin{pmatrix}  n  \\ k \end{pmatrix} = C^k_n$ \[\frac{n!}{k!(n - k)!}\]&$[n]^k = A^k_n$\[\frac{n!}{(n - k)!}\]\\
\hline
&&\\
\textbf{Avec répétions}&$B^*(n, k) \qquad |\bullet | \bullet \bullet |\quad |\bullet | \bullet \bullet |$&\[n^k\]\\
\end{tabular}
\end{center}
\section{Stirling}
Le nombre de \emph{k-partitions} d'un ensemble de cardinal $n$.
\[S(n, k) = \frac{1}{k!}Sur( n \rightarrow k)\]
Récurrence:
\[S(n, k) = S(n - 1, k - 1) + k . S(n - 1, k)\]
\section{Bell}
Le nombre total de \emph{partitions} d'un n-ensemble.
\[b_n = \sum_{i = 0}^{i = n}S(n, i)\]
Récurrence:
\[b_n = \sum_{i = 0}^{n - 1}\begin{pmatrix}  n - 1  \\ i \end{pmatrix}b_i\]
\section{Parallélisme}
\begin{center}
\begin{tabular}{p{7cm}|p{7cm}}
\textbf{Pascal-Ensembles}&\textbf{Stirling-Partitions}\\
\hline
&\\
\[B(n,k) = \frac{1}{k!}In(n \leftarrow k)\]&\[S(n,k) = \frac{1}{k!}Sur(n \rightarrow k)\]\\
\hline
&\\
\[B(n,k) = B(n - 1, k) +  B(n - 1, k - 1)\]&\[S(n, k) = S(n - 1, k - 1) + kS(n - 1, k)\]\\
\hline
&\\
\[\sum_{k = 0}^{k = n}\begin{pmatrix}  n \\ k \end{pmatrix} = 2^n\]&\[\sum_{k = 0}^{k = n}S(n,k) = b_n\]\\
\end{tabular}
\end{center}
\chapter{\color{blue}Equations de récurrence}
\section{Définition}
Soit $k$ un entier naturel. Une récurrence linéaire d'ordre $k$, à coefficients constants, en la suite \emph{inconnue} $(v_n)_{n = 0}^{\infty}$, est une équation de la forme:
\[a_0v_{n+k} + a_1v_{n+k-1} + \cdots + a_{k-1}v_{n+1} + a_kv_n = b_n \qquad \text{avec }n \in \mathbb{N}\]
\begin{itemize}
\item $(v_n)^{\infty}_{n = 0}$ est la suite \emph{inconnue}.\\
\item $a_0, \cdots , a_k$ sont des coefficients réels constants.\\
\item $(b_n)_{n = 0}^{\infty}$ est une suite de réels donnée.\\\\
\end{itemize}
\begin{itemize}
\item \emph{Homogène}: $\forall \in \mathbb{N} : b_n = 0$\\
\item \emph{Affine}: cas général\\
\end{itemize}
\section{Récurrences homogènes de degré 0 et 1}
\begin{itemize}
\item \emph{Degré 0}: $v_n = 0 \qquad \forall n$\\
\item \emph{Degré 1}: $v_n = v_0\left (\frac{-a_1}{a_0} \right )^n$\\
\end{itemize}
\section{Récurrences homogène de degré 2}
Equation générale:
\[v_{n+2} + a_1v_{n+1} + a_2v_n = 0\]
Equation caractéristique:
\[r^2 + a_1r + a_2 = 0\]
\section{Cas avec 2 racines réels distinctes}
Solution générale:
\[v_n = c_1r_1^n + c_2r_2^n\]
Conditions initiales:
\[c_1 + c_2 = v_0 \qquad{\qquad{\qquad{\qquad}}} c_1r_1 + c_2r_2 = v1\]
\section{Cas avec 2 racines très proches}
Si les racines sont très proches l'une de l'autre, $r_2 = r_1(1 + \delta )$, avec $|\delta | \ll 1$.\\
 La solution générale sera de la forme approchée:
\[
\begin{array}{r c l}
v_n &\approx &c_1r_1^n + c_2r_1^n(1 + n\delta)\\
&=&(c_1 + c_2)r_1^n + (c_2r_1\delta )nr_1^{n-1}\\
\end{array}
\]
\section{Cas avec 2 racines confondues}
Solution générale:
\[v_n = d_0r_1^n + d_1nr_1^{n-1}\]
Conditions initiales:
\[d_0 = v_0 \qquad{\qquad{\qquad{\qquad}}} d_0r_1 = d_1 = v_1\]
\section{Cas avec 2 racines complexes conjuguées}
Solution générale:
\[v_n = c_1\rho{^n}\cos{(n\theta)} + c_2\rho{^n}\sin{(n\theta)}\]
Conditions initiales:
\[c_1 = v_0 \qquad{\qquad{\qquad{\qquad}}} c_1\rho\cos{(\theta)} + c_2\rho\sin{(\theta)} = v_1\]
\section{Certaines récurrences non homogènes}
Equation générale:
\[a_0v_{n+k} + a_1v_{n+k-1} + \cdots + a_{k-1}v_{n+1} + a_kv_n = b_n \qquad \text{avec }n \in \mathbb{N}\]
Supposons $b_n = bs^n$.
Résolution:\\
\begin{itemize}
\item Somme d'une solution particulière et des solutions homogènes.\\
\item \emph{Degré 0}: $v_n = bs^n \qquad \forall n$\\
\end{itemize}
\section{Récurrences non homogènes de degré 1}
Equation générale:
\[v_{n+1} - av_n = bs^n\]\\
Résolution, en cherchant $v_n = cs^n$:\\
\begin{itemize}
\item $s \neq a$
\[
v_n &=& \frac{b}{s - a}s^n + da^n \qquad{\qquad{\qquad{\qquad}}}
v_0 &=& \frac{b}{s - a} + d
\]
\item $s = a$ \[v_n = bna^{n-1} + v_0a^n\]
\end{itemize}
\chapter{\color{blue}Graphes}
\section{Définition}
Soir un N ensemble fini non vide, dont  les éléments sont appelés des noeuds. Soit un R ensemble fini , dont les éléments sont appelés  des arêtes. Soit I une relation entre noeuds et arêtes, c'est-à-dire un sous-ensemble de $N \times R$, appelé relation d'\emph{incidence}, telle que e nombre de noeuds incidents à une arête soit égal à 1 ou à 2. On dit alors que le triplet $(N, R, I)$ est un \emph{graphe} (non orienté).
\section{vocabulaire}
\begin{itemize}
\item $\alpha \in \mathbb{R}$ est une boucle si $|\{i|iI\alpha\} = 1$\\
\item $|N|$ est l'\emph{ordre} du graphe.\\
\item Le \emph{degré} de $n$, noté $deg(n)$, est le nombre d'arêtes adjacentes au noeud $n$, les boucles comptant double.\\
\item Un graphe est \emph{simple} si il n'a ni boucle, ni noeuds reliés par des arêtes multiples.\\
\item $\alpha = \{i, j\}$ identifie l'unique arête telle que $iI\alpha$ et $jI\alpha$
\end{itemize}
\section{Isomorphisme}
Deux graphes simples $G = (N,R)$ et $G' = (N',R')$ sont \emph{isomorphes} si:\\
\begin{itemize}
\item Il existe une bijection $f : N \rightarrow N'$\\
\item $\{i,j\} \in R \Leftrightarrow \{f(i), f(j)\} \in R'$\\
\end{itemize}
\section{Matrice d'incidence}
La matrice d'incidence M est de genre $|N|\times |R|$ :\\
\begin{itemize}
\item $m_{i,\alpha} := 2 \Leftrightarrow \alpha$ est boucle sur $i$\\
\item $m_{i,\alpha} := 1 \Leftrightarrow \alpha$ est une arête ordinaire incidente à $i$\\
\item $m_{i,\alpha} := 0 \Leftrightarrow \alpha$ n'est pas incidente à $i$\\
\end{itemize}
Propriétés:\\
\begin{itemize}
\item $\sum_{i \in N}m_{i,\alpha} = 2$\\
\item $\sum_{i \in N}m_{i,\alpha} = deg(i)$\\
\item $\sum_{i \in N}deg(i) = 2|R|$\\
\item Le nombre de noeuds de degré impair d'un graphe est pair\\
\end{itemize}
\section{Matrice d'adjacence}
La matrice d'adjacence A est de genre $|N| \times |N|$:\\
\begin{itemize}
\item $a_{i,j} :=$ nombre d'arêtes reliant $i$ et $j$ si $i \neq j$\\
\item $a_{i,j} :=$ deux fois le nombre de boucles sur $i$\\
\end{itemize}
Propriétés:\\
\begin{itemize}
\item $\sum_{j \in N}a_{i,j} = \sum_{j \in N}a_{i,j} = deg(i)$\\
\item $\sum_{(i,j) \in N^2}a_{i,j} = 2|R|$\\
\item $MM^t = A + D$ où D est la matrice diagonale des degrés.\\
\end{itemize}
\section{Voyages dans un graphe}
\begin{center}
\begin{tabular}{p{4cm}|p{3.5cm}|p{3.5cm}}
&\textbf{Noeuds distincts}&\textbf{Arêtes distinctes}\\
\hline
&&\\
\textbf{Parcours ouvert $\: i_0 \neq i_k$}&chemin&piste ouverte\\
&&\\
\hline
&&\\
\textbf{Parcours fermé}&cycle&circuit (piste fermée)\\
&&\\
\end{tabular}
\end{center}
Si G est un graphe simple, le nombre de parcours de longueur $k$ entre ses noeuds $i$ et $j$ est donné par $(A^k)_{i,j}$.
\section{Graphes bipartis}
Le graphe simple $G = (N, R)$ est \emph{biparti} si il existe une partition $\{N_0, N_1\}$ de N telle que 
\[\{i, j\} \in R \Rightarrow i \in N_0\: et \: j \in N_1\:(ou\:i \in N_1\: et \: j \in N_0)\]\\
Un graphe simple est biparti si et seulement si il ne possède aucun cycle de longueur impaire.
\section{Connexité}
Un graphe est \emph{connexe} si il existe un chemin reliant toute paire de noeuds.\\\\
Soit un graphe $G = (N, R)$. On considère la partition $\{N_1, \cdots , N_m\} de N et l'ensemble $\{R_1, \cdots R_m\}$ des sous-ensembles $R_l$ de R, disjoints deux à deux, qui satisfont aux deux conditions suivantes:\\
\begin{itemize}
\item $R_l$ est l'ensemble des arêtes incidentes aux noeuds dans $N_l$,\\
\item Le graphe $G_l := (N_l, R_l)$ est connexe,\\
\end{itemize}
pour $l = 1, \cdots , m$. Alors les graphes $G_1, \cdots , G_m$ sont appelés les composantes connexes du graphe G.\\\\
Si il existe $N' \subset N$ non vide tel que aucune arête ne relie un noeud de N et un noeud de $N\backslash N'$, alors G n'est pas connexe.
\subsection*{Test de connexité}
Soient:\\
\begin{itemize}
\item $i_0 \in N$ un noeud quelconque de $G = (N,R)$,\\
\item $N' = \{i_0\}$ et $R' = \emptyset$,\\
\item $R_{reste} = R$\\
\end{itemize}
Tant que $\exists \alpha \in R_{reste}$ et $i \in N'$ tels que $iI\alpha$:\\
\begin{itemize}
\item $R_{reste} := R_{reste}\backslash \{\alpha\} , R'  = R' \cup \{\alpha\}$\\
\item $N' := N' \cup \{j | jI\alpha\}$\\
\end{itemize}
G est connexe si et seulement si $N' = N$.
\subsection*{Corollaires}
\begin{itemize}
\item Si $G = (N,R)$ est connexe alors $|R| \geq |N| - 1$\\
\item Si $G = (N,R)$ est connexe alors $|R| = |N| - 1$ si et seulement si G est sans cycle\\
\end{itemize}
\section{Arbres}
\begin{itemize}
\item G est connexe et sans cycle\\
\item G est connexe et $|R| = |N| - 1$\\
\item G est sans cycle et $|R| = |N| - 1$\\
\item G est sans cycle et lui ajouter une arête crée un t un seul cycle\\
\item G est connexe et supprimer une arête quelconque le déconnecte\\
\item Deux noeuds distincts de G sont reliés par un et un seul chemin\\
\end{itemize}
\section{Arbres sous-tendants}
L'arbre $G' = (N', R')$ est un arbre sous-tendant $G = (N,R)$ si $N = N'$ et $R' \subseteq R$.\\\\
$ \qquad \star$ G est connexe $\Leftrightarrow$ G possède un arbre sous-tendant.
\section{Arbres sous-tendants de poids minimum}
Soient:\\
\begin{itemize}
\item $c : R \rightarrow \mathbb{R}$ associant un poids à chaque arête.\\
\item $c(G) := \sum_{r \in R}c(r)$ est le poids du graphe G.\\
\end{itemize}
A est un \emph{arbre sous-tendant de poids minimum} de G si et seulement si A sous-tend G et tout arbre A' sous-tendant G est tel que $c(A) \leq c(A')$.
\subsection*{Kruskal}
Soit pour un graphe connexe $G = (N,R)$:\\
\begin{itemize}
\item $R_{ord} := trier(R)$,\\
\item $R' := \emptyset$.\\
\end{itemize}
Tant que $|R'| < |N| - 1$:\\
\begin{itemize}
\item $\alpha = Premier(R_ord)$;\\
\item $R_ord = R_ord\backslash\{\alpha\}$;\\
\item Si $(N, R' \cup \{\alpha\})$ est sans cycle, alors $R' = R' \cup \{\alpha\}$.\\
\end{itemize}
$(N, R')$ est un arbre sous-tendant de poids minimum de $(N, R)$.
\section{Euler}
\begin{itemize}
\item Une \emph{piste eulérienne} est une piste qui passe par toutes les arêtes du graphe.\\
\item Un grahe connexe G est eulérien $\Leftrightarrow$ Tous les noeuds de G sont de degré pair.\\
\item Le graphe G possède une piste eulérienne $\Letrightarrow$ G est connexe, et contient au maximum deux noeuds de degré impair.\\
\end{itemize}
\section{Hamilton}
\begin{itemize}
\item un graphe simple possède un \emph{chemin hamiltonien} si il possède un chemin passant par chacun de ses noeuds.\\
\item Un graphe simple possède un \emph{cycle hamiltonien} si il possède un cycle passant par chacun de ses noeuds.\\
Un \emph{graphe hamiltonien} est un graphe simple possédant un cycle hamiltonien.\\
\end{itemize}
\section{Voyages complets dans un graphe}
\begin{center}
\begin{tabular}{p{4cm}|p{3.5cm}|p{3.5cm}}
&\textbf{Par tous les Noeuds une et une seule fois}&\textbf{Par toutes les arêtes une et une seule fois}\\
\hline
&&\\
\textbf{Parcours ouvert $\: i_0 \neq i_k$}&chemin hamiltonien&piste eulérienne\\
&&\\
\hline
&&\\
\textbf{Parcours fermé}&cycle hamiltonien$\qquad$ graphe hamiltonien&circuit eulérien $\qquad$ graphe eulérien\\
\end{tabular}
\end{center}


\part{\color{orange}Mécanique}
\chapter{\color{orange}Vecteurs}
\section{Décomposition des vecteurs}
\[ A = \sqrt{{A_x}^2 + {A_y}^2} \]
\[ \theta = \arctan{\frac{A_y}{A_x}} \]
\section{Produit scalaire}
\[ \vec{A}.\vec{B} = AB\cos{\theta} = |A||B|\cos{\theta} \]
\[ \vec{A}.\vec{B} = A_x B_x + A_y B_y + A_z B_z \]
\section{Produit vectoriel}
\[ C = A \times B =  AB\sin{\theta} \]
\[C_x = A_yB_z - A_zB_y\qquad{\qquad{\qquad}}C_y = A_zB_x - A_xB_z\qquad{\qquad{\qquad}}C_z = A_xB_y - A_yB_x\]
On à grâce à la méthode du \emph{pouce} retrouver le produit des composantes:
\[
\begin{array}{r c l}
\hat{i} \times \hat{j} &=& \hat{k}\\
\hat{j} \times \hat{k} &=& \hat{i}\\
\hat{k} \times \hat{i} &=& \hat{j}\\
\end{array}
\]
\[
\left |
\begin{tabular}{c c c}
i&j&k\\
A_x&A_y&A_z\\
B_x&B_y&B_z\\
\end{tabular}
\right |
\]
\chapter{\color{orange}Lois de Newton}
\section{Loi d'inertie}
Si la somme des forces agissant sur un corps est nulle, alors il ne subit aucune accélération et se déplacement à vitesse constante.\\
\[ \sum \vec{F} = 0 \]
\section{Loi du mouvement}
Soit un corps de masse $m$ : l'accélération subie par ce corps est proportionnelle à la résultante des forces qu'il subit, et inversement proportionnelle à sa masse m.\\
\[ \sum \vec{F} = m \vec{a} \]
\section{Principe d'action-réaction}
Tout corps A exerçant une force sur un corps B subit une force d'intensité égale, de même direction mais de sens opposé, exercée par ce corps B.\\
\[ \vec{F}_{A sur B} = -\vec{F}_{B sur A} \]
\chapter{\color{orange}Conditions d'équilibre}
\section{Conditions}
\begin{itemize}
\item La somme des forces est nulle.\[\sum \vec{F} = 0\]\\
\item La somme des moments en un point A est nulle.\[\sum \vec{\tau_A} = 0\]
\end{itemize}
\chapter{\color{orange}Mouvements}
\subsection{Mouvement rectiligne uniforme (MRU/MRUA)}
\[ v_x = \lim_{\Delta t \rightarrow 0 } \frac{\Delta x}{\Delta t} = \frac{dx}{dt} \]
\[ a_x = \lim_{\Delta t \rightarrow 0 }} \frac{\Delta v_x}{\Delta t} = \frac{dv_x}{dt} \]

\[ v_x = v_{0x} + a_{x}t \]
\[ x = x_0 + v_{0x} t + \frac{a t^2}{2}\]

\section{Trajectoire d'un projectile}

\[ x = (v_0 \cos{ \alpha_0 }) t \]
\[ y = (v_0 \sin{ \alpha_0 }) t - \frac{1}{2} g t^2 \]
\[ v_x = v_0 \cos{ \alpha_0 } \]
\[ v_y = v_0 \sin{ \alpha_0 } - gt\]

\section{Mouvement circulaire uniforme (MCU)}
\[ a_{rad} = \frac{v^2}{R} \]
\[ T = \frac{2\pi R}{v}\]
\[ a_{rad} = \frac{4\pi^2 R}{T^2} \]
\[ a_{tan} = \frac{ d|\vec{v}| }{ dt }\]
\[ F_{net} = ma_{rad} = m\frac{v^2}{R}\]

\section{Vitesse en courbe}
Sur un sol plat:
\[ v_{max} = \sqrt{\mu_s g R} \]
En virage incliné sans forces de frottements:
\[ v_{max} = \sqrt{Rg\tan{\beta}}\]
En virage incliné avec forces de frottements:
\[ v_{max} = \sqrt{Rg\left (\frac{\sin{\beta} + \mu_s\cos{\beta}}{\sin{\beta} - \mu_s\cos{\beta}}\right )}\]
\[\mu_s = \frac{v^2\cos{\beta} - Rg\sin{\beta}}{v^2\sin{\beta} + Rg\cos{\beta}}\]
\section{Vitesse relative}
\[ \vec{v}_{P/A} = \vec{v}_{P/B} + \vec{v}_{B/A} \]

\chapter{\color{orange}Résistance des fluides et vitesse terminale}
\section{A petite vitesse}
\[ F_f = kv \]
\[ v_t = \frac{mg}{k} \]
\section{A grande vitesse}
\[ F_f = Dv^2 \]
\[ v_t = \sqrt{ \frac{mg}{D} }\]

\chapter{\color{orange}Energie potentielle et cinétique}
\section{Travail}
\[W = \int_{x_1}^{x_2} \vec{F} d\vec{l}\]
\section{Energie}
\[K_{cin\acute{e}tique} = \frac{mv^2}{2}\]
\[U_{potentielle\  gravitationnelle} = mgy\]
\[U_{potentielle\  \acute{e}lastique} = \frac{1}{2}kx^2\]
$K$ et $U$ sont définis à une constante près.

\section{Forces conservatrices}
Lorsqu'il n'y aucune perte d'énergie.
\[E = K_1 + U_1 = K_2 + U_2 = cste \]

\section{Forces non-conservatrices}
Lorsque des forces extérieurs agissent sur le corps.
\[K_1 + U_1 + W_{ext} = K_2 + U_2\]
\[W_{ext} = (K_2 - K_1) + (U_2 - U_1) = F(x_2 - x_1)\]

\section{Energie potentielle élastique}
\[F_{ressort} = kx\]
\[U_{\acute{e}lastique} = \frac{kx^2}{2}\]
$k$ dépend de l'élasticité.
\chapter{\color{orange}Gravitation}
\section{Force d'attraction d'un corps}
\[F_g = \frac{Gm_1m_2}{r^2}\]
\[G = 6.67\times 10^{-11} N.m^2/kg^2\]
Le poids d'un corps est la somme des forces gravitationnelles exercées sur celui-ci par tous les autres corps de l'univers.
\[W_{grav} = \int_{r_1}^{r_2}F_r dr\]
\[U = -\frac{GMm}{r}\]

\section{Satellite en orbite circulaire}
\[ \frac{GMm}{r^2} = \frac{mv^2}{r} \Leftrightarrow v_{orbitale} = \sqrt{\frac{GM}{r}} \]
\[T = \frac{2\pi r}{v} = 2\pi r \sqrt{\frac{r}{GM}} = \frac{2\pi r^{3/2}}{\sqrt{GM}}\]
\section{Vitesse de libération}
\[E_{totale} = E_{potentielle} + E_{cin\acute{e}tique} \Leftrightarrow 0 = -\frac{GMm}{r} + \frac{mv^2}{2}\]
\[ \frac{GMm}{r} = \frac{mv^2}{2} \Leftrightarrow v_{lib\acute{e}ration} \geq \sqrt{\frac{2GM}{r}} \]
\[v_{lib\acute{e}ration} \geq \sqrt{2}v_{orbitale}\]

\chapter{\color{orange}Momentum}
\section{Définition par la deuxième loi de Newton}
On peut définir le \emph{momentum} comme étant la quantité de mouvement d'un corps.
\[\vec{p} = m\vec{v}\]
\[\sum \vec{F} = m\vec{a} = m\frac{d\vec{v}}{dt} = \frac{d\vec{p}}{dt}\]
\[\vec{J} = \int_{t_1}^{t_2} \sum\vec{F} dt = \int_{t_1}^{t_2}\frac{d\vec{p}}{dt} dt = \int_{\vec{p_1}}^{\vec{p_2}} d\vec{p} = \vec{p_2} - \vec{p_1}\]
\section{Momentum et énergie cinétique}
\begin{itemize}
\item L'énergie cinétique correspond au travail total effectué sur un corps pour accélérer celui-ci de l'état d'équilibre à sa vitesse actuelle.\\
\item Le momentum équivaut à l'impulsion pour accélérer un corps de l'état d'équilibre à sa vitesse présente.\\
\end{itemize}
\subsection{Conservation de la quantité de mouvement}
Si la somme des forces extérieurs est nulle, alors la quantité totale de mouvement du système est contante.
\[\vec{P} = \vec{p_1} + \vec{p_2} + ...\]
\chapter{\color{orange}Collisions}
\section{Types de collisions}
\begin{itemize}}
\item \emph{Collision élastique}: Les forces en les corps sont conservatrices et l'énergie totale du système reste la même avant et après la collision.\\
\item \emph{Collision inélastique}: L'énergie totale du système est moindre après la collision.\\
\item \emph{Collision totalement inélastique}: Après la collision, les deux corps \emph{collent} ensemble pour ne former qu'un.\\
\end{itemize}
\section{Collisions complètement inélastiques}
Considérons un corps A en mouvement et un corps B au repos.

\[m_A\vect{v_{A1}} + m_B\vec{v_{B1}} = (m_A + m_B)\vec{v_2}\]
\[\Downarrow\]

\[v_{2x} &=& \frac{m_A }{m_A + m_B}v_{A1x}\]

\section{Collisions élastiques}
Considérons un corps A en mouvement et un corps B au repos.
\[m_A\vect{v_{A1x}} = m_A\vec{v_2x} +  m_B\vec{v_{B2x}}\qquad{\&{\qquad}}
\frac{m_A\vect{v_{A1x}^2}}{2} = \frac{m_A\vect{v_{A2x}^2}}{2} + \frac{m_B\vect{v_{B2x}^2}}{2}\]
\[\Downarrow\]
\[
v_{A2x} &=& \frac{m_A - m_B}{m_A + m_B}v_{A1x}\qquad{\qquad{\qquad}}
v_{B2x} &=& \frac{2m_A }{m_A + m_B}v_{A1x}\]
\chapter{\color{orange}Mouvement périodique}
\section{Formules}
\[x = A\cos{(\omega{t} + \phi)}\]
\begin{itemize}
\item \emph{$A$}: l'amplitude du mouvement.\\
\item \emph{$\omega$}: La vitesse angulaire donnée par \[\omega = \frac{V}{R}\]\\
\item \emph{$\phi$}:le déphasage du mouvement.\\
\end{itemize}
\section{Fréquence, période et vitesse angulaire}
\[T = \frac{1}{f} = \frac{2\pi}{\omega}\]
\[\omega = 2\pi{f} = \frac{2\pi}{T}\]
\section{Oscillation d'un ressort}
Soit:\\
\[F = ma = m\frac{d^2x}{dt} = -kx\]
En résolvant l'équation différentielle on trouve:\\
\[x(t) = A\sin{(\omega{t})}\]
On peut ensuite trouver $\omega$ en injectant la solution dans l'équation:\\
\[
\begin{array}{r c l}
m(A\sin{(\omega{t})})'' &=& - kA\sin{(\omega{t})}\\
-mA\omega^2\sin{(\omega{t})} &=& - kA\sin{(\omega{t})}\\
m\omega^2 &=& k\\
\end{array}
\]
On trouve alors:
\[\omega = \sqrt{\frac{k}{m}}\]
\section{Pendule simple}
Soit:\\
\[F = ma = m\frac{d^2x}{dt} = m\frac{Ld^2\theta}{dt} = -mg\sin{(\theta )}\]
Pour des angles de faible amplitude on va pouvoir considérer:\\
\[\sin{(\theta )} \cong \theta\]
On a obtient donc:\\
\[\frac{Ld^2\theta}{dt} = -g\theta\]
En résolvant l'équation différentielle on trouve:\\
\[\theta{(t)} = \theta_0\sin{(\omega{t})}\]
On peut ensuite trouver $\omega$ en injectant la solution dans l'équation:\\
\[
\begin{array}{r c l}
L(\theta_0\sin{(\omega{t})})'' &=& -g\theta{(t)}\\
-L\theta_0\omega^2\sin{(\omega{t})} &=& -g\theta_0\sin{(\omega{t})}\\
L\omega^2 &=& g\\
\end{array}
\]
On trouve alors:
\[\omega = \sqrt{\frac{g}{L}}\]
Similitude avec le ressort:\\
\[F_{\theta} = -mg\sin\theta \cong -mg\theta = -mg\frac{x}{L}\]
\[\omega =\sqrt{\frac{k}{m}} =\sqrt{\frac{mg/L}{m}} = \sqrt{\frac{g }{L}}\]
\section{Energie dans un mouvement harmonique}
\[E = \frac{1}{2}mv^2_x + \frac{1}{2}kx^2 = \frac{1}{2}kA^2 = cste\]





\part{\color{purple}Electricité}
\chapter{\color{purple}Electrostatique}
\section{Loi de Coulomb}
\[F = \frac{1}{4\pi\epsilon_0}\frac{q_1q_2}{r^2}\]
\[K \cong 9.10^9 \frac{Nm^2}{C^2}\]
\section{Champs électriques}
\[\overrightarrow{E} = \frac{\overrightarrow{F}}{Q}\]
\begin{description}
\item[Champ d'un point de charge: ] \[\frac{1}{4\pi\epsilon_0}\frac{q}{r^2}\]
\item[Champ à  l'extérieur d'une sphère: ] \[\frac{1}{4\pi\epsilon_0}\frac{Q}{r^2}\]
\item[Champ à  l'intérieur d'une sphère: ] \[\frac{1}{4\pi\epsilon_0}\frac{Qr}{R^3}\]
\item[Champ d'une plaque infinie: ] \[\frac{\sigma}{2\epsilon_0}\]
\item[Champ entre deux plaques: ] \[\frac{\sigma}{\epsilon_0}\]
\end{description}
\section{Dipôles}
\[\overrightarrow{\tau} = \overrightarrow{p} \times \overrightarrow{E} = pE\sin\phi\]
\section{Flux électrique (Gauss)}
\[\Phi_{E} = \oint E\cos\phi dA = \oint E_{\perp} dA = \oint \overrightarrow{E}.d\overrightarrow{A} = \frac{Q_{encl}}{\epsilon_0}\]
Pour les conducteurs: \[E_{\perp} = \frac{\sigma}{\epsilon_0}\]
\section{Energie électrique}
\[W_{a\rightarrow{b}} = U_a - U_b = -\delta{U} = \int_{a}^{b}F dr\]
\[\int_{a}^{b}F dr = \int_{a}^{b}\frac{1}{4\pi\epsilon_0}\frac{Qq_0}{r^2} dr = \frac{Qq_0}{4\pi\epsilon_0}\left(\frac{1}{a} - \frac{1}{b}\right)\]
\section{Potentiel électrique}
\[V = \frac{U}{Q_0} = \frac{Q}{4\pi\epsilon_0{r}}\]  \[V_a - V_b = \int_{a}^{b}\overrightarrow{E}.d\overrightarrow{l} = \int_{a}^{b}E\cos{\phi} dl\]
\section{Capacités et diélectriques}
\[C = \frac{Q}{V_{ab}} = \frac{\epsilon_{0}A}{d}\qquad{\qquad{\qquad}} U = \frac{CV^2}{2} = \frac{Q^2}{2C} = \frac{QV}{2}\]\\
\[K = \frac{C}{C_0}  \qquad{\qquad{\qquad}}   K = \frac{V_0}{V}  \qquad{\qquad{\qquad}}    K\epsilon_0 = \epsilon \]\\
\[u = \frac{1}{2}K\epsilon_{0}E^2 = \frac{\epsilon{E^2}}{2} \qquad{\qquad{\qquad}} \oint{K}\overrightarrow{E}.d\overrightarrow{A} = \frac{Q_{encl}}{\epsilon_0}\]

\chapter{\color{purple}Courant continu}
\section{Courant électrique (DC)}
\[I = \frac{dq}{dt}\qquad{\qquad{\qquad}}\rho = \frac{E}{J}\qquad{\qquad{\qquad}}q(t) = \int_{t_0}^{t}i(t) dt + q{t_0}\]
\section{Résistance et résistivité}
\[R = \frac{\rho{L}}{A} \qquad{\qquad{\qquad}}V = IR\]
\section{Force électromotrice et puissance}
\[P = VI = I^2R\] 
\[ V_{ab} = \varepsilon - IR_{interne}\qquad{\qquad{\qquad}}w = \int_{t_1}^{t_2}p(t) dt\]
\section{Lois de Kirchoff's}
\[\sum{I} = 0  \qquad{\qquad{\qquad}}\sum{V} = 0\]
\section{Capacités \& Inductances}

\begin{table}[H]
\begin{center}
\begin{tabular}{p{6.5cm}|p{6.5cm}}
\textbf{Capacité} & \textbf{Inductance}\\
\hline
\[I(t) = \frac {CdV}{dt}\] & \[V(t) = \frac{LdI}{dt}\]\\
\[\tau = RC\] & \[\tau = \frac{L}{R}\]\\
\[U = \frac{CV^2}{2} = \frac{Q^2}{2C}\] & \[U = \frac{LI^2}{2}\]
\end{tabular}
\end{center}
\end{table}

\section{Circuit R-L-C}
\[\frac{Q^2}{2C} + \frac{LI^2}{2} = \frac{Q^{2}_{max}}{2C}\]
\[I = \pm \sqrt{\frac{Q^{2}_{max} - q^2}{LC}}\]
\[ w = \sqrt{\frac{1}{LC}}\qquad{\qquad{\qquad}}w' = \sqrt{\frac{1}{LC} - \frac{R^2}{4C^{2}}} \]
\chapter{\color{purple}Courant alternatif}
\section{Courant électrique (AC)}
\[i = I\cos{\omega{t}}\qquad{\qquad{\qquad}}v = V\cos{(\omega{t} + \phi)}\]
\[X(t) = A + Be^{-\frac{t}{\tau}}\]
\section{Valeurs efficaces}
\[I_{eff} = \frac{I}{\sqrt{2}}\qquad{\qquad{\qquad}}V_{eff} = \frac{V}{\sqrt{2}}}\qquad{\qquad{\qquad}}P_{eff} = V_{eff}I_{eff}\cos{\theta}\]
\section{Capacités \& Inductances}
\begin{table}[H]
\begin{center}
\begin{tabular}{p{6.5cm}|p{6.5cm}}
\textbf{Capacité} & \textbf{Inductance}\\
\hline
\[I_C = \frac{CdV}{dt}\]&\[V_L = \frac{LdI}{dt}\]\\
\[i = \frac{dq}{dt} \Rightarrow q = \frac{I_{0}\sin{\omega{t}}}{\omega}\]&{}\\
\[V_C = \frac{I_{0}\sin{\omega{t}}}{\omega{C}}\]&\[V_{L} = -L\omega{}I_{0}\sin{\omega{t}}\]\\
\[X_C = \frac{1}{\omega{C}}\]&\[X_L = L\omega\]
\end{tabular}
\end{center}
\end{table}

\section{Circuit R-L-C}
\[Z = \sqrt{R^2 + (X_L - X_C)^2} = \sqrt{R^2 + \left(\omega{L} - \frac{1}{\omega{C}}\right)^2}\]
\[\tan{\phi} = \cfrac{\omega{L} -\cfrac{1}{\omega{C}}}{R}\]
\section{Transformateur}
\[\frac{V_1}{V_2} = \frac{N_1}{N_2}\qquad{\qquad{\qquad}}V_{1}I_{1} = V_{2}I_{2}\]

\end{document}