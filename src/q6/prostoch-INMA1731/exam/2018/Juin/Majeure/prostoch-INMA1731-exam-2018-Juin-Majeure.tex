\documentclass[fr]{../../../../../../eplexam}

\hypertitle{Processus Stochastiques
}{6}{INMA}{1731}{2018}{Juin}{Majeure}
{Victor Anckaert}
{Luc Vandendorpe}

\section{}

\begin{enumerate}
    \item Qu'est-ce qu'un modèle AR(n) ?
    \item Donnez la fonction de densité spectrale de l'output, en partant de la définition d'une fonction de densité spectrale d'un système BIBO stable.
    \item Donnez un modèle AR(2) tel que la fonction de densité spectrale ait un pic en $\Omega=\frac{\pi}{4}$.
\end{enumerate}

\begin{solution}

\begin{enumerate}
    \item Un modèle AR(n) est un modèle Auto Régressif. Il est décrit par :
    $$ \overline{A}(z^{-1})Y(k) = E(k)$$
    $$ Y(k) + a_1Y(k-1) + \ldots + a_nY(k-n) = E(k) $$
    où $A(z) = z^n\overline{A}(z^{-1})$ est un polynôme monique avec toutes ses racines à l'extérieur du cercle unité, et $E(k)$ un bruit blanc de moyenne nulle
    \item Pour un système BIBO stable, nous avons la relation :
    $$ \gamma_Y = H(z)\gamma_XH^*(\frac{1}{z^*}) $$
    Dans notre cas, la fonction de transfert est $\frac{1}{\overline{A}(z^{-1})}$, et $\gamma_X = \sigma_E^2$. On a donc :
    $$ \gamma_y(z) = \frac{\sigma_E^2}{A(z)A^*(\frac{1}{z^*})} $$
    \item Modèle AR(2) : $Y(k) + a_1Y(k-1) + a_2Y(k-2) = E(k)$ 
    
    On a : $A(z) = a_2 + a_1z + z^2$, et donc comme densité spectrale : 
    $$\gamma_Y = \frac{\sigma_E^2}{(a_2+a_1z+z^2)(a_2+\frac{a_1}{z}+\frac{1}{z^2})} = \frac{\sigma_E^2z^2}{(a_2+a_1z+z^2)(a_2z^2+a_1z+1)}$$
    Le but est d'avoir un pic dans la densité spectrale en $\Omega = \frac{\pi}{4}$, donc vu que $z = \exp{j\Omega}$, on aura un pic en $z = \sqrt{2}(1+j)$. 
    
    Une manière simple  d'obtenir ce pic est de faire en sorte que les deux seconds degrés du dénominateur aient un minimum en $\sqrt{2}(1+j)$. On trouve donc en dérivant et en égalant à 0 que
    $a_1 = -2\sqrt{2}(1+j)$, et $a_2 = 1$. 
    
    Une autre technique était d'annuler le dénominateur en $\sqrt{2}(1+j)$ pour aller vers l'infini, comme ça on est sûr d'avoir un pic.
\end{enumerate}

\end{solution}


\section{}

Question sur le filtre de kalman (équations données).
    
\begin{enumerate}
    \item Donnez les équations linéaire de représentation d'état pour lesquels le filtre de kalman est appliqué. Définissez chaque variable.
    \item Donnez un algorithme de Kalman modifié si l'on possède uniquement les observations $y_0,y_2,y_4,\ldots$
\end{enumerate}
    
\begin{solution}
 
\begin{enumerate}
        \item
    
        $$x_{t+1} = Ax_t + \Gamma u_t$$
        $$y_t = Bx_t + w_t$$
        Avec $u$ et $w$ qui sont des Bruits Blancs.
        
        \item 
        Pour estimer les différents $x_0, x_2, x_4,...$ On part des équations: 
        
        $$x_{t+2} = Ax_{t+1} + \Gamma u_{t+1}$$
        $$y_t = Bx_t + w_t$$
        
        En développant,
        
        $$x_{t+2} = A^2x_{t} + A\Gamma u_{t} + \Gamma u_{t+1}$$
        $$y_t = Bx_t + w_t$$
        
        Alors, nous pouvons simplement utiliser le filtre de Kalman en remplaçant A par $A^2$ et $\Gamma$ par $A\Gamma + \Gamma$ (vu qu'on somme de temps de bruit blanc pour chaque pas de temps).        
        
        Ensuite, pour estimer les différents $x_1, x_3, x_5,...$ Un bon estimateur serait: $$\frac{x_{t+1}+x_{t-1}}{2}$$
\end{enumerate}
 
\end{solution}


\section{}

On a des observations $y$, on essaye d'estimer $I$.
$$y(n)=\sum_{l=0}^{N-1} h(l) I(n-l)+w(n)$$
$$\hat{I}(n)= \sum_{l=-K}^K c(l) y(n-l) + \sum_{l=0}^{L-1} [\delta(l) - d(l)] I(n-l)$$
$w$ et $I$ non-corrélés, $w$ bruit blanc, $d(l)$ monique
\begin{enumerate}
    \item Donnez les équations que les coefficients $c(l)$ et $d(l)$ doivent respecter pour que le filtre soit optimal au sens de Wiener.
    \item Donnez l'équation  que les coefficients $c(z)$ et $d(z)$ doivent respecter pour que le filtre soit optimal pour un estimateur LMMSE.
    \item Obtenez $C(z)$ en fonction de $D(z)$.
    \item Ecrivez $E(z) = I(z) - \widehat I(z)$ uniquement en fonction de $D(z)$.
\end{enumerate}

\begin{solution}
 
\begin{enumerate}
    \item Les observations sont $y$, et on essaye d'estimer $I$. Le principe d'orthogonalité est alors $$E[e(n) y^* (n-l)]=0$$ avec $e(n)=I(n)-\hat{I}(n)$.
    En développant on trouve alors
    $$E[I(n) y^* (n-l)]=E[\hat{I}(n) y^* (n-l)]$$
    On développe la partie de gauche:
    $$E[I(n) y^* (n-l)]=E[I(n) (\sum_{k=0}^{N-1} h(k) I(n-l-k) + w(n-l))^*]$$
    $$=\sum_{j=0}^{N-1} h^*(k) R_I(l+k)+R_{IW}(l)=\sum_{j=0}^{N-1} h^*(k) R_I(l+k)$$ car $I$ et $W$ sont non corrélés.
    
    On développe la partie de droite:
    $$E[\hat{I}(n) y^*(n-l)]=$$$$E\{[\sum_{a=-K}^{K} c(a) (\sum_{j=0}^{N-1} h(j) I(n-a-j) + w(n-a)) + \sum_{a=0}^{N-1} (\delta(a)-d(a)) I(n-a)][\sum_{k=0}^{N-1} h(k) I(n-l-k) + w(n-l)]^*\}$$
    $$=\sum_{a=-K}^{K} c(a) \sum_{j=0}^{N-1} h(j) \sum_{k=0}^{N-1} h^*(k) R_I(l+k-a-j) +  \sum_{a=-K}^{K} c(a) R_W(l-a) + \sum_{a=0}^{N-1} (\delta(a)-d(a)) \sum_{k=0}^{N-1} h^*(k) R_I(l+k-a)$$
    $R_IW$ et $R_WI$ sont égaux à 0 car $I$ et $w$ sont toujours non corrélés

    \item Les observations dans le domaine $z$ sont $$Y(z)=H(z) I(z) + W(z)$$ 
    et la deuxième équation devient 
    $$\hat{I}(z)=C(z) Y(z) + (1-D(z)) I(z)$$
    Les équations à respecter sont alors 
\end{enumerate}
 
\end{solution}

\end{document}
