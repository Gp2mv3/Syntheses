\part{Preuves de programme}
\section{Introduction}

\subsection{Science de la programmation}
Le \textbf{déboguage} : programmer, tester, corriger, jusqu'à ne plus trouver d'erreurs. C'est \textbf{inefficace} en tant que méthodologie. Ca ne permet pas d'établir que le programme est \textbf{correct}. Ce n'est pas fiable pour détecter que le programme n'est \textbf{pas correct}. Chaque test réussi \textbf{augmente notre confiance} en la justesse de l'algorithme, mais on n'est \textbf{jamais sûr}.\\

Le \textbf{déboguage} et le \textbf{ test} sont donc incertain pour établir la correction et pour trouver les erreurs mais surtout, inutile comme base de \textbf{construction} de programmes.\\

Une \textbf{science de la programmation} sert à \textbf{spécifier} les programmes, \textbf{vérifier} les programmes par rapport à leurs spécifications et \textbf{construire} les programmes sur base de leurs spécifications.


\subsection{Problème, solution et preuve}
$\bullet$\textbf{Théorie du problème}:
Dans la théorie du problème, on définit les \textbf{structures}, les \textbf{opérations} et \textbf{caractéristiques} ainsi que les \textbf{propriétés utiles}. On définit également les \textbf{cas particuliers}.\\

$\bullet$\textbf{Solution}:
Dans la solution, on détermine "\textbf{comment faire ?}". On généralise le résultat désiré. On définit une situation initiale et une situation finale pour ensuite définir une itération entre ces 2 situations.\\

$\bullet$\textbf{Preuve}:
La \textbf{correction} assure que si les données satisfont les pré-conditions, alors les résultats satisfont les post-conditions.\\
La \textbf{terminaison} assure que si les données satisfont les pré-conditions, alors le programme se termine.\\
La \textbf{correction partielle} assure que si les données satisfont les pré-conditions, et si le programme se termine, alors les résultats satisfont les post-conditions.\\
Correction totale $\equiv$ Correction partielle ET Terminaison
\\ \vspace{1,5mm}\\
On prouve la terminaison grâce au \textbf{variant}. Il \textbf{diminue} à chaque itération et est toujours \textbf{positif ou nul}. Le nombre d'itérations est donc fini.\\
On prouve la correction partielle grâce à l'\textbf{invariant}. Si les pré-conditions sont vraies initialement, alors l'invariant est vrai à l'entrée dans la boucle.\\ Si l'invariant est vrai avant une itération de la boucle, alors l'invariant est vrai après l'itération.\\ Si l'invariant est vrai à la sortie de la boucle, alors les post-conditions sont vraies finalement.\\ \vspace{1,5mm}\\
La preuve sur l'itération est une récurrence. Il y a une \textbf{cas de base}, un \textbf{cas inductif} et une \textbf{conclusion}.\\

$\bullet$\textbf{Représentation}:
La représentation cherche à trouver la meilleure représentation pour les données, le problème, la solution et la preuve.
\subsection{Spécifier des programmes}
Les \textbf{assertions de programme} sont des propositions vraies à un point du programme.\\

\textbf{Assertion}: [ p ] $\equiv $ en ce point, p est vrai, avec p comportant des \textbf{variables du programme}\\

$\bullet$\textbf{Triplet de Hoare}:
[P] S [Q] $\equiv$ \textbf{triplet de Hoare}, \\ avec pré-condition P, programme S et post-condition Q.\\

[P] S [Q] est une \textbf{proposition logique}, valide ou invalide. [P]S[Q] est valide ssi : \\- \hspace{5mm} \textbf{Si P est vraie avant} d'exécuter S\\- \hspace{5mm} \textbf{Alors} l'exécution de S \textbf{se termine}\\- \hspace{5mm} \textbf{Et Q est vraie après} l'exécution de S.\\ \hspace{5mm}
C'est une \textbf{correction totale}, S réalise Q sous l'assomption de P.\\

$\bullet$\textbf{Variables auxiliaires}:
Les variables auxiliaires ne sont pas des variables du programme. Elles sont rigides et donc ne change pas au cours de l'exécution.\\

$\bullet$\textbf{Conséquence}:
La conséquence est un connecteur logique qui peut lier deux pré- ou post-conditions ensemble.\\

[Cond1] $\Rightarrow$ [Cond2], avec Cond1 plus contraignante que Cond2\\

Dans le cas de la pré-condition, elle crée un \textbf{renforcement} de la pré-condition. On va rajouter une pré-condition plus contraignante et précise au-dessus de la condition actuelle.
Dans le cas de la post-condition, elle crée un \textbf{affaiblissement} de la post-condition. On va rajouter une post-condition moins contraignante en dessous de la condition actuelle. \\

La règle de conséquence est la suivante : \textbf{Si P $\Rightarrow$ Q, alors [P][Q]}