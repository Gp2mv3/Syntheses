\documentclass[a4paper, 11pt, onecolumn]{article}

\usepackage[french]{babel}
\usepackage{color}
\usepackage[utf8]{inputenc}
\usepackage[margin=2cm]{geometry}
\usepackage{framed}
\usepackage{fourier-orns}

\title{Analyse de données quantitative\\Question 9}
\date{}

\begin{document}

\maketitle

\textit{Dérivez l’algorithme de classification des données qui est utilisé dans le cadre de l’analyse discriminante, après avoir effectué une projection sur les axes discriminant (une Gaussienne estimée par classe – mixture de Gaussiennes). Expliquez également comment estimer les performances d’un modèle de classification (cross-validation, etc) et en quoi cela est important.}

\begin{enumerate}
\item \textbf{Contexte}

  \begin{description}
    \item[Analyse discriminant] est une méthode de \textbf{feature extraction} (\textit{càd qu'on va créer de nouvelles
      dimension pour réduire la corrélation entre les varriables et conserver l'information interessante}).
      C'est aussi une méthode de \textbf{classification}.
  \end{description}

  La \textbf{décompositon de la variance} rentre dans le contexte de l'analyse discriminante.
On va chercher l'axe qui maximise le rapport de la variance entre classe et la variance totale des données projetée (voir schéma slide 48 part 2).
 

  \danger Cela s'applique \textbf{exclusivement} aux données numériques. 

  \paragraph{}
Nous avons une projection avec le problème de valeur propre suivant
$$\Sigma^{-1}Bv = \lambda v$$
avec
$$
\left\{
\begin{array}{l}
\sigma_{v(w)}^2=v^T\left[\frac{1}{n}\sum_{k=1}^qn(k)\left(\frac{1}{n(k)}\sum_{i\in C(k)}(x_i-g(k))(x_i-g(k))^T\right)\right]v=v^TWv\\
\sigma_{v(b)}^2=v^T\left[\sum_{k=1}^qn(k)\frac{(g(k)-g)(g(k)-g)^T}{n}\right]v=v^TBv\\
\sigma_v^2=v^T\left[\sum_{i=1}^n\frac{(x_i-g)(x_i-g)^T}{n}\right]v=v^T\Sigma v
\end{array}
\right.
$$

On va donc projeter les données sur les axes avec le vecteur propre associé à la plus grande valeur propres. On obtient le score $z$
$$z_i=v^Tx_i$$

\item \textbf{Algorithme de classification}

On peut utiliser une distribution gaussienne pour evaluer la probabilité à priori à parir des données projetée
$$P(z|y=\omega_k) = \frac{1}{(2\pi)^{p/2}|W|^{1/2}}exp[-\frac{1}{2}(z-g(k))^TW^{-1}(z-g(k))]$$
Avec $W$ une matrice de variance-covariance commune


\begin{framed}
Nous allons utiliser la formule de Bayes.
\begin{eqnarray}
P(y=\omega_i|z) &=& \frac{P(y=\omega_i)P(z|y=\omega_i)}{P(z)}\\
&=& \frac{P(y=\omega_i)P(z|y=\omega_i)}{\sum_{k=1}^qP(\omega_k)P(z|y=\omega_k)}
\end{eqnarray}
Chaque observation est associe a la classe pour laquelle la probabilité est maximale
\begin{eqnarray}
P(y=\omega_k|z)&>&P(y=\omega_i|z)\\
-ln(P(y=\omega_k|z)) &<& -ln(P(y=\omega_i|z))
\end{eqnarray}
En remplacant par la formule de distribution gaussienne
\begin{eqnarray}
(z-g(k))^TW^{-1}(z-g(k))-2ln(P(\omega_k))+ln(|W|)&<&(z-g(i))^TW^{-1}(z-g(i))\\
&&-2ln(P(\omega_i))+ln(|W|)
\end{eqnarray}
Et comme la matrice de variance-covariance $W$ est commune
\begin{eqnarray}
(z-g(k))^TW^{-1}(z-g(k))-2ln(P(\omega_k))&<&(z-g(i))^TW^{-1}(z-g(i))-2ln(P(\omega_i))
\end{eqnarray}
\end{framed}

$\rightarrow$ Nous avons à nouveau un \textbf{hyperplan} séparant les deux classes.
Dans le cas ou $W$ n'est pas égale aux deux données les surface de séparation ne sont plus des hyperplan. 

On calcule alors la distance du points à la classe
$$dist^2(x,k)=ln|W_k| + (x-g_k)^TW_k^{-1}(x-g_k)-2ln(P(\omega_k))$$

\item \textbf{Comment calculer la performance d'un modele}

  Le calcul de performance apparait avec la volonté de \textbf{réduire l'overfitting}. L'idée est d'evaluer la performance sur des données indépendante, c'est à dire des données qui n'ont pas été utilisé lors de la construction du modèle.

  \paragraph{}
Il existe 4 techniques permettant de gerer les données pour la construction du modèles et une fois les modèles construit on regarde la différence entre les previsions attendues sur les données de test et les resultats effectivement obtenus à la sortie du modèle.

Les 4 methodes sont les suivantes:

$\rightarrow$ \textbf{Holdout method}: Avec les données à notre disposition, on divise l'ensemble de ces données en deux : on définis un \textcolor{red}{training set} (\textit{utilisé pour la construction du modèle}) et un \textcolor{red}{validation set} (\textit{utilisé pour tester le modèles}). Les données du validation set sont des observations "sacrifiée" à la verification.

$\rightarrow$ \textbf{Cross Validation}: On divise les données en k groupes de taille égale et on choisi un des groupes comme \textcolor{red}{validation set} et les autres comme \textcolor{red}{training set}. On recommence l'operation k fois, une fois par groupe. 

On calcul dans les deux methodes l'erreur quadratique moyenne, et dans le cas de la Cross-Val, on fait la moyenne des k erreurs.

$\rightarrow$ \textbf{Leave-one-out}: Comme pour la cross-validation mais on divise les données en k groupes de 1 données. 

$\rightarrow$ \textbf{Bootstrap}: On selectionne une donnée aleatoirement et on l'ajoute au training set. Les données peuvent être selectionné plusieurs fois. 

Une version très utilisé du bootstrap est le bootstrap .632, dans lequel on effectue n fois une selection aleatoire,  où n est le nombre de données.
Toute les données qui ne sont pas dans le training set (qui representeront 1-63.2\% des données) formeront le validation set.
Et on repete l'operation k fois.

\end{enumerate}

\end{document}
