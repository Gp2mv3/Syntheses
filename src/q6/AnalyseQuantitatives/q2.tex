\documentclass[a4paper, 11pt, onecolumn]{article}

\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage[margin=2cm]{geometry}
\usepackage{framed}
\usepackage{color}


\title{Analyse de données quantitative\\Question 2}
\date{}

\begin{document}

\maketitle

\textit{Le cadre de la classification supervisée, qu’est-ce qu’un modèle d’arbre de décision ? Décrivez en détail un algorithme permettant de construire un arbre de décision à partir d’un ensemble de données. Expliquez également comment estimer les performances d’un modèle de classification (cross-validation, etc) et en quoi cela est important.}

\begin{enumerate}

  \item \textbf{Expliquer rapidement ce qu'est la classification supervisée} 

  On possede un \textbf{ensemble de données} avec 
  
  \begin{enumerate}
    \item {une \textbf{variable dépendante} dont on aimerait pouvoir prévoir l'apparition}
    \item {et des \textbf{variables explicative} qui nous serviront à expliquer (prévoir) la variable dépendante.}
  \end{enumerate}
  
  Cet ensemble est donc \textbf{déscriptif} \textit{puisqu'il décrit une situation observée}, et l'on aimerait qu'il devienne un ensemble\textbf{ predictif} \textit{pour prédire la realisation de situations.}

Pour cela, on va essayer de répartir la variable dépendante, dans différentes classes.

\begin{framed}
  \begin{description}
    \item[Une classe] : Groupement d'observation apparaissans sous des
      conditions semblables.
    \item[Un modèle de classification ] : Routine permettant d'associer une observation
      à une classe.
    \item[Training set ] : Quantité d'observation de base qui vont pouvoir nous aider à 
      généraliser d'autre cas.
    \end{description}
  \end{framed}

  Le but de la \textbf{classification supervisé} est donc de trouver un modèle
  pour pouvoir établir une prédiction sur base de certaines variables. 
  Pour cela, nous utiliserons un \textbf{training set}.

\paragraph{}\textit{Exemple d'utilisation:}
\begin{itemize}
\item Reconnaitre la voix d'une personne (avec comme variable
explicative: la vitesse, la frequence).

\item Prevoir ce qui dans un produit attire un client (sur base des couleurs,
de formes, et aussi des données personelles au client)
\end{itemize}

\item \textbf{Qu'est ce qu'un arbre de decision}

\begin{description}
  \item[Arbre] : Matéhmatiquement un arbre est un graphe orienté, acyclique et connexe. Il possède des noeuds qui possède un seul parent (\textit{Except le noeud ``racine''}),
    et un ou plusieurs sous noeuds (\textit{Except pour les noeuds ``feuilles}).
\end{description}

\item \textbf{Construction}

  On va diviser les données à chaque noeud de l'arbre. 
  Toutefois, il faut décider \textbf{Comment} diviser les données 
  (\textit{Quel variable utilisé pour les chaque niveau?}), et \textbf{jusqu'a quand} diviser
  les données (\textit{Toute les variables doivent être utilisé ou peut ou s'arreter
  à un moment?}).

  La technique de construction expliquée ici est une methode \textbf{"gloutonne"} 
  (greedy) (\textit{un algorithme greedy est un algorithme qui recherche des maximums locaux afin d'arriver à un maximum global}).

\begin{enumerate}
\item \textbf{Il faut déterminer comment diviser les données}

  Pour cela, il faut une mesur de \textbf{l'impureté du noeud} où l'on va effectuer
  la division.

Il existe 4 techniques pour determiner l'impurete d'un noeud:
\begin{itemize}
\item Gini Index
\item Entropy
\item Misclassification Error
\item Chi-square
\end{itemize}

Dans les 4 techniques, le calcul de l'impurete permet de savoir l'interet en terme d'information que va apporter la division. 

\textit{Un exemple simple, est le cas où la division répartit de facon uniforme les données entre tout les sous-noeuds, on sait alors que la division que l'on viens d'effectuer ne nous apporte AUCUNE information.}

Il faut donc \textbf{maximiser le gain d'information apporté}, et selectionner la division qui apporte le plus de gain.

\item \textbf{Il faut déterminer quand stopper la division}

  Trois critère pour arrêter d'étendre l'arbre (\textit{c'est à dire rajouter des sous-noeuds avec des divisions supplementaire}). 
\begin{itemize}
\item Toute les données du noeuds appartiennent à la même classe.
\item Toute les données du noeuds ont des données qui se ressemble
\item Un nombre prédéfinis de noeuds ou de données par noeud a été atteint.
\end{itemize}

Une fois l'arbre construit, on peut representer chaque noeud comme etant une \textbf{regle de classification} (exemple: \textit{\textsc{IF} poisson possede une longueur 15 m \textsc{THEN} requin})
\end{enumerate}


\item \textbf{Importance de calculer la performance d'un modele}

  \begin{description}
    \item{ Il est important de pouvoir évaluer la \textbf{performance d'un modele}, afin de pouvoir choisir quel modèle doit être utiliser pour une situation donnée.
      En effet, certains modèles fonctionnent mieux dans certaines conditions 
      (\textit{certain marchent mieux avec beaucoup de données, d'autre avec des données de types numérique, ...}). }

    \item {Il est aussi important de pouvoir evaluer la \textbf{complexité d'un modèle}. 
      Si un modele est trop précis, il répondra mal à l'entrée de nouvelles donnée (appellé \textbf{l'overfitting}). A l'inverse, si un modele est trop peu précis, il ne nous apportera aucune information (appellé l'underfitting).}
  \end{description}

\item \textbf{Comment calculer la performance d'un modele}

  Le calcul de performance apparait avec la volonté de \textbf{réduire l'overfitting}. L'idée est d'evaluer la performance sur des données indépendante, c'est à dire des données qui n'ont pas été utilisé lors de la construction du modèle.

  \paragraph{}
Il existe 4 techniques permettant de gerer les données pour la construction du modèles et une fois les modèles construit on regarde la différence entre les previsions attendues sur les données de test et les resultats effectivement obtenus à la sortie du modèle.

Les 4 methodes sont les suivantes:

$\rightarrow$ \textbf{Holdout method}: Avec les données à notre disposition, on divise l'ensemble de ces données en deux : on définis un \textcolor{red}{training set} (\textit{utilisé pour la construction du modèle}) et un \textcolor{red}{validation set} (\textit{utilisé pour tester le modèles}). Les données du validation set sont des observations "sacrifiée" à la verification.

$\rightarrow$ \textbf{Cross Validation}: On divise les données en k groupes de taille égale et on choisi un des groupes comme \textcolor{red}{validation set} et les autres comme \textcolor{red}{training set}. On recommence l'operation k fois, une fois par groupe. 

On calcul dans les deux methodes l'erreur quadratique moyenne, et dans le cas de la Cross-Val, on fait la moyenne des k erreurs.

$\rightarrow$ \textbf{Leave-one-out}: Comme pour la cross-validation mais on divise les données en k groupes de 1 données. 

$\rightarrow$ \textbf{Bootstrap}: On selectionne une donnée aleatoirement et on l'ajoute au training set. Les données peuvent être selectionné plusieurs fois. 

Une version très utilisé du bootstrap est le bootstrap .632, dans lequel on effectue n fois une selection aleatoire,  où n est le nombre de données.
Toute les données qui ne sont pas dans le training set (qui representeront 1-63.2\% des données) formeront le validation set.
Et on repete l'operation k fois.


\end{enumerate}
\end{document}
