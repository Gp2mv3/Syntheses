\documentclass[a4paper, 11pt, onecolumn]{article}

\usepackage[french]{babel}
\usepackage{color}
\usepackage[utf8]{inputenc}
\usepackage[margin=2cm]{geometry}
\usepackage{framed}


\title{Analyse de données quantitative\\Question 1}
\date{}

\begin{document}

\maketitle

\textit{Décrivez en détail ce qu’est un modèle de type «régression logistique»: forme du modèle,surface de séparation,estimation des paramètres et interprétation des coefficients. Expliquez également comment estimer les performances d’un modèle de classification (cross-validation,etc) et en quoi cela est important.}

\begin{enumerate}

\item \textbf{Expliquer rapidement ce qu'est la classification supervisée} 

  On possede un \textbf{ensemble de données} avec 
  
  \begin{enumerate}
    \item {une \textbf{variable dépendante} dont on aimerait pouvoir prévoir l'apparition}
    \item {et des \textbf{variables explicative} qui nous serviront à expliquer (prévoir) la variable dépendante.}
  \end{enumerate}
  
  Cet ensemble est donc \textbf{déscriptif} \textit{puisqu'il décrit une situation observée}, et l'on aimerait qu'il devienne un ensemble\textbf{ predictif} \textit{pour prédire la realisation de situations.}

Pour cela, on va essayer de répartir la variable dépendante, dans différentes classes.

\begin{framed}
  \begin{description}
    \item[Une classe] : Groupement d'observation apparaissans sous des
      conditions semblables.
    \item[Un modèle de classification ] : Routine permettant d'associer une observation
      à une classe.
    \item[Training set ] : Quantité d'observation de base qui vont pouvoir nous aider à 
      généraliser d'autre cas.
    \end{description}
  \end{framed}

  Le but de la \textbf{classification supervisé} est donc de trouver un modèle
  pour pouvoir établir une prédiction sur base de certaines variables. 
  Pour cela, nous utiliserons un \textbf{training set}.

\paragraph{}\textit{Exemple d'utilisation:}
\begin{itemize}
\item Reconnaitre la voix d'une personne (avec comme variable
explicative: la vitesse, la frequence).

\item Prevoir ce qui dans un produit attire un client (sur base des couleurs,
de formes, et aussi des données personelles au client)
\end{itemize}
\item \textbf{Regression}

  \begin{description}
    \item[La regression logistique] estime immédiatement la probabilité a posteriori qu'une observation appartiennent à une classe. La regression logistique va séparé les données par des hyperplans (dans l'espace des données). Cette méthode fonctionne autant avec des valeurs \textbf{numériques} que \textbf {catégorielles}.
  \end{description}

On va définir un vecteur de paramètre pour chaque classe avec $q$ le nombres de classe et $p$ le nombre de variables.

$$W_k = [\omega_{0k}, \omega_{1k}, ..., \omega_{pk}]^T$$

On va aussi rajouter un biais à chaque observation $x$, et redefinir ainsi le vecteur des observations.
\begin{description}
  \item {Note : \textit{Ce biais est ajouté pour que la nullité d'une des variables dans une observation ne rende pas les résultats incohérent.}}
\end{description}

$$x' = [1, x_1, x_2, ..., x_p]^T$$

On considerera alors $[W_k-W_l]^T x'$ comme etant un hyperplan séparant deux classes $l$ et $k$.

La regression logistique va donc essayer d'estimer la probabilité a posteriori.

$$P(\omega_k|x) \approx \widehat{y}_k(x) = \frac{exp(W_k^Tx')}{\sum_{j=1}^q exp(W_j^Tx')}$$

Avec $\widehat{y}_k(x) \in [0;1]$ et $\sum_{j=1}^q \widehat{y}_k(x) = 1$. On va donc arriver à estimer ces hyperplans par la formule suivante.

$$log(\frac{P(\omega_k|x)}{P(\omega_l|x)}) \approx [W_k-W_l]^T x'$$

On dit qu'une estimation appartient à une classe $k$ si avec $l \neq k$

\begin{eqnarray}
	\widehat{y}_k(x) &>& \widehat{y}_l(x) \\
	\frac{exp(W_k^Tx')}{\sum_{j=1}^q exp(W_j^Tx')} &>& \frac{exp(W_l^Tx')}{\sum_{j=1}^q exp(W_j^Tx')} \\
	exp(W_k^Tx') &>& exp(W_l^Tx') \\
	W_k^Tx' &>& W_l^Tx' \\
	(W_k - W_l)^T x' &>& 0
\end{eqnarray}

On retrouve ici l'hyperplan passant par l'origine. Mais comment estime t'on le vecteur $W_k$? Pour cela on va utiliser le maximum de vraissemblance.

Soit un training set $\{x_i, y_i, i: 1, ..., n\}$, avec $x_i$ le vecteur des observations et $y_i$ les vrais classes des membres.

$$L(x_1, ..., x_n; y_1, ..., y_n) = \prod_{i=1}^n P(x_i, y_i) = \prod_{i=1}^n P(y_i|x_i) P(x_i)$$

On va réécrire cette formule

\begin{eqnarray}
	L(x_1, ..., x_n; y_1, ..., y_n) &=& \prod_{i=1}^n P(y_i|x_i) P(x_i)\\
	&=& \prod_{i=1}^n P(y_i|x_i) * \prod_{i=1}^n P(x_i) \\
	&=& \prod_{i=1}^n P(x_i) * \prod_{i=1}^n \prod_{k=1}^q \{P(y_i|x_i)\}^{y_k(x_i)} \\
&=& \prod_{i=1}^n P(x_i) * \prod_{i=1}^n \prod_{k=1}^q \{\widehat{y}_k(x_i)\}^{y_k(x_i)} \\
&\propto& \prod_{i=1}^n \prod_{k=1}^q \{\widehat{y}_k(x_i)\}^{y_k(x_i)}
\end{eqnarray}

(Je veux confirmation de l'explication qui va suivre)Pour passer de la ligne (9) à (10) on enleve $P(x_i)$ et le calcul reste proportionnel.

Une fois que l'on arrive à cette étape on va simplifier l'expression en prennant son logarithme.

$$log L = \sum_{i=1}^n \sum_{k=1}^q y_k(x_i)ln(\widehat{y}_k(x_i))$$

Cette fonction est strictement concave en terme de $W$ et ne possede qu'un seul maximum global. Nous allons utiliser un algorithme se basant sur le gradient pour trouver ce maximum. 

$$W_{ik} \leftarrow W_{ik} + \Delta  W_{ik}$$

Avec

$$\Delta  W_{ik} = \eta \frac{\partial log L}{\partial W_{ik}}$$

Où $\eta$ est optimisé à chaque itération. Une fois que l'algorithme a trouve le maximum, on stop l'iteration. Cet algorithme nous assure de pouvoir trouver ce maximum.

Une dernière remarque moyennement interessant, le modele est invariant aux translations, on peut rajouter des constantes à tout les vecteurs $W_k$, cela ne change pas le modèle.

\item \textbf{Importance de calculer la performance d'un modele}

  \begin{description}
    \item{ Il est important de pouvoir évaluer la \textbf{performance d'un modele}, afin de pouvoir choisir quel modèle doit être utiliser pour une situation donnée.
      En effet, certains modèles fonctionnent mieux dans certaines conditions 
      (\textit{certain marchent mieux avec beaucoup de données, d'autre avec des données de types numérique, ...}). }

    \item {Il est aussi important de pouvoir evaluer la \textbf{complexité d'un modèle}. 
      Si un modele est trop précis, il répondra mal à l'entrée de nouvelles donnée (appellé \textbf{l'overfitting}). A l'inverse, si un modele est trop peu précis, il ne nous apportera aucune information (appellé l'underfitting).}
  \end{description}

\item \textbf{Comment calculer la performance d'un modele}

  Le calcul de performance apparait avec la volonté de \textbf{réduire l'overfitting}. L'idée est d'evaluer la performance sur des données indépendante, c'est à dire des données qui n'ont pas été utilisé lors de la construction du modèle.

  \paragraph{}
Il existe 4 techniques permettant de gerer les données pour la construction du modèles et une fois les modèles construit on regarde la différence entre les previsions attendues sur les données de test et les resultats effectivement obtenus à la sortie du modèle.

Les 4 methodes sont les suivantes:

$\rightarrow$ \textbf{Holdout method}: Avec les données à notre disposition, on divise l'ensemble de ces données en deux : on définis un \textcolor{red}{training set} (\textit{utilisé pour la construction du modèle}) et un \textcolor{red}{validation set} (\textit{utilisé pour tester le modèles}). Les données du validation set sont des observations "sacrifiée" à la verification.

$\rightarrow$ \textbf{Cross Validation}: On divise les données en k groupes de taille égale et on choisi un des groupes comme \textcolor{red}{validation set} et les autres comme \textcolor{red}{training set}. On recommence l'operation k fois, une fois par groupe. 

On calcul dans les deux methodes l'erreur quadratique moyenne, et dans le cas de la Cross-Val, on fait la moyenne des k erreurs.

$\rightarrow$ \textbf{Leave-one-out}: Comme pour la cross-validation mais on divise les données en k groupes de 1 données. 

$\rightarrow$ \textbf{Bootstrap}: On selectionne une donnée aleatoirement et on l'ajoute au training set. Les données peuvent être selectionné plusieurs fois. 

Une version très utilisé du bootstrap est le bootstrap .632, dans lequel on effectue n fois une selection aleatoire,  où n est le nombre de données.
Toute les données qui ne sont pas dans le training set (qui representeront 1-63.2\% des données) formeront le validation set.
Et on repete l'operation k fois.

\end{enumerate}

\end{document}
