\documentclass[a4paper, 11pt, onecolumn]{article}

\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage[margin=2cm]{geometry}
\usepackage{float}
\usepackage{pict2e}
\usepackage{framed}
\usepackage{fourier-orns}
\usepackage{color}

\title{Analyse de données quantitative\\Question 11}
\date{}

\begin{document}

\maketitle


\textit{Décrivez le fonctionnement du classifieur Bayesien naif et dérivez la formule qui est appliquée pour catégoriser les données. Décrivez également l’algorithme de classification par «k plus proches voisins». Expliquez enfin comment estimer les performances d’un modèle de classification (cross-validation, etc) et en quoi cela est important.}

\begin{enumerate}
\item \textbf{Classifieur Bayesien naif}

  Le \textbf{modèle bayesien} calcule les probabilité d'appartenance à une classe à posteriori. Cette technique se base sur le théorème de Bayes :
\begin{framed}
$$P(\omega_k|x)=\frac{P(x|\omega_k)P(\omega_k)}{P(x)}$$
Avec 

\begin{tabular}{ll}
$x$ & un vecteur d'observation\\
$\omega_k$ & une classe\\
$P(\omega_k|x)$ & la probabilité d'appartenir à une classe $\omega_k$ sachant que $x$ a ete observe\\
$P(\omega_k)$ & la probabilité d'appartenir à une classe $\omega_k$\\
$P(x)$ & la probabilité d'observer $x$ (on va le supposer constant pour chaque classe)\\
$P(x|\omega_k)$ & la probabilité d'observer $x$ sachant que cette observation appartient à $\omega_k$
\end{tabular}
\end{framed}

\danger Pour notre calcul, on va supposer que les variables n'ont pas de \textbf{relation de dépendance} entre elles.

\begin{framed}
On passe de la ligne 1 à 2 en supprimant le $P(x)$ constant pour toute les observations. On utilise des sommes à la place d'une multiplication pour eviter l'annulation si une probabilité est nulle.
\begin{eqnarray}
P(\omega_k|x)&=&\frac{P(x|\omega_k)P(\omega_k)}{P(x)}\\
&=&P(x|\omega_k)P(\omega_k)\\
P(x|\omega_k)&=& \prod_{i=1}^p P(x_i|\omega_k)\\
log[P(x|\omega_k)]&=& \sum_{i=1}^p P(x_i|\omega_k)
\end{eqnarray}
\end{framed}

$P(\omega_k)$ se calcul en regardant le nombres d'éléments dans $\omega_k$ sur la totalité des observations.
\begin{itemize}
  \item Si $x_i$ est \textbf{catégorielle} alors $P(x_i=x|\omega_k)$ est le nombre d'elements dans $\omega_k$ qui ont $x_i=x$ sur le nombre d'éléments dans $\omega_k$
  \item Si $x_i$ est \textbf{continue} alors $P(x_i=x|\omega_k)$ peut etre calculé sur base de la densité paramétrique (\textbf{CLARRIFIER}). Un exemple serait l'usage d'une distribution gaussienne $P(x_i|\omega_k)=g(x_i, \mu_k, \sigma_k)$ avec $g(x,\mu,\sigma)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
\end{itemize}

\item \textbf{K plus proche voisins}

  \begin{description}
    \item [La méthode des "k-nearest neighbour"] utilise la proximité d'une observation aux différentes observations d'entrainement pour estimer l'appartenance d'une observation à une classe. 
    \item{On fixe un k et on prends les k observations dont la distance à l'observation que l'on chercher à classier est la plus faible. }
  \end{description}

  \danger au k que l'on choisis : k \textbf{trop petit} veut dire une sensibilité excessive au bruit et k \textbf{trop large} inclu des points d'autres classes.

  \paragraph{Mais comment évalue-t-on la distance d'un élément à un autre?}
  \begin{enumerate}
    \item {On peut utiliser simplement la distance euclidienne $d(x,y)=\sqrt{\sum_{i=1}^nx_i^2-y_i^2}$.}
    \item {On peut aussi poser un poids pour que les éléments les plus éloigné ai moins d'impact dans la décision en posant $w = 1/d^2$.}
    \item {Enfin on peut estimer la probabilité à posteriori comme etant la proportion de représentation de chaque classe parmis les plus proche voisins.}
  \end{enumerate}

\danger Il faut aussi mettre tout a proportion pour pouvoir comparer ce qui est comparable et que chaque variable influe sur la distance de facon égale.

\textbf{Note:}Le classifieur KNN ne construit pas vraiment de modèle de classification.

\item \textbf{Estimation des performances}

  Le calcul de performance apparait avec la volonté de \textbf{réduire l'overfitting}. L'idée est d'evaluer la performance sur des données indépendante, c'est à dire des données qui n'ont pas été utilisé lors de la construction du modèle.

  \paragraph{}
Il existe 4 techniques permettant de gerer les données pour la construction du modèles et une fois les modèles construit on regarde la différence entre les previsions attendues sur les données de test et les resultats effectivement obtenus à la sortie du modèle.

Les 4 methodes sont les suivantes:

$\rightarrow$ \textbf{Holdout method}: Avec les données à notre disposition, on divise l'ensemble de ces données en deux : on définis un \textcolor{red}{training set} (\textit{utilisé pour la construction du modèle}) et un \textcolor{red}{validation set} (\textit{utilisé pour tester le modèles}). Les données du validation set sont des observations "sacrifiée" à la verification.

$\rightarrow$ \textbf{Cross Validation}: On divise les données en k groupes de taille égale et on choisi un des groupes comme \textcolor{red}{validation set} et les autres comme \textcolor{red}{training set}. On recommence l'operation k fois, une fois par groupe. 

On calcul dans les deux methodes l'erreur quadratique moyenne, et dans le cas de la Cross-Val, on fait la moyenne des k erreurs.

$\rightarrow$ \textbf{Leave-one-out}: Comme pour la cross-validation mais on divise les données en k groupes de 1 données. 

$\rightarrow$ \textbf{Bootstrap}: On selectionne une donnée aleatoirement et on l'ajoute au training set. Les données peuvent être selectionné plusieurs fois. 

Une version très utilisé du bootstrap est le bootstrap .632, dans lequel on effectue n fois une selection aleatoire,  où n est le nombre de données.
Toute les données qui ne sont pas dans le training set (qui representeront 1-63.2\% des données) formeront le validation set.
Et on repete l'operation k fois.


\end{enumerate}


\end{document}
