\documentclass[fr]{../../../../../../eplexam}

\usepackage{booktabs}
\usepackage{csquotes}

\hypertitle{Probabilités et statistiques II}{5}{BIR}{1304}{2011}{Août}{All}
{Florian Thuin\and Paul-Henri Callewaert \and François Duchêne}
{Patrick Bogaert}

\section{}

Un agriculteur possède un champ carré de longueur $\mu$, dont il désire estimer la surface. Pour cela, il effectue 2 mesures indépendantes $X_{1}$ et $X_{2}$ de la longueur de son champs telles que ces mesures suivent une loi normale d'espérance $\mu$ et de variance $\sigma^{2}$. Pour estimer la surface, plusieurs possibilités s'offrent à lui. Il peut faire la moyenne des mesures et l'élever au carré, ou bien il peut élever les mesures au carré et prendre leur moyenne. Une troisième solution revient à multiplier les 2 mesures. Les trois estimateurs correspondants sont les suivants :



  \[
   \hat{\theta_{1}} = \frac{{(X_{1} + X_{2})}^{2}}{4}
  \]

  \[
   \hat{\theta_{2}} = \frac{(X_{1}^{2} + X_{2}^{2})}{2}
  \]

  \[
   \hat{\theta_{3}} = X_{1} \times X_{2}
  \] \bigskip

\begin{solution}
  Calcul du biais du paramètre $\hat{\theta_{1}}$ :

  \[
   E[\hat{\theta_{1}}] = E\left[\frac{{(X_{1} + X_{2})}^{2}}{4}\right]
  \]
  \[
   = \frac{1}{4} \times E\left[{(X_{1} + X_{2})}^{2}\right]
  \]
  \[
   = \frac{1}{4} \times E[X_{1}^{2} + 2 X_{1} X_{2} + X_{2}^{2}]
  \]
  \[
   = \frac{1}{4} \times (E[X_{1}^{2}] + E[2 X_{1} X_{2}] + E[X_{2}^{2}])
  \]
  \[
   = \frac{1}{4} \times (E[X_{1}^{2}] - E^{2}[X_{1}] + E^{2}[X_{1}] + E[2 X_{1} X_{2}] + E[X_{2}^{2}] - E^{2}[X_{2}] + E^{2}[X_{2}])
  \]
  \[
   = \frac{1}{4} \times (\sigma^{2} + E^{2}[X_{1}] + E[2 X_{1} X_{2}] + \sigma^{2} + E^{2}[X_{2}])
  \]
  \[
   = \frac{1}{4} \times (\sigma^{2} + \mu^{2} + E[2 X_{1} X_{2}] + \sigma^{2} + \mu^{2})
  \]

  Puisque les 2 mesures sont indépendantes :
  \[
   = \frac{1}{4} * (\sigma^{2} + \mu^{2} + 2* E[X_{1}] * E[X_{2}] + \sigma^{2} + \mu^{2})
  \]
  \[
   = \frac{1}{4} * (\sigma^{2} + \mu^{2} + 2* \mu * \mu + \sigma^{2} + \mu^{2})
  \]
  \[
   = \frac{1}{4} * (\sigma^{2} + \mu^{2} + 2* \mu^{2} + \sigma^{2} + \mu^{2})
  \]
  \[
   = \mu^{2} + \frac{\sigma^{2}}{2}
  \]

  Le biais est donc de $\frac{\sigma^{2}}{2}$


  \bigskip

  Calcul du biais du paramètre $\hat{\theta_{2}}$ :

   \[
   E[\hat{\theta_{2}}] = E\left[\frac{X_{1}^{2} + X_{2}^{2}}{2}\right]
  \]
  \[
   = \frac{1}{2} \times E[X_{1}^{2} + X_{2}^{2}]
  \]
  \[
   = \frac{1}{2} \times (E[X_{1}^{2}] + E[X_{2}^{2}])
  \]
  \[
   = \frac{1}{2} \times (E[X_{1}^{2}] - E^{2}[X_{1}] + E^{2}[X_{1}] + E[X_{2}^{2}] - E^{2}[X_{2}] + E^{2}[X_{2}])
  \]
  \[
   = \frac{1}{2} \times (\sigma^{2} + E^{2}[X_{1}] + \sigma^{2} + E^{2}[X_{2}])
  \]
  \[
   = \frac{1}{2} \times (\sigma^{2} + \mu^{2} + \sigma^{2} + \mu^{2})
  \]
  \[
   = \frac{1}{2} \times (2 *\sigma^{2} + 2 * \mu^{2})
  \]
  \[
   = \sigma^{2} + \mu^{2}
  \]

  Le biais est donc $\sigma^{2}$
  \bigskip

  Calcul du biais du paramètre $\hat{\theta_{1}}$ :

  \[
   E[\hat{\theta_{1}}] = E[X_{1} X_{2}]
  \]
  \[
   = E[X_{1}] \times E[X_{2}] + \textrm{Cov}[X_{1} X_{2}]
  \]

  Puisque les deux observations sont indépendantes, la corrélation vaut zéro.
  \[
   = \mu^{2}
  \]

  Cet estimateur est sans biais.

\end{solution}

\section{}

  Un chercheur étudie l'effet d'un raccourcisseur de paille sur les céréales. Un raccourcisseur de paille est une molécule, fort utilisée en agriculture, qui agit sur la croissance de la plante afin de limiter son développement en hauteur. Dans une expérience, il étudie la différence entre la hauteur des plantes réparties entre 2 groupes. Le premier groupe n'est pas traité et sert de témoin. Le second groupe est traité à l'aide du produit. A la fin de la période de croissance, le chercheur a mesuré la hauteur (en mètres) de quelques plantes choisies au hasard dans chaque groupe. Voici ses résultats : \bigskip

  \begin{center}
  \begin{tabular}{@{}lcccccccc@{}}
      \toprule
      \toprule
      \textbf{Plante n\textdegree} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
      \midrule
      \textbf{Témoin} & 1.37 & 1.01 & 1.36 & 1.48 & 1.34 & 1.46 & 1.21 & 1.43 \\
      \textbf{Traités} & 1.21 & 1.00 & 1.14 & 1.33 & 1.07 & 1.10 & 1.04 & 1.28 \\
      \bottomrule
      \bottomrule
  \end{tabular}
  \end{center}

  \begin{enumerate}
   \item Donnez un intervalle de confiance à la hauteur moyenne d'une plante non traitée.
   \item La variance de la hauteur peut-elle être considérée comme identique entre les plantes témoins et les plantes traitées ?
   \item Le traitement induit-il une diminution de la taille des plantes ? Justifiez.
  \end{enumerate}

  Pour chacun des tests et intervalles de confiance, considérez le niveau de confiance $1 - \alpha = 0.95$.

\begin{solution}
    \begin{enumerate}
  \item Pour la hauteur moyenne dans un groupe, on est dans le cas où on cherche une moyenne avec une variance inconnue.

  \[
   \mu \in \left[\overline{X} \pm t^{(n-1)}_{1-\alpha/2} \times \sqrt{\frac{s^{2}}{n}}\right]
  \]

  \[
   \overline{X} = \frac{1}{n} \sum_{t=1}^{N} X_{i}
  \]
  \[
   = \frac{1}{8} \times 10,66 = 1,3325
  \]

  \[
   s^{2} = \frac{1}{(n-1)} \times \sum_{t=1}^{N} {\left(X_{i} - \overline{X}\right)}^{2}
  \]
  \[
   s^{2} = \frac{1}{7} \times 0,16875 = 0,024
  \]
  \[
   t^{7}_{0,975} = 2,365
  \]
  \[
   \mu \in \left[1,3325 \pm 2,365 \times \sqrt{\frac{0,024}{8}}\right]
  \]
  \[
   \mu \in \left[1,203;1,462\right]
  \]

  \item Pour que la variance de la hauteur des plantes traitées soit considérée identique à celle des plantes non-traitées, il faut que, $H_{0} : \frac{\sigma_{2}^{2}}{\sigma_{1}^{2}} = \gamma_{0}$ où $\gamma_{0} = 1$ dans notre cas.

  Considérons le problème de test comme étant,
  
  \begin{align*}
  	 H_{0} &\equiv \frac{\sigma_{2}^{2}}{\sigma_{1}^{2}} = \gamma_{0} = 1 \\
  	 H_{1} &\equiv \frac{\sigma_{2}^{2}}{\sigma_{1}^{2}} \neq \gamma_{0}
  \end{align*}


  On calcule que,

	\[
	n_{1} = n_{2} = 8,\ \overline{X}_{1} = 1,33625,\ \overline{X}_{2} = 1,14625
	\]
	\[
	S^{2}_{1} = \frac{1}{(n-1)} \times \sum_{t=1}^{N} {\left(X_{i} - \overline{X}\right)}^{2} = \frac{1}{7} \times 0,16875 = 0,02411
	\]
	\[
	S^{2}_{2} = \frac{1}{(n-1)} \times \sum_{t=1}^{N} {\left(X_{i} - \overline{X}\right)}^{2} = \frac{1}{7} \times 0,0963875 = 0,013769
	\]

	On calcule la valeur observée de la statistique :

	\[
	F_{obs} = \frac{S^{2}_{1}}{S^{2}_{2}} = \frac{0,02411}{0,013769} = 1,75103
	\]

	Nous remarquons que $S^{2}_{1}>S^{2}_{2}$. Nous allons donc chercher, pour $\alpha=0,05$, le quantile d'ordre $1-\alpha$ dans la distribution de \textbf{Fisher-Snedecor} de paramètre (7, 7),

	\[
	F_{th} = F_{0,95}(7,7) = 3,787
	\]
	
	La statistique $F_{obs}$ étant considéré comme étant dans la région critique si jamais $F_{obs} \ge F_{th}$ est vérifié, nous remarquons ici que :
	
	\[
	1,751 < 3,787
	\]
	
	Il n'y a donc pas rejet de l'hypothèse $H_{0}$ pour $\alpha=0,05$. Les variances pourraient être considérées égales. On s'attend en effet à ce que $H_{0}$ soit vraie lorsque la valeur de $F_{obs}$ s'approche de 1.

	\item Comme nous pouvons considérer la possibilité que les variances sont peut-être égales, nous pouvons effectuer un second test d'hypothèse sur les moyennes des deux échantillons. Nous supposons alors que $\sigma_{1}^2 = \sigma_{2}^2 = \sigma^2$.
	
	Considérons le test d'hypothèse suivant,
	
	\begin{align*}
		H_0 &\equiv \mu_1 = \mu_2 &\Leftrightarrow& &\mu_1 - \mu_2 &= d_0 = 0\\
		H_1 &\equiv \mu_1 > \mu_2 &\Leftrightarrow& &\mu_1 - \mu_2 &> d_0
	\end{align*}

	Comme nous ne connaissons pas la variance $\sigma^2$, nous allons utiliser la loi de \textbf{Student} afin de calculer notre statistique $T$ tel que :
	
	\[
	T_{obs} = \frac{\overline{X}_1 - \overline{X}_2 - d_0}{\sqrt{S^{2}_P (\frac{1}{n_1} + \frac{1}{n_2})}}
	\]
	
	Pour calculer $S^{2}_P$, nous utilisons la formule de combinaison de variance,
	
	\[
	S^{2}_{Pooled} = \frac{(n_1 - 1) S^{2}_1 + (n_2 - 1) S^{2}_2}{n_1 + n_2 - 2}
	\]
	
	\[
	S^{2}_P = \frac{(8 - 1) \times 0,02411 + (8 - 1) \times 0,013769}{14} = \frac{0,265153}{0,01894} = 0,01894
	\]
	
	Maintenant que nous avons notre variance combinée, nous pouvons calculer notre statistique $T$ :
	
	\[
	T_{obs} = \frac{1,33625-1,14625}{\sqrt{0,01894 \times (\frac{1}{8} + \frac{1}{8})}} = \frac{0,19}{0,06881} = 2,7612
	\]
	
	Nous pouvons maintenant calculer la statistique théorique pour une valeur de confiance $\alpha = 0,05$, c'est-à-dire le quantile d'ordre $1-\alpha$. 
	
	\[
	T_{th} = St^{0,95}_{14} = 1,761
	\]
	
	La région critique où on doit rejeter l'hypothèse nulle étant considérée comme étant $T_{obs} \geq T_{th}$, nous remarquons ici que :
	
	\[
	2,7612 > 1,761
	\]
	
	Nous pouvons donc rejeter l'hypothèse nulle.
	
	Si nous effectuons un deuxième test avec cette fois-ci une valeur de confiance de $\alpha = 0,01$, nous pouvons remarquer que :
	
	\[
	T_{th2} = St^{0,99}_{14} = 2,624
	\]
	Et donc,
	\[
	2,7612 > 2,624
	\]
	
	L'hypothèse nulle peut à nouveau être rejetée. Nous en concluons que le traitement a un effet significatif sur la diminution de la taille des plantes.
    \end{enumerate}

\end{solution}

\section{}
  Un scientifique fait des recherches sur l'échauffement des cellules lorsqu'elles sont soumises à des ondes électromagnétiques. Il a soumis des cellules à des ondes de fréquences croissantes et a obtenu les résultats suivants :

  \begin{center}
  \begin{tabular}{lcccccccc}
   \toprule
   \toprule
   Echauffement (mK) & 0.06 & 0.05 & 0.06 & 0.36 & 0.36 & 0.54 & 0.37 & 0.61 \\
   \midrule
   Fréquence (GHz) & 0.3 & 0.5 & 0.7 & 0.9 & 1.1 & 1.3 & 1.5 & 2 \\
   \bottomrule
   \bottomrule
  \end{tabular}
  \end{center}

  Un modèle linéaire sous forme de droite (pente + intercept) est envisagé pour décrire l'effet de la fréquence sur l'échauffement. \bigskip

  \begin{enumerate}
   \item Ecrivez ce modèle sous forme matricielle et estimez-en les paramètres.
   \item Calculer un intervalle de confiance pour la pente.
   \item D'après le modèle utilisé, la fréquence a-t-elle un impact sur l'échauffement des cellules ?
   \item Durant l'expérience, la puissance de l'onde a également été mesurée. En considérant une extension du modèle précédent sous forme d'un plan, le paramètre supplémentaire étant associé à la puissance, la SCR de ce nouveau modèle est de 0.05. Ce modèle est-il meilleur que le précedent ?
  \end{enumerate}

\begin{solution}
  On sait que la chaleur (variable $Y$) est dépendante de la fréquence (variable $X$). On sait également que le modèle est linéaire.
  
  Il s'agit donc d'une régression \emph{simple}, pouvant s'écrire tel que
  
  \[
  Y = a + b X + \epsilon
  \]
  
  avec $a$ et $b$ les deux paramètres de cette régression et $\epsilon$ l'erreur.

  \begin{enumerate}

  \item Le modèle peut être écrit sous forme matricielle
  
  De façon simpliste :
  \[
  Y = \beta \times X
  \]
  %%% Je vois pas beaucoup l'intérêt de la ligne suivante, s'agit il
  %\[
   %E[T] = E\left[\sum_{i=1}^{n} a_{i} X_{i}\right] = \sum_{i=1}^{n} a_{i} \times \underbrace{E[X_{i}]}_{\mu} = \underbrace{\sum_{i=1}^{n} a_{i}}_{1} \times \mu = \mu
  %\]
	De façon plus détaillée :
	\[
	\begin{bmatrix}
	    n       & \sum_{i=1}^{n} X_{i} \\
	    \sum_{i=1}^{n} X_{i} & \sum_{i=1}^{n} X_{i}^{2} \\
	\end{bmatrix}
	\times \begin{bmatrix}
	    a \\
	    b \\
	\end{bmatrix}
	=
	\begin{bmatrix}
	    \sum_{i=1}^{n} Y_{i} \\
	    \sum_{i=1}^{n} X_{i} Y_{i} \\
	\end{bmatrix}
	\]

	\[
	\begin{bmatrix}
	    8       & 8,3 \\
	    8,3 & 10,79 \\
	\end{bmatrix}
	\times \begin{bmatrix}
	    a \\
	    b \\
	\end{bmatrix}
	=
	\begin{bmatrix}
	    2,41 \\
	    3,282 \\
	\end{bmatrix}
	\]

	On calcule, $\overline{X} = 1,0375$, $\overline{Y} = 0,30125$, $\sum_{i=1}^{8} {(X_{i}-\overline{X})}^{2} = 2,17875$ et $\sum_{i=1}^{8} (X_{i}-\overline{X})(Y_{i}-\overline{Y}) = 0,76559$
	
	Nous pouvons maintenant calculer les estimations de $\widehat{b}$,
	\[
	\widehat{b} = \frac{\sum_{i=1}^{8} (X_{i}-\overline{X})(Y_{i}-\overline{Y})}{\sum_{i=1}^{8} {(X_{i}-\overline{X})}^{2}} = \frac{0,76559}{2,17875} = 0,35139
	\]
	\[
	\widehat{a} = \overline{Y}-\widehat{b} \times \overline{X} = -0,06332
	\]

	\item Nous calculons que
	\[
	S^{2} = \frac{\sum_{i=1}^{8} {(Y_{i}-\overline{Y})}^{2}}{n-2} = 0,0572
	\]
	Dans la table de distribution de \textbf{Student} de n-2 degrés de liberté, nous trouvons que $t_{0,975}^6=1,94318$.
	Et l'intervalle de confiance pour la pente ($b$) vaut
	\[
	\begin{bmatrix}
    \widehat{b}\pm t_{0,95;n-2}\sqrt{\frac{S^{2}}{\sum_{i=1}^{n} {(X_{i}-\overline{X})}^{2}}}
	\end{bmatrix}
	\]
	Donc,
	\[
	\begin{bmatrix}
    -0,045082; 0,7478621
	\end{bmatrix}
	\]

	\item Testons l'hypothèse nulle que \enquote{la fréquence a un impact sur l'échauffement des cellules}.\\
	On s'intéresse au problème de test défini par :

	\begin{eqnarray*}
	H_{0}: b & = & 0 \\
	H_{1}: b & \neq & 0
    \end{eqnarray*}

	La statistique de test est $T = \frac{\widehat{b}}{\sqrt{\frac{S^{2}}{\sum_{i=1}^{n} {(X_{i}-\overline{X})}^{2}}}}$
	avec laquelle nous pouvons calculer la valeur observée de cette statistique valant $T_{obs}=2,168678$

	Or, celle-ci est supérieur à $T_{th} = t_{0,975}^6 = 2,446912$ que nous avions trouvé précédemment.\\
	Comme $T_{th} > T_{obs}$, la statistique ne se trouve pas dans la région critique, et nous ne pouvons donc pas rejeter l'hypothèse nulle.

	\item
	!!! Ceci est une ébauche de la sous-question 4 !!!

	On s'intéresse au problème de test défini par :

	\begin{eqnarray*}
	H_{0}: \beta_{1} \neq \beta_{2} & \textrm{ou} & \alpha{1} \neq \alpha{1}\\
	H_{1}: \beta_{1} =    \beta_{2} & \textrm{et} & \alpha{1}  =   \alpha{1}
    \end{eqnarray*}

	La statistique de test pour éprouver $H_{0}$ est\\
	\[
	F=\frac{(SCR_{0}-SCR)/2}{SCR/(N-4)}
	\]

	On sait que $SCR_{2} = 0,05$\\
	On calcule que
	\[
		SCR_{1} = S_{1}^{2}*(n_{1}-2) = 0,3432
	\]

	\begin{eqnarray*}
		SRC     & = & 0,5+0,3432 =  0,3932 \\
		SRC_{0} & = & 2,139
	\end{eqnarray*}

	\[
	F_{obs}=26,6399
	\]

	\[
	F_{0,95}(2,12)=3,885\\
	\]

	On rejette donc l'hypothèse nulle au niveau significatif 0,05. On peut donc dire que le second modèle est meilleur que le premier.

    \end{enumerate}

\end{solution}

\end{document}
