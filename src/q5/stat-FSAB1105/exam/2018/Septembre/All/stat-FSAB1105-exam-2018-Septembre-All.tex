\documentclass[fr]{../../../../../../eplexam}
\usepackage{../../../../../../eplunits}

\hypertitle{Probabilité et Statistiques}{5}{FSAB}{1105}{2018}{Septembre}{All}
{Bac 3 2017-2018}
{Anouar El Ghouch}

\section{QCM (4 points)}
$+0.8$ pour une bonne réponse, $-0.2$ pour une mauvaise réponse et $0$ pour une abstention. Il y avait 5 questions (pas identiques pour tous les exemplaires de l'examen).
\begin{enumerate}
    \item Soit une fonction de densité donnée par
    \[ f(y_1,y_2)=k \]
    avec $0<y_1<1.3$, $0<y_2<1.3$, $0<y_1+y_2\le1.3$.
    Quelle est la valeur de $k$?

    \item Que dit la loi des grands nombres?
    \begin{enumerate}[label=\alph*.]
        \item On peut faire des tests sur la moyenne avec un grand échantillon.
        \item La moyenne suit une distribution normale lorsque l'échantillon est grand.
        \item L'espérance d'une distribution peut être approximée par la moyenne d'un échantillon lorsque cet échantillon est grand.
        \item 
        \item aucune réponse
    \end{enumerate}

    \item Si le coefficient de variation est nul,
    \begin{enumerate}[label=\alph*.]
        \item toutes les valeurs sont nulles,
        \item toutes les valeurs sont les mêmes,
        \item l'écart type est nul,
        \item b et c,
        \item aucune réponse.
    \end{enumerate}

    \item Soit la fonction de densité
    \[
        F_X(x) = \begin{cases}
                0                    & \quad \text{si } x < 0 \\
                \frac{3x^3}{4}       & \quad \text{si } 0 \le x < 1 \\
                \frac{3}{4}          & \quad \text{si } 1 \le x < 2 \\
                \frac{m^2 +32}{48}   & \quad \text{si } 2 \le x < 4 \\
                1                    & \quad \text{si } x \ge 4
            \end{cases}\quad,
    \]
    que vaut la médiane?

    \item Si j'effectue un test avec un seuil de signification $\alpha=0.05$ et que je rejette l'hypothèse $H_0$ pour un test unilatéral, cela signifie que:
    \begin{enumerate}[label=\alph*.]
        \item la \textit{p}-valeur est plus grande que $\alpha$,
        \item 
        \item je rejette $H_0$ pour un test bilatéral avec $\alpha=0.1$,
        \item je rejette $H_0$ pour un test bilatéral avec $\alpha=0.025$,
        \item je ne peux rien conclure pour le test bilatéral.
    \end{enumerate}
\end{enumerate}

\begin{solution}
    \begin{enumerate}
    \item On dessine la zone d'existence grâce aux conditions. Celle-ci est définie par le plan $y_1=0$, $y_2=0$ et la droite $y_2=1.3-y_1$.
        On a donc:
        \[ \int_0^{1.3} \int_0^{1.3-y_2} k \dif y_1 \: \dif y_2 = 1 \implies k=1.1834 \, .\]
    \item c

    \item d

    Par définition, le coefficient de variation est : 
    $$c_v = \frac{s}{\overline{x}}\, .$$
    C'est l'écart-type relatif (sans unité). Du coup, $s = c_v \overline{x} = 0$: l'écart-type est nul (réponse c). Par ailleurs, la variance est nulle aussi car c'est l'écart-type au carré. Comme il n'y a pas de variation, les valeurs sont toutes identiques (réponse b).
    \item On cherche $F(m)=0.5$, seul le cas où $0 \le x < 1$ est possible et cela donne: $\frac{3x^3}/4=0.5$. Du coup $m=0.87$.
    \item 
    \end{enumerate}
\end{solution}


\section{(4 points)}
\begin{enumerate}
    \item $X_k \sim \textrm{Po}\left(\lambda_k\right)$ où les $X_k$ sont iid avec $k = 1, \dots, K$. Montrez que : 
    $$T = \sum_{k = 1}^{K} X_k\sim \textrm{Po}\left(\sum_{k = 1}^{K} \lambda_k\right)$$
    Une question reposant sur l'application de la propriété de la somme des moments.
    \item Soit $X \sim \mathrm{Po}(100)$, trouvez $P(X>120)$.
    \item Si $X \sim \mathrm{Po}(\lambda)$ et $Y|X=x \sim \mathrm{Bin}(x,p)$, prouvez que $Y\sim \mathrm{Po}(p\lambda)$.
\end{enumerate}

\begin{solution}
 \begin{enumerate}
     \item La fonction génératrice de moments de \( X_k \) vaut \( m_{g,X_k}(t) = \exp\left(\lambda_k(e^t-1)\right) \). On calcule la fonction génératrice de moments de \( T \) :
     \begin{align*}
      m_{g,T}(t) & = \mathbb{E}\left[\exp(tT)\right] = \mathbb{E}\left[\exp\left(t\sum X_k\right)\right] = \prod_k \underbrace{\mathbb{E}\left[\exp(t X_k)\right]}_{m_{g,X_k}(t)} = \prod_k \exp\left(\lambda_k(e^t-1)\right)\\
      & = \exp\left(\left(\sum_k \lambda_k\right)(e^t-1)\right)
     \end{align*}

     en utilisant le fait que pour des VA iid, l'espérance d'un produit est égal au produit des espérances. Ce résultat n'est autre que la fonction génératrice de moments d'une distribution de Poisson de paramètre \( \sum_k \lambda_k \). Par équivalence entre distribution et fonction génératrice de moments, on peut donc affirmer que 
     \[ T \sim \textrm{Po}\left(\sum_{k = 1}^{K} \lambda_k\right) \]
     \item $P(X>120) = 1 - P(X \leqslant 120) = 1 -$ cdfPoisson($ \lambda$ = 100, start=0, end= 120) $=0.02267$
     \item Distribution conditionelle :
     \begin{align*}
	P(Y=y | X=x) &= \frac{p(x,y)}{p_x(x)}\\
	p(x,y) &= p_X(x) p(y|x)
     \end{align*}

	soit z=x-y, si $x \leqslant y$ alors ${x \choose y}$=0
     \begin{align*}
	P(Y=y) &= \sum_{x=0}^{\infty} P(Y=y, X=x)\\
	&=\sum_{z=0}^{\infty} P(Y=y, X=z)\\
	&=\sum_{z=0}^{\infty} \textrm{Po}(\lambda) \textrm{Bin}(z,p)\\
	&=\sum_{z=0}^{\infty} \cfrac{e^{-\lambda} \lambda^{z+y} }{(z+y)!} \cfrac{(z+y)!}{(z+y-y)! y!} p^y (1-p)^z\\
	&= \cfrac{e^{- \lambda} \lambda^y}{y!} p^y \sum_{z=0}^{\infty} \cfrac{\lambda^z (1-p)^z}{z!} \\
	&= \cfrac{e^{- \lambda} \lambda^y}{y!} p^y e^{(1-p)\lambda}\\
	&= \cfrac{(p\lambda)^ye^{-\lambda p}}{y!}\\
	&= \textrm{Po}(\lambda p)
      \end{align*}
 \end{enumerate}
\end{solution}


\section{(4 points)}
Le \textsc{spf} mobilité effectue une étude sur la vitesse moyenne des automobilistes dans les tunnels bruxellois en période de travaux. Afin de cibler leur prochaines campagnes de sensibilisation, le but est de déterminer s'il y a une différence significative entre les hommes et les femmes. L'étude permet de collecter deux échantillons de mesures indépendants et supposés normalement distribués. Les statistiques obtenues sont les suivantes:

\begin{table}[!h]
\centering
\begin{tabular}{r|ccc}
Hommes ``H'' & $n_H = 21$ & $\Bar{x} = 45$ & $s^2 = 15$\\
\hline
Femmes ``F'' & $n_F = 16$ & $\Bar{x} = 42$ & $s^2 = 20$\\
\end{tabular}
\end{table}

\textit{Note: l'ensemble de cet exercice est à réaliser avec un niveau de significativité $\alpha = 0.05$.}

\begin{enumerate}
    \item Réalisez un test pour déterminer si la variance diffère en fonction du sexe.
    \item Donnez un intervalle de confiance pour $\mu_H - \mu_F$. Enoncez précisément les hypothèses sous-jacentes à votre calcul et effectuez le lien avec le point 1.
    \item La vitesse moyenne diffère-t-elle en fonction du sexe?
\end{enumerate}

\begin{solution}

\begin{enumerate}
    \item On réalise le test d'hypothèse bilatéral $H_0 : \sigma^2_F = \sigma^2_H$ vs $H_1 : \sigma^2_F \neq \sigma^2_H$.

    Le test statistique de \textit{Fisher}\footnote{Il faut mettre la valeur la plus grande au numérateur.} donne \( f = s_F/s_H = 1.1547 \). On rejette $H_0$ si 
    \[f > F_{n_1-1,n_2-1,\alpha/2} = F_{15,20,0.025} = 2.57 \quad \mathrm{ou}\quad f < F_{n_1-1,n_2-1,1-\alpha/2} = F_{15,20,0.975} =  F_{15,20,0.025}^{-1} = 0.39  \]

    La valeur observée est en dehors de la région de rejet, donc on ne peut pas rejeter l'hypothèse nulle.

    \item On suppose avoir deux échantillons issus d'une distribution normale, d'espérances \( \mu_F \) et \( \mu_H \) avec la même variance\footnote{C'est légitime car on n'a pas rejeté cette hypothèse au point 1.}. Puisque cette variance est inconnue, on utilise une distribution \textit{student} pour donner un intervalle de confiance bilatéral à \SI{95}{\percent}:
    \[ CI = (\bar{x}_H - \bar{x}_F) \pm t_{n_H+n_F-2,\alpha/2}\:\sqrt{\frac{(n_H-1){s_H^2}+(n_F-1)s_F^2}{n_H+n_F-2}}\sqrt{\frac{1}{n_H}+\frac{1}{n_F}
    } = \left[0.307;5.693\right] \]
    \item Non, car 0 n'est pas dans l'intervalle de confiance pour $\mu_H - \mu_F$ (point 2). On ne peut donc pas rejeter l'hypothèse nulle pour ce cas ($H_0:\mu_H = \mu_F$) en déclarant que les vitesses sont différentes.
\end{enumerate}

\end{solution}

\section{(4 points)}
On peut modéliser la durée d'une connexion sur le site \textit{www.coolsite.be} par une loi de densité
$$\theta^{-2}xe^{-x/\theta}I(x>0).$$
Pour fixer vos tarifs publicitaires, vous voulez estimer le paramètre $\theta$ à partir d'un échantillon iid $X_1,\dots,X_n$ de $n$ durées de connexion. On vous donne $\mathbb{E}[X_i] = 2\theta$ et $\mathbb{V}[X_i] = 2\theta^2$.
\begin{enumerate}
    \item Calculez l'estimateur de maximum de vraisemblance (MLE) $\hat{\theta}_n$ de $\theta$.
    \item Calculez l'erreur quadratique moyenne (MSE) de $\hat{\theta}_n$?.    
    \item Proposez un estimateur $\hat{\lambda}_n$ consistent pour $\lambda = \ln(\theta)$ en justifiant votre choix.
    \item Donnez la distribution asymptotique de $\hat{\lambda}_n$.
\end{enumerate}

\begin{solution}

\begin{enumerate}
    \item Use the MLE's function, then it's log function:
    \[ LL_n(\theta) = \sum_i \ln\left( f(x_i;\theta)\right) = \sum_i -2\ln(\theta)+\ln(x_i)-\frac{x_i}{\theta} = -2n\ln(\theta)+\sum_i\ln(x_i)-\frac{\sum_ix_i}{\theta} \]
    Maximize the parameter, that is, derive the log function with respect to the parameter. The derivative is 0 since you want to maximize the parameter.
    \[ \fpart{LL_n}{\theta}(\hat{\theta}_n) = -\frac{2n}{\hat{\theta}_n} + \frac{\sum_ix_i}{\hat{\theta}_n^2} = 0 \]
    In the end, you find:
    $$\hat{\theta}_n = \frac{\sum_iX_i}{2n} =  \frac{\overline{X}}{2}$$
    We can check that the second derivative is negative, such that we have a maximum in \( \hat{\theta}_n \):
    \[ \ffpart{LL_n}{\theta}(\hat{\theta}_n) = \frac{2n}{\hat{\theta}_n^2} -2 \frac{\sum_ix_i}{\hat{\theta}_n^3} = \frac{2n}{\hat{\theta}_n^2} \left( 1- \underbrace{\frac{\sum_ix_i}{n\hat{\theta}_n}}_{= 2} \right) < 0 \]
    \item The estimator is unbiased, we can show that by computing the MLE's expected value using the expected value given above:
    \[ \mathbb{E}\left[\hat{\theta}_n\right] = \mathbb{E}\left[\frac{\sum_iX_i}{2n} \right] = \frac{1}{2n} \sum_i\mathbb{E}\left[X_i \right] = \frac{1}{2n} \sum_i 2\theta = \theta \]
    Thus the MSE is equal to the variance only. Since the $X_i$ are iid, we use the given variance to compute the MLE's variance, that is: 
    $$MSE(\hat{\theta}_n) = \mathbb{V}\left[\hat{\theta}_n\right] = \mathbb{V}\left[\frac{\sum_i X_i}{2n}\right] = \frac{1}{4n^2} \sum_i\mathbb{V}\left[X_i\right] = \frac{1}{4n^2} \sum_i 2\theta^2 = \frac{\theta^2}{2n}$$
    We can see that the estimator is consistent (the variance approaches 0 for large $n$). 
    \item By MLE's property of invariance, the estimator is : 
    $$\hat{\lambda}_n = \ln\left(\hat{\theta}_n\right) = \ln\left(\frac{\overline{X}}{2}\right)$$
    Since the previously calculated estimator is consistent, this one is consistent too (same property).
    \item Knowing that \( \lambda = g(\theta) = \ln(\theta) \), we calculate \( g'(\theta) = 1/\theta \) and the \textit{Fisher information}
    \[ I_n(\theta) = - \mathbb{E}\left[ LL_n''(\theta) \right] = \frac{2n}{\theta^2} \left( \frac{\mathbb{E}[X_i]}{\theta} -1 \right) = \frac{2n}{\theta^2} \]
    An asymptotic property states that the ML estimator \( g\left(\hat{\theta}_n\right) \) of \( g(\theta) \) is consistent and asymptotically normal with distribution 
    \[ g\left(\hat{\theta}_n\right) \sim N\left( g(\theta), \frac{g'(\theta)^2}{I_n(\theta)} \right) \]
    Thus
    \[ \hat{\lambda}_n \sim N \left( \ln(\theta), \frac{(1/\theta)^2}{2n/\theta^2} \right) = N \left( \ln(\theta), \frac{1}{2n} \right) \]
\end{enumerate}

\end{solution}

\section{(4 points)}

On a deux machines qui fonctionnent en série. $X_1$ est la durée de vie de la première et $X_2$ est la durée de vie de la seconde avec $X_i \sim \mathrm{Expo}(\beta _i)$.

\begin{enumerate}
    \item Exprimer la durée de vie du système $Z$, c'est-à-dire $P(Z>t)$.
    \item Quelle est la probabilité que le système tombe en panne à cause de la machine 1 ?
    \item On définit une nouvelle variable $I$ qui vaut 1 si la panne est due à la première machine et 0 sinon. Calculer $P(Z>t,I=\delta)$ pour $\delta$ appartenant à $[0,1]$ et en déduire que $Z$ et $I$ sont indépendants.
\end{enumerate}

\begin{solution}
 \begin{enumerate}
  \item Comme les machines sont en série, on a \( Z = \min(X_1,X_2) \). Donc
  \[ P(Z>t) = P(\min(X_1,X_2) > t) = P(X_1>t)P(X_2>t) = \exp(-t(\beta_1+\beta_2)) \]

  \item On cherche la probabilité que la durée de vie de la machine 1 soit inférieure à celle de la machine 2. Pour cela, on utilise la densité de probabilité de \( x_1 \) et \( x_2 \):
  \[ f_{X_1,X_2}(X_1,X_2) = f_{X_1}(x_1)f_{X_2}(x_2) = \frac{1}{\beta_1\beta_2}\exp\left(-\frac{x_1}{\beta_1}-\frac{x_2}{\beta_2}\right) \]
  On obtient ainsi que
  \[ P\left(X_1 < X_2\right) = \int_0^\infty \int_{x_1}^\infty \frac{1}{\beta_1\beta_2}\exp\left(-\frac{x_1}{\beta_1}-\frac{x_2}{\beta_2}\right)\: \dif x_1 \: \dif x_2 = \frac{\beta_2}{\beta_1+\beta_2} \]

  \item \nosubsolution
 \end{enumerate}

\end{solution}

\end{document}
