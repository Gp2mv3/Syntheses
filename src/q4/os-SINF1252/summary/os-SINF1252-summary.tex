\documentclass[fr,license=none]{../../../eplsummary}

\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{enumerate}
\DeclareMathOperator{\xor}{\oplus}

\usepackage{../../../eplcode}
\usepackage{../../../eplunits}

\hypertitle{Syst\`emes informatiques}{4}{SINF}{1252}
{Beno\^it Legat\and Damien Mercier}
{Olivier Bonaventure}

\lstset{language={C}}

\part{Le language \clang{}}
\section{Normes}
Depuis sa création par Dennis Ritchie en 1973,
le \clang{} a pas mal évolué.
Il existe plusieurs normes dont la norme \clang99 qui permet
de faire pas mal de nouvelles choses.

Pour demander à \lstinline[language=bash]|gcc|
de compiler du code avec \clang99,
il faut lui donner l'argument \lstinline[language=bash]|--std=c99|.

\section{Les pointeurs}
En \clang{}, les variables sont passées par \emph{valeur},
pour partager une variable sans la copier, on utilise les pointeurs.
Un pointeur contient l'adresse \emph{virtuelle} d'un endroit en mémoire.
\begin{lstlisting}
int n = 0;
int *i = &n;
printf("%d == n\n", *i, n); // imprime 0 == 0
\end{lstlisting}
On doit aussi donner ce vers quoi pointe l'adresse (ici, un \lstinline|int|)
pour permettre au compilateur d'effectuer de l'arithmétique des pointeurs.
En effet, lorsqu'on fait
\begin{lstlisting}
int *p = 0x10;
p++;
\end{lstlisting}
\lstinline|p| n'est pas incrémenté de 1 mais de la taille d'un
\lstinline|int|, c'est à dire \lstinline|sizeof(int)|.

Par convention, \lstinline|NULL| est la valeur d'un pointeur qui
ne pointe pas encore vers de la mémoire allouée.
Il vaut donc mieux toujours donner cette valeur à un pointeur qui ne pointe
pas vers quelque chose de telle sorte que
\begin{lstlisting}
if (p != NULL) {
  free(p);
}
\end{lstlisting}
ne libère jamais de la mémoire non allouée.

\subsection{Le heap}
Les pointeurs permettent aussi de s'allouer de la mémoire dans la \emph{heap}.
La heap est un endroit de la mémoire où on peut s'allouer dynamiquement
de la mémoire.
C'est à dire s'allouer un nombre de bytes
qu'on ne connait pas à la compilation.

Pour cela, on utilise la fonction \lstinline|malloc| qui alloue de la mémoire
et la fonction \lstinline|free| qui la libère.
En effet, si on ne libère jamais la mémoire qu'on s'alloue dans la heap,
elle risque d'être remplie et \lstinline|malloc| renverra alors
\lstinline|NULL|.
\lstinline|malloc| renvoie un pointeur de type \lstinline|void*|
pour rester générique.
Il vaut mieux ne pas le caster dans le type voulu, car cette conversion est implicite.
\begin{lstlisting}
int n;
printf("Combien voulez-vous de int (%d bytes par int) ? : ",
       sizeof(int));
scanf("%d", &n);
// On s'alloue n int consecutifs dans la heap
int *p = malloc(n * sizeof(int));
if (p == NULL) {
  // n est negatif, nul ou trop grand
  printf("Vous avez ete un peut trop optimiste il me semble :)\n");
}
// utilisation de p
// On n'oublie pas de liberer la memoire
free(p);
p = NULL;
\end{lstlisting}

\lstinline|malloc| ne met pas de valeur dans la mémoire qu'elle alloue
et \lstinline|free| ne change pas la valeur de \lstinline|p|
(d'ailleurs il en est incapable car on ne lui a pas passé un pointeur
vers \lstinline|p|).

Il existe aussi la fonction \lstinline|calloc| qui contrairement à
\lstinline|malloc| initialise tous les bytes à 0.
\lstinline|calloc| est donc moins rapide que \lstinline|malloc| mais
met tous les bytes à 0 de manière très efficace.
\begin{lstlisting}
#define N 42
int *p = malloc(N * sizeof(int));
for (int i = 0; i < N; i++) {
  p[i] = 0;
}
// est plus lent que
int *p = calloc(N, sizeof(int));
\end{lstlisting}

\section{Structures}
On peut créer des structures qui sont une sorte de classes sans méthodes.
On accède aux éléments à l'aide de \lstinline|.|, \lstinline|a.b|
est l'élément au label \lstinline|b| dans la variable \lstinline|a|.
On a un raccourci pour \lstinline|(*a).b| qui est \lstinline|a->b|.
\begin{lstlisting}
struct point {
  int x;
  int y;
}
int move (struct point *p, struct point delta) {
  (*p).x += delta.x;
  p->y += delta.y;
}
int main () {
  struct point d;
  d.x = 1;
  d.y = 2;
  struct point *triangle = malloc(3 * sizeof(struct point));
  printf("Before\n");
  for (int i = 0; i < 3; i++) {
    triangle[i].x = i;
    triangle[i].x = i+1;
    printf("(%d, %d)\n", triangle[i].x, triangle[i].y);
  }
  printf("After\n");
  for (int i = 0; i < 3; i++) {
    move(triangle[i], d);
    printf("(%d, %d)\n", triangle[i].x, triangle[i].y);
  }
  free(triangle);
  return 0;
}
\end{lstlisting}

\section{Fonctions}
En \clang{}, les variables sont passées par \emph{valeur}.
Il n'y a jamais de passage par référence comme en \java{} pour les objets
ou comme pour le \oz{}.
Par exemple,
\begin{lstlisting}
void inc1 (int a) {
  a++;
}
void inc2 (int *b) {
  (*b)++;
}
void foo () {
  int n = 0;
  inc1(n);
  printf("%d\n", n); // affiche 0
  inc2(&n);
  printf("%d\n", n); // affiche 1
}
\end{lstlisting}
Comme on fait un passage par valeur,
\lstinline|a| vaut 0 et changer \lstinline|a| ne change pas \lstinline|n|.
Par contre, \lstinline|b| contient l'adresse de \lstinline|n| donc modifier
\lstinline|*b| modifie bien \lstinline|n|.
C'est pour ça que pour \lstinline|scanf|,
il faut passer l'adresse de la variable qui doit stocker le résultat.

\section{Opérateurs}
\subsection{Opérateurs logiques}
Les opérateurs de bits s'exécutent sur chaque bit.
On a
\begin{center}
  \begin{tabular}{cccc}
    \clang{} bit & \clang{} \lstinline|bool| & Logique & Appelation\\
    \& & \&\& & $\land$ & AND\\
    | & || & $\lor$ & OR\\
    $\hat{}$ &  & $\xor$ & XOR
  \end{tabular}
\end{center}

\section{Portée des variables}
En \clang{}, il n'y a pas de classes,
les variables sont soit \emph{locales}, soit \emph{globales}.

\subsection{Variables globales}
Les variables globales sont initialisées à 0 ou NULL pour les pointeurs.
Elles sont visibles partout.
Elles sont déclarées à l'extérieur de toute fonction.

\subsection{Variables locales}
Elles ne sont pas initialisées.
Elles sont visibles uniquement à l'intérieur de la fonction à l'intérieur
de laquelle elles sont créées.
Si elles ont le même nom qu'une variable globale,
la variable globale ne sera pas disponible à l'intérieur de la fonction.
Contrairement aux variables globales, ces variables ne sont pas
initialisées.

\subsection{Variables de boucle}
À partir de la norme \clang99,
on peut déclarer des variables à l'intérieur
de n'importe quel bloc.
\begin{lstlisting}
int main () {
  {
    int i = 0;
  }
  i = 1; // ne compile pas
  return 0;
}
\end{lstlisting}
ce qui permet d'écrire
\begin{lstlisting}
int main () {
  int sum = 0;
  for (int i = 0; i < 5; i++) {
    sum += i;
  }
  return 0;
}
\end{lstlisting}





\section{Types de données}
\subsection{Nombres entiers}
Les nombres sont limités par le nombre de bits qui sont utilisés pour les représenter en mémoire.
Il y deux types de nombres entiers : Les nombres entiers \textbf{signés} (\texttt{int}) et les nombres entiers \textbf{non signés} (\texttt{unsigned int}).
\\
Par convention, le bit le plus à gauche est appelé le \textbf{bit de poids fort} tandis que celui le plus à droite, est le \textbf{bit de poids faible}.
\\\\
Plusieurs représentations de séquences de bits existent : \\
\begin{tabular}{l||l|c|c|l}
  \textbf{Représentation} &  & \textbf{Base} & \textbf{Plage} & \textbf{Exemple} \\
  \hline \hline \textbf{Binaire} & Représente 1 bit & 2 & [0-1] & \texttt{0b1111011} \\
  \hline \textbf{Octal} & Représente 3 bits & 8 & [0-7] & \texttt{0173} \\
  \hline \textbf{Hexadécimal} & Représente 4 bits (nibble) & 16 & [0-9A-F] & \texttt{0x07b} \\
  \hline \textbf{Décimal} &  & 10 & [0-9] & \texttt{123} \\
  \hline
\end{tabular} \\
\begin{footnotesize}
  \textbf{Attention} : Lorsqu'on écrit un nombre commençant par un 0, le compilateur \clang{} le prendra comme étant en notation octale ! Donc \texttt{0123==123} renverra \texttt{FALSE}, en effet, \texttt{\textbf{0}123} représente le nombre décimal \texttt{83}.

\end{footnotesize}
Afin de connaître la taille en mémoire d'un type de donnée en \clang{}, il faut utiliser \texttt{sizeof}.
\texttt{sizeof} renvoit le nombre d'\textbf{octets} (1 octet correspond à 8 bits).

\subsubsection{Nombres entiers signés}
Plusieurs manières existent pour représenter un nombre entier signé.
La première consiste à utiliser le bit le plus à gauche afin de représenter le signe : $$ (-1)^{b_{n-1}} \times \sum_{i=0}^{n-2} b_i \times 2^i$$
En pratique, cette notation n'est que très peut utilisée car elle rend l'implémentation des circuits électroniques de calcul plus compliquée et elle permet de représenter la valeur zéro de deux manière différentes : \texttt{00…00} et \texttt{10…00}

La représentation la plus courante est de sortir de la somme le bit de poids fort et de le multiplier par -1 :
$$ -(b_{n-1}) \times 2^{n-1} +  \sum_{i=0}^{n-2} b_i \times 2^i$$
De cette manière, il n'y a qu'une représentation pour le \texttt{0} (lorsque tous les bits valent \texttt{0}); par contre, il existe toujours un nombre entier négatif qui n'a pas d'équivalent positif.

Un nombre \texttt{short} par exemple est représenté sur 16 bits, il peut donc représenter les nombres compris entre $-2^{15}$ et $2^{15} - 1$, c'est à dire les nombres entiers $\in [-32768, 32767]$.


Attention : Le langage \clang{} ne prévoit aucun mécanisme d'exception qui permettrait au programmeur de détecter qu'on dépasse l'intervalle autorisé pour un type de variable.
Il faut donc choisir le type de variable (\texttt{short}, \texttt{int}, \texttt{long}, \texttt{long long},...) judicieusement en fonction de l'application et être sûr qu'on ne dépasse pas l'intervalle.

\subsection{Nombres réels}
Pour un nombre réel sur 32 bits (resp. 64 bits) on a : $seeeeeeeemmmmmmmmmmmmmmmmmmmmmmm$ avec $s$ le signe sur 1 bit, $e$ l'exposant sur 8 bits (resp. 11) et $m$ la fraction (ou mantisse) sur 23 bits (resp. 52) :
$$\phantom{.} (-1)^s\times(1+\sum^{23}_{i=1} m_i 2^{-i})\times 2^{e-E_{max}}).$$
Il est intéressant de noter que
\begin{itemize}
  \item une représentation en virgule flottante sur $n$ bits ne permet jamais de représenter plus de $2^n$ nombres réels différents.
  \item les représentations en virgule flottante privilégient les nombres réels compris dans l'intervalle $[-1,1]$.
    On retrouve autant de nombres réels représentables dans cet intervalle qu'en dehors.
\end{itemize}

\subsection{Les tableaux}
En \clang{}, les tableaux permettent d'agréger des données d'un même type.
Exemple :
\begin{lstlisting}
#define N 10
int vecteur[N];
int matriceC[N][N];
int matriceR[N][2*N];
\end{lstlisting}

Attention : il n'est pas possible de récupérer la taille d'un tableau à partir de la variable (ex \java{} : \texttt{coord1.length}).
Il faut donc toujours passer cette information en plus du tableau (ex : \texttt{main(\textbf{int argc} , ...)}).

\subsection{Caractères et chaînes de caractères}
\subsubsection{Caractères}
Les caractères peuvent être encodés selon plusieurs représentations :
\begin{itemize}
  \item \textbf{ASCII} : 7 bits - mais représenté sur 8 bits.
    Par exemple : "A" est \texttt{0b01000001}.
  \item \textbf{ISO-8859} : 8 bits.
  \item \textbf{Unicode} : Permet de représenter tous les caractères connus de toutes les langues.
    Utilise plus que 8 bits par caractère.
\end{itemize}
La fonction \texttt{toupper} prend un \texttt{int} comme argument et traite l'information en fonction du type d'encodage qui a été défini\footnote{Avec \texttt{setlocale}, voir \texttt{locale}.}.

Dans la suite du cours, nous supposerons qu'un caractère est toujours représentable en utilisant le type \texttt{char} permettant de stocker un octet.

\subsubsection{Chaîne de caractères}
En \clang{}, les chaînes de caractères sont représentées sous forme de tableaux de caractères (\texttt{char}).
Le dernier caractère d'une chaîne de caractères en \clang{} est par convention le caractère \texttt{'$\backslash$0'}.
Il faut faire attention à ne jamais le ``dépasser'' car le \clang{} n'a pas de mécanisme d'exception et donc aller trop loin dans le tableau ne produira pas d'exception du type \texttt{ArrayOutOfBoundException} comme en \java{} mais un résultat imprévisible.


\subsection{Les pointeurs}
Un \textbf{pointeur} est définit comme étant une variable content l'adresse d'une autre variable.
\begin{lstlisting}
int i=1;				// entier
int *ptr_i;				// pointeur vers un entier

ptr_i=&i;				// initialisation du pointeur, a l'adresse de i
*ptr_i = *(ptr_i)+1252;	// changement du contenu de la memoire pointee par ptr_i
\end{lstlisting}

\subsection{Les structures}
En \clang{}, les structures permettent de définir des données plus complexes.
La langage \clang{} permet la définition de structures qui combinent différents types de données simples ou structurés.
Les structures permettent de facilement regrouper des données qui sont logiquement reliées entre elles et doivent être manipulées en même temps.
\begin{lstlisting}
// Definition d'une structure
struct student {
  int matricule ;
  char prenom [ 2 0 ] ;
  char nom [ 3 0 ] ;
};
// Declaration + Initialisation
struct student linus = { 1 , "Linus" , "Torvalds" } ;
struct student richard = { .matricule = 2 , .prenom = "Richard" , .nom = "Stallman" } ;
struct student evil;
evil.noma = 3;
evil.prenom = "Bill";
evil.nom = "Gates";
\end{lstlisting}


\texttt{typedef} permet de redéfinir le nom des types de données.
\begin{lstlisting}
// Definition de nouveaux noms pour des types existants
typedef int Entier;
typedef struct student Etudiant;
// Declaration de variable utilisant ces nouveaux noms
Entier matricule = 4;
Etudiant mark = {matricule , "Mark" , "Shuttleworth" };
\end{lstlisting}
Les données d'une structure peuvent être accédées via l'opérateur "\texttt{.}" (point).
Mais étant donné que les pointeurs sont souvent utilisés lors de la manipulation de structures, une notation plus pratique que \texttt{(*ptr).elem} existe : \texttt{ptr->elem}.
\begin{lstlisting}
//Avec l'operateur '.'
printf("[%d] %s %s\n", mark.matricule, mark.nom, mark.prenom);
//Avec l'operateur '->'
Etudiant *e = &evil;
printf("[%d] %s %s\n" e->matricule, e->nom, e->prenom);
// qui est identique a :
printf("[%d] %s %s\n", (*e).matricule, (*e).nom, (*e).prenom);
\end{lstlisting}

\section{Compléments en langage \clang{}}
\subsection{Les fonctions}
\subsubsection{Déclaration \textit{vs} Définition}
La \textbf{déclaration} d'une fonction (= sa signature) indique au compilateur le type (en cas de variables) ou les arguments et le type de la valeur de retour (en cas de fonctions).
Toute fonction ou variable doit être déclarée avant d'être utilisée.
En règle générale, on regroupe toutes les déclarations de fonction à l'intérieur d'un \textbf{fichier header} dont le nom se termine par \texttt{.h}

La \textbf{définition} d'une fonction consiste en l'implémentation de la fonction déclarée, ou dans le cas d'une variable, de son initialisation.

\subsubsection{Passage des paramètres}
Le langage \clang{} utilise le \textbf{passage par valeur} des arguments.
Lorsqu'une fonction est exécutée, elle reçoit les valeurs de ces arguments.
Ces valeurs sont stockées dans une zone mémoire qui est locale à la fonction.
Toute modification faite sur la valeur d'une variable à l'intérieur d'une fonction est donc locale à cette fonction.
Attention néanmoins : lorsqu'on passe un pointeur en argument on copie la valeur du pointeur (l'adresse d'une zone mémoire).
Le contenu de la zone mémoire pointée par le pointeur n'est pas copié, il est donc possible à la fonction de le modifier\footnote{Cette remarque s'applique également aux tableaux, puisqu'un tableau est en réalité un pointeur (vers la première case du tableau).}!
Par contre, si la fonction essaye de changer le pointeur lui même (pour qu'il pointe vers une autre zone mémoire) ce changement n'aura lieu que dans la fonction puisqu'il s'agit bien d'une copie du pointeur!


\subsection{Manipulation de bits}
Le langage \clang{} permet au programmeur de manipuler facilement les bits qui se trouvent en mémoire.
Pour cela, le langage \clang{} définit des expressions qui correspondent à la plupart des opérations de manipulation de bits que l'on retrouve dans les langages d'assemblage.
Les premières opérations sont les opérations logiques, elles sont résumées par le tableau \ref{table:opbin}.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{|c|c||c|c|c|c|c}
      \hline
      \multirow{3}*{\textbf{A}} & \multirow{3}*{\textbf{B}} & \textit{négation} & \textit{conjonction logique} & \textit{disjonction logique} & \textit{ou exclusif} \\
                                & & \textbf{NOT(A)} & \textbf{A AND B} & \textbf{A OR B} & \textbf{A XOR B} \\
                                & & $\lnot A$ & $A \land B$ & $A \lor B$ & $A \xor B$ \\
      \hline
      \hline 0 & 0 & \multirow{2}*{1} & 0 & 0 & 0 \\
      \cline{1-2}\cline{4-6} 0 & 1 &  & 0 & 1 & 1 \\
      \hline 1 & 0 & \multirow{2}*{0} & 0 & 1 & 1 \\
      \cline{1-2}\cline{4-6} 1 & 1 &  & 1 & 1 & 0 \\
      \hline \hline
      \multicolumn{6}{|l|}{\textbf{Exemple en \clang{} : }} \\
      \multicolumn{6}{|l|}{
        \begin{minipage}{0.5\textwidth}
          \texttt{char a = 0b01110011;}\\
          \texttt{char b = 0b00100101;}
        \end{minipage}
      } \\
      \hline
      \multicolumn{2}{|l|}{\textbf{Opération\footnotemark}} & \texttt{\~{}a} & \texttt{a\&b} & \texttt{a|b} & \texttt{a\^{}b} \\
      \hline
      \multicolumn{2}{|l|}{\textbf{Résultat}} & \texttt{0b10001100} & \texttt{0b00100001} & \texttt{0b01110111} & \texttt{0b01010110} \\
      \hline
    \end{tabular}
    \caption{Récapitulatif des opérations.}
    \label{table:opbin}
  \end{center}
\end{table}
\footnotetext{Il faut faire attention à ne pas confondre les opérateurs binaires logiques \texttt{\&} et \texttt{|} avec les expressions logiques \texttt{\&\&} et \texttt{||} !}


Il est également important de mentionner les lois formulées par De Morgan qui peuvent se résumer par les équations suivantes :
$$\lnot ( A \lor B) = \lnot A \land \lnot B \text{~~~~~~~et~~~~~~~} \lnot ( A \land B) = \lnot A \lor \lnot B$$
Une des propriétés intéressantes de l'opération XOR est que $(A \xor B) \xor B = A$.
Cette propriété est largement utilisée par les méthodes de chiffrement.

\subsubsection{Décalage de bits}
\paragraph{Bit-shift à gauche} $n$ bits sont déplacés de \texttt{B} vers la gauche en ajoutant des 0 à droite.
En \clang{} : \texttt{a = n<<B}.
\paragraph{Bit-shift à droite} $n$ bits sont déplacés de \texttt{B} vers la droite en ajoutant des 0 à gauche.
En \clang{} : \texttt{a = n>>B}.
Ces opérations de décalage permettent différentes manipulations de bits\footnote{Pour un exemple, voir \texttt{int2bin} à la page 33 du syllabus [PDF].}.


\subsection{typecast en \clang{}}
Le langage \clang{} supporte des conversions implicites et explicites entre les différents types de données.
Ces conversions sont possibles entre les types primitifs et les pointeurs.

Attention : Contrairement au compilateur \java{}, le compilateur \clang{} n'émet pas toujours de message de \textit{warning} lors de l'utilisation de typecasts qui risquent d'engendrer une perte de précision. Un exemple de typecast implicite est celui fait par les fonctions \texttt{malloc}.

\begin{lstlisting}[emph={unType,unAutreType,Etudiant},emphstyle={\color{blue}\bfseries}]
// Exemple de typecast explicite
unType a = ... ;
unAutreType b = (unAutreType) a;

// Exemple de typecast implicite
Etudiant * e;
e = malloc(sizeof(Etudiant)); \\ Le typecast est implicite
\end{lstlisting}



\subsection{Les pointeurs}
En \clang{}, il est possible de définir des pointeurs vers n'importe quel type d'information qui est manipulé par un programme \clang{}.

Il est ainsi possible d'avoir des pointeurs vers des fonctions.
Cela peut être utile par exemple pour avoir une application qui propose différentes fonctions pour afficher (ou non) les informations de débogage.
Ou encore pour utiliser la fonction \texttt{qsort} qui permet de trier un tableau de n'importe quel type d'information.
Sa signature est la suivante : \\
\texttt{\textbf{void} qsort(\textbf{void} *base, \textbf{size\_t} nel, \textbf{size\_t} width, \textbf{int} (*compar) (\textbf{const void} *, \textbf{const void} *))}.
Le quatrième argument est un pointeur vers la fonction qui permet de comparer deux élémets du tableau.
Cette fonction retourne un entier négatif si son premier argument est inférieur au second, nul si les deux éléments sont égaux et positif sinon. \\

Il est également possible d'avoir des pointeurs vers des pointeurs.
En pratique, on retrouve des pointeurs vers des pointeurs lorsqu'on doit manipuler des structures multidimensionnelles, mais aussi lorsqu'il faut qu'une fonction puisse modifier une adresse qu'elle a reçue en argument\footnote{Comme par exemple la fonction \texttt{strtol} de la librairie standard qui prend comme deuxième argument un pointeur vers un pointeur (\texttt{endptr}) qui permet d'indiquer un pointeur vers le premier caractère en erreur en cas d'erreur de conversion (sinon il indiquera le caractère de fin de chaîne \texttt{'$\backslash$0'}).}.

\subsection{Écriture de grands programmes}
Lors de l'écriture de grands programmes, il est préférable de les découper en modules.
Chaque module contient des fonctions qui traitent d'un même type de problème et sont fortement couplées.
Un module d'un programme \clang{} est en général composé en deux parties :
\begin{itemize}
  \item Le \textit{fichier header} : Contient les définitions de certaines constantes et les signatures des fonctions exportées par ce module.
    Ce fichier est en quelque sorte un résumé du module, c'est son interface externe.
    Il doit être inclus dans tout fichier qui utilise les fonctions du module\footnote{En pratique un \textit{fichier header} ne peut être inclus qu'une seule fois.
      Mais comme il se peut qu'un \textit{fichier header} fasse appel à un autre, on utilise la règle de bonne pratique suivante : on ajoute une condition au préprocesseur avec \texttt{\#ifndef \_MON\_MODULE\_} suivi de \texttt{\#define \_MON\_MODULE\_} en début de \textit{fichier header}.
    On termine la condition avec \texttt{\#endif} en fin de fichier.}.
    Ce fichier contient donc :
    \begin{itemize}
      \item Signatures des fonctions.
        (Uniquement les fonctions qui sont destinées à être utilisées par des modules extérieurs.)
      \item Constantes qui sont utilisées à l'intérieur du module et doivent être visibles en dehors de celui-ci.
        Ces constantes peuvent être définie en utilisant des directives \texttt{\#define} du préprocesseur.
      \item Variables globales qui doivent être accessibles en dehors du module.
    \end{itemize}
  \item Le fichier contenant le code du module.
\end{itemize}

Pour inclure des fichiers headers :
\begin{itemize}
  \item Soit il s'agit d'un module fourni par le système : \\
    \texttt{\#include <lemodule.h>}
  \item Soit il s'agit d'un module du programme (dans le même répertoire ou dans un répertoire définit en utilisant la variable d'environnement \texttt{GCC\_INCLUDE\_DIR} ou \texttt{CPATH}) : \\
    \texttt{\#include "lemodule.h"}.
\end{itemize}
La procédure/ordre de compilation est expliqué dans le cours (page 90-91).


\subsection{\texttt{static}}
Le qualificateur \texttt{static} peut être utilisé dans différents cas :
\begin{itemize}
  \item Pour des variables définies en dehors d'un bloc dans un module : dans ce cas, cette variable n'est accessible que par les fonctions du module.
  \item Pour des variables définies à l'intérieur d'un bloc (par exemple dans une fonction) : dans ce cas, cela indique que cette variable doit toujours se trouver à la même localisation en mémoire, quelque soit le moment où elle est appelée.
    Ces variables sont placées par le compilateur dans le bas de la mémoire, avec les variables globales\footnote{Doit être utilisé avec beaucoup de précaution et bien documenté!}.
    Un de leurs intérêts est qu'elles ne sont initialisées qu'au lancement du programme et non pas à chaque invocation de la fonction dans laquelle elles sont définies.
  \item Pour des fonctions : lorsqu'une déclaration de fonction est précédée par le qualificateur \texttt{static}, cela indique que la fonction ne doit pas être visible en dehors du module dans lequel elle est définie.
\end{itemize}

\subsection{\texttt{extern}}
Lorsqu'une déclaration de variable globale est préfixée par \texttt{extern}, cela indique au compilateur que la variable est définie dans un autre module qui sera linké ultérieurement.
Le compilateur réserve une place pour cette variable dans la table des symboles du fichier objet, mais cette place ne pourra être liée à la zone mémoire qui correspond à cette variable que lorsque l'éditeur de liens combinera les différents fichiers objets entre eux.


\subsection{Traitement des erreurs}
Pour certaines fonctions ou appels système, il est parfois nécessaire de fournir à l'utilisateur plus d'information sur l'erreur qui s'est produite.
La valeur de retour utilisée pour la plupart des fonctions de la librairie et appels système (souvent un \texttt{int} ou un pointeur), ne permet pas de fournir de l'information précise sur l'erreur qui s'est produite.

Les systèmes Unix utilisent la variable globale \texttt{errno} pour résoudre ce problème et permettre à une fonction de la librairie ou un appel système qui a échoué de donner plus de détails sur les raisons de l'échec.
Cette variable globale est définie dans le fichier \texttt{errno.h} qui doit être inclus par tout programme voulant tester ces codes d'erreur.
La librairie standard fournit également les fonctions \texttt{perror} et \texttt{strerror} qui facilitent l'écriture de messages d'erreur compréhensibles pour l'utilisateur. \\
Attention : La valeur de \texttt{errno} n'est modifiée qu'en cas d'échec, elle ne permet donc pas de savoir si une fonction a réussi ou non !



\section{Gestion et organisation de la mémoire}
\subsection{Déclarations et portées}
La \textbf{portée} d'une variable peut être définie comme étant la partie du programme où la variable est accessible et où sa valeur peut être modifiée.

En \clang{}, une variable a une \textbf{portée globale} lorsqu'elle est définie en dehors de toute définition de fonction.
Une telle variable est accessible dans toutes les fonctions présentes dans le fichier.
Dans un fichier donné, il ne peut donc évidemment pas y avoir deux variables globales qui ont le même identifiant.
Une variable définie dans un \textbf{bloc} a par contre une \textbf{portée locale} à ce bloc.
La variable n'existe pas avant le début du bloc et n'existe plus à la fin du bloc.

Lorsqu'un identifiant de variable locale est utilisé à plusieurs endroits dans un fichier, c'est la définition la plus proche qui est utilisée.

En pratique, les variables globales doivent être utilisées de façon parcimonieuse et il faut limiter leur utilisation aux données qui doivent être partagées par plusieurs fonctions à l'intérieur d'un programme.
Lorsqu'une variable globale a été définie, il est préférable de ne pas réutiliser son identifiant pour une variable locale.

Les premières versions du langage \clang{} imposaient la définition de toutes les variables locales au début des blocs.
Les standards récents [\clang{}99] autorisent la déclaration de variables juste avant leur première utilisation (à peu près comme en \java{}).

\subsubsection{Constantes}
Les versions récentes de \clang{} [\clang{}99] permettent également de définir des variables dont la valeur sera constante durant toute l'exécution du programme.
Pour ce faire il faut utiliser le mot clé \texttt{const} devant la déclaration de la variable (l'équivalent de \texttt{final} en \java{}).

Une autre façon de définir des constantes est d'utiliser la macro \texttt{\#define} du préprocesseur qui permet de remplacer une chaîne de caractères par un nombre ou une autre chaîne de caractères.
Mais les inconvénients par rapport à \texttt{const} sont :
\begin{itemize}
  \item Avec \texttt{const} il est possible de définir n'importe quel type de donnée en \clang{}, y compris des structures ou des pointeurs.
    (Tandis qu'avec \texttt{\#define}, on ne peut définir que des nombres ou des chaînes de caractères.)
  \item Les variables déclarées avec \texttt{const} sont stockées en mémoire, il est donc possible d'obtenir l'adresse en mémoire (pour l'examiner via un \textit{debugger} par exemple).
\end{itemize}


\subsection{Organisation de la mémoire}
\begin{wrapfigure}{r}{0.3\textwidth}
  \vspace{-0.5cm}
  \includegraphics[width=0.3\textwidth]{mem}
  \caption{\label{fig:mem} Organisation d'un programme Linux en mémoire}
  \vspace{-2.5cm}
\end{wrapfigure}
Lorsqu'un programme s'exécute sur un système Unix, la mémoire peut être vue comme étant divisée en 6 zones principales (figure~\ref{fig:mem}).
\subsubsection{Le segment text}
La première zone est appelée le \textbf{\textit{segment text}}.
Elle est située dans la partie basse de la mémoire\footnote{Voir variable \texttt{etext}.}.
C'est dans cette zone que sont stockées toutes les instructions qui sont exécutées par le micro-processeur.
Elle est généralement considérée par l'OS comme étant uniquement accessible en lecture\footnote{Donc si un programme essaye de modifier son \textit{segment text} il sera immédiatement interrompu par le système d'exploitation}.
C'est dans le \textit{segment text} qu'on retrouvera les instructions de langage machine correspondant aux fonctions de calcul et d'affichage du programme
$\implies$ langage d'assemblage.

\subsubsection{Le segment des données initialisées}
La deuxième zone appelée \textbf{\textit{segment des données initialisées}} contient l'ensemble des données et chaînes de caractères qui sont utilisées dans le programme.
Ce segment contient 2 types de données :
\begin{itemize}
  \item l'ensemble des variables globales qui sont explicitement initialisées par le programme ou initialisée à 0 par le compilateur;
  \item les constantes et chaînes de caractères utilisées par le programme.
\end{itemize}

\subsubsection{Le segment des données non initialisées}
La troisième zone appelée \textbf{\textit{segment des données non initialisées}} est réservée aux variables non initialisées.
Cette zone en mémoire est initialisée à zéro par l'OS au démarrage du programme.
C'est dans cette zone qu'on stockera les valeurs de la variable \texttt{g} et des tableaux \texttt{array} et \texttt{msg} de l'exemple ci-dessous :

\begin{lstlisting}
#define MSG_LEN 10
int g;   // initialise par le compilateur
int g_init=1252;
const int un=1;
int tab[3]={1,2,3};
int array[10000];
char cours[]="SINF1252";
char msg[MSG_LEN]; // initialise par le compilateur

int main(int argc, char *argv[]) {
  int i;
  printf("g est a l'adresse %p et initialisee a %d\n",&g,g);
  printf("msg est a l'adresse %p contient les caracteres :",msg);
  for(i=0;i<MSG_LEN;i++)
  printf("%x ",msg[i]);
  printf("\n");
  printf("Cours est a l'adresse %p et contient : %s \n",&cours,cours);
  return(EXIT_SUCCESS);
}
\end{lstlisting}


\paragraph{Initialisation des variables} En \clang{}, il faut être attentif à bien initialiser l'ensemble des variables utilisées dans un programme car le compilateur \clang{} est très permissif (contrairement au compilateur \java{}).
Le compilateur \clang{} n'initialise pas les variables locales à zéro (pour un gain de performance), on ne peut donc pas faire d'hypothèse sur la valeur d'une variable non initialisée.

\subsubsection{Le tas (ou heap)}
La quatrième zone de la mémoire est le \textbf{\textit{tas}} (ou \textit{heap}).
Il s'agit d'une des deux zones dans laquelle un programme peut obtenir de la mémoire supplémentaire pour stocker de l'information.
L'OS mémorise pour chaque processus en cours d'exécution, la limite supérieure de son \textit{heap} et permet à un processus de modifier la taille de son \textit{heap} via les appels système \texttt{brk} et \texttt{sbrk}.
Ces deux appels système sont rarement utilisés directement car ils se contentent uniquement de modifier la limite supérieure du \textit{heap} sans fournir d'API permettant d'y allouer efficacement des blocs de mémoire\footnote{On peut néanmoins utiliser directement \texttt{brk} sous forme d'un appel à \texttt{sbrk(0)} de façon à connaître la limite supérieure actuelle du \textit{heap}.}.

\paragraph{\texttt{malloc} et \texttt{free}}

En \clang{}, la plupart des processus allouent et libèrent de la mémoire en utilisant les fonctions \texttt{malloc} et \texttt{free} qui font partie de la librairie standard.

La fonction \texttt{malloc} prend comme argument la taille (en bytes) de la zone mémoire à allouer.
Cette taille doit être de type \texttt{size\_t}, il est important de toujours utiliser \texttt{sizeof} lors du calcul de la taille d'une zone mémoire à allouer.
\texttt{malloc} retourne un pointeur du type \texttt{(void *)} qui peut être casté en un pointeur du bon type.

La fonction \texttt{free} permet quant à elle de libérer la mémoire qui a été allouée par \texttt{malloc}.
Elle prend comme argument le pointeur dont la valeur a été initialisée par \texttt{malloc}.
La valeur du pointeur n'est pas modifiée, mais après libération de la mémoire il n'est évidemment plus permit d'accéder aux données qui étaient stockées dans cette zone\footnote{Bien que le compilateur \clang{} ne génère pas de code permettant de vérifier automatiquement qu'un accès via un pointeur pointe ou non vers une zone mémoire qui est libre (pour des raisons de performance).}.

\texttt{malloc} et \texttt{free} sont fréquemment utilisés dans des programmes qui manipulent des structures de données dont la taille varie dans le temps.
C'est le cas par exemple pour les différentes sortes de listes chaînées, les piles, les \textit{queues}, les arbres,\dots

\paragraph{Attention}
Il ne faut pas compter sur les \texttt{free} implicites.
Lorsqu'un programme se termine, via \texttt{return} dans la fonction \texttt{main} ou par un appel explicite à \texttt{exit}, l'OS libère tous les segments utilisés par le programme, le text, les données, le tas et la pile.
Néanmoins, ne pas libérer la mémoire lorsqu'elle n'est plus utilisée est un problème courant qui est généralement baptisé \textit{memory leak} ou fuite de mémoire.
Ce problème est particulièrement gênant pour les processus tels que les serveurs Internet qui ne se terminent pas ou des processus s'exécutant longtemps.
Une petite erreur de programmation causant un \texttt{memory leak} peut après quelque temps consommer une grande partie de l'espace mémoire inutilement.
Ce n'est pas acceptable !

Il existe également d'autres fonctions que \texttt{malloc} et \texttt{free} dans la librairie standard.
Citons \texttt{calloc} qui permet d'initialiser la mémoire à 0\footnote{Il est aussi possible d'initialiser la mémoire avec \texttt{memset} ou \texttt{bzero}.}.

\subsubsection{Les arguments et variables d'environnement}
La zone située dans le haut de la mémoire est une zone qui contient deux types de variables :
\begin{itemize}
  \item Les arguments qui ont été passés via la ligne de commande.
    L'OS met dans \texttt{argc} le nombre d'arguments et place dans \texttt{char *argv[]} tous les arguments passés avec dans \texttt{argv[0]} le nom du programme qui est exécuté.
  \item Ensuite les variables d'environnement.
\end{itemize}

\paragraph{Les variables d'environnements}
Ces variables sont généralement relatives à la configuration du système.
Leurs valeurs sont définies par l'administrateur système ou l'utilisateur.
De nombreuses variables d'environnement sont utilisées dans les systèmes Unix.
Elles servent à modifier le comportement de certains programmes.
Voici quelques variables utiles\footnote{Il est possible de lister les définitions actuelles des variables d'environnement via la commande \texttt{printenv}.
  Les interpréteurs de commande tels que bash permettent de facilement modifier les valeurs de ces variables.
La plupart d'entre elles sont initialisées par le système ou via les fichiers qui sont chargés automatiquement au démarrage de l'interpréteur comme le fichier \texttt{/etc/profile} et le fichier \texttt{.profile} du répertoire utilisateur.}.

\noindent\begin{tabularx}{\textwidth}{|p{0.08\textwidth}|p{0.45\textwidth}|p{0.05\textwidth}p{0.1\textwidth}|p{0.185\textwidth}|}
  \hline
  \textbf{Nom} & \textbf{Description} & \multicolumn{2}{c|}{\textbf{Définit par}} & \textbf{Exemple} \\
  \hline \hline
  \texttt{HOSTNAME} & Nom de la machine sur laquelle le programme s'exécute.
  & Admin & \texttt{hostname} & \texttt{damien-laptop}\\
  \hline
  \texttt{SHELL} & Interpréteur de commande utilisé par défaut pour l'utilisateur courant.
  Cet interpréteur est lancé par le système au démarrage d'une session de l'utilisateur.
  Il est stocké dans le fichier des mots de passe.
  & User & \texttt{passwd} & \texttt{/bin/bash} \\
  \hline
  \texttt{USER} & Nom de l'utilisateur courant.
  Sous Unix, chaque utilisateur est identifié par un numéro d'utilisateur et un nom uniques.
  & Admin & \texttt{passwd} & \texttt{damien} \\
  \hline
  \texttt{HOME} & Répertoire d'accueil de l'utilisateur courant.
  Ce répertoire d'accueil appartient à l'utilisateur.
  C'est dans ce répertoire qu'il peut stocker tous ses fichiers.
  & & & \texttt{/home/damien} \\
  \hline
  \texttt{PRINTER} & Nom de l'imprimante par défaut qui est utilisée par \texttt{lp}. & & & \\
  \hline
  \texttt{PATH} & Contient la liste ordonnée des répertoires que le système parcourt pour trouver un programme à exécuter.
  Cette liste contient généralement les répertoires dans lesquels le système stocke les exécutables standards ainsi que des répertoires relatifs à des programmes spécialisés\footnote{Par exemple \texttt{/usr/lib/mozart/bin}}.
  & User\footnote{par exemple en ajoutant \texttt{PATH=\$PATH : \$HOME/local/bin : .} dans le fichier \texttt{.profile}.
Dans cet exemple le répertoire \texttt{\~{}/local/bin} sera ajouté ainsi que le répertoire courant symbolisé par le "\texttt{.}".} & & \texttt{/usr/local/sbin: /usr/local/bin: /usr/sbin: /usr/bin: /sbin: /bin: /usr/games}\\
  \hline
\end{tabularx}

La librairie standard contient plusieurs fonctions qui permettent de manipuler les variables d'environnement d'un processus.
\begin{itemize}
  \item \texttt{getenv} permet de récupérer la valeur associée à une variable d'environnement.
    Retourne un pointeur \texttt{NULL} si la variable n'a pas été assignée.
  \item \texttt{unsetenv} permet de supprimer une variable de l'environnement du programme courant.
  \item \texttt{setenv} permet de modifier la valeur d'une variable d'environnement.
    Cette fonction alloue de la mémoire pour stocker de nouvelles variables d'environnement et peut donc échouer (c'est-à-dire retourner un code différent de 0) s'il n'y a pas assez de mémoire disponible.
\end{itemize}

\subsubsection{La pile (ou \textit{stack})}
La \textbf{\textit{pile}} ou \textbf{\textit{stack}} est la dernière zone de mémoire utilisée par un processus.
Cette zone est extrêmement importante car c'est dans cette zone que le processus va stocker l'ensemble des variables locales mais également les valeurs de retour de toutes les fonctions qui sont appelées.
Cette zone est gérée comme une pile (d'où son nom) avec un fonctionnement de type LIFO (\textit{Last In}, \textit{First Out}).
À chaque fois qu'une fonction est appelée, elle est placée sur la pile ainsi que ses arguments.
Les variables locales le sont également.
Durant son exécution, une fonction accède donc à ses variables locales sur la pile sans interférer avec les variables locales de l'exécution des autres fonctions\footnote{Il peut s'agir de fonctions différentes ou de la même fonction qui est en attente d'un résultat, par exemple dans le cas de fonctions récursives.}.

La pile joue un rôle essentiel lors de l'exécution de programmes en \clang{} puisque toutes les variables locales, y compris celles de la fonction \texttt{main}, y sont stockées.
La pile sert également à stocker l'adresse de retour des fonctions, ce qui permet a une fonction de poursuivre correctement son exécution après avoir exécuté une autre fonction afin d'en récupérer la valeur de retour.

Le fonctionnement de la pile confirme la portée locale : lorsqu'une variable est définie comme argument ou localement à une fonction \texttt{f}, elle n'est donc accessible que durant l'exécution de la fonction \texttt{f}.

De plus, comme le langage \clang{} utilise le passage par valeur, les valeurs des arguments d'une fonction sont copiée sur la pile avant de démarrer l'exécution de cette fonction.
Il est important d'en être conscient, par exemple si l'on doit passer des structures importantes a une fonction.
Le choix de passer un pointeur vers la structure peut donc être plus judicieux (mais permet à la fonction de modifier le contenu de la structure dont le pointeur est passé en argument) afin de gagner en performance et en utilisation de mémoire.


Certaines variantes de Unix et certains compilateurs permettent l'allocation de mémoire sur la pile via la fonction \texttt{alloca}.
Néanmoins, cette façon d'allouer de la mémoire sur la pile n'est pas portable et il est préférable de n'allouer de la mémoire que sur le tas en utilisant \texttt{malloc}.

En vue du fonctionnement de la pile il faut être attentif à ne jamais retourner l'adresse d'une variable locale.
Cette erreur est signalée lors de la compilation par \texttt{gcc} sous la forme d'un \textit{warning} : \texttt{warning : function return address of local variable}.


\section{Organisation des ordinateurs}
\begin{wrapfigure}{r}{0.3\textwidth}
  \vspace{-0.5cm}
  \includegraphics[width=0.3\textwidth]{vanNeumann}
  \caption{\label{fig:vanNeumann}Modèle de von Neumann.}
\end{wrapfigure}

Un des premiers principes fondateurs est le modèle d'architecture de \textit{von Neumann}\footnote{Introduit avec le développement des premiers ordinateurs durant la Seconde Guerre mondiale mais reste tout à fait valable aujourd'hui.} (Figure \ref{fig:vanNeumann}).
La partie la plus intéressante de ce modèle est organisée autour de 2 types de dispositifs :
\begin{itemize}
  \item L'unité centrale ou \textbf{\textit{processeur}} qui peut être décomposée en 2 parties :
    \begin{itemize}
      \item L'unité de commande : permet de charger, décoder et exécuter les instructions du programme qui sont stockées en mémoire.
      \item L'unité arithmétique et logique : regroupe les circuits électroniques qui permettent d'effectuer les opérations arithmétiques (addition, soustraction, division,\dots) et logiques.
        C'est cette unité qui réalise les calculs proprement dits.
    \end{itemize}
  \item La \textbf{\textit{mémoire}} qui joue un double rôle :
    \begin{itemize}
      \item Stocke les données qui sont traitées par le programme;
      \item Stocke les instructions qui composent ce programme.
    \end{itemize}
\end{itemize}

\subsection{La mémoire}
\paragraph{Première approche} En première approximation, on peut considérer la mémoire comme étant un dispositif qui permet de stocker des données binaires.
La mémoire est découpée en blocs d'un octet.
Chacun de ces blocs est identifié par une adresse, qui est elle aussi représentée sous la forme d'un nombre binaire.
Une mémoire qui permet de stocker $2^k$ bytes de données utilisera au minimum $k$ bits pour représenter l'adresse d'une zone mémoire\footnote{Par exemple, une mémoire pouvant stocker 64 millions de bytes doit utiliser au moins 26 bits d'adresse.}.
En pratique, les processeurs des ordinateurs de bureau utilisent 32 ou 64 bits\footnote{D'anciens processeurs utilisaient 16 ou 20 bits d'adresse.}.
Ce nombre de bits utilisés pour représenter une adresse en mémoire limite la capacité totale de mémoire adressable par un processeur.
Ainsi, un processeur qui utilise des adresses sur 32 bits n'est pas capable physiquement d'adresser plus de \SI{4}{\giga\byte} de mémoire.


\begin{wrapfigure}{r}{0.5\textwidth}
  \vspace{-0.5cm}
  \includegraphics[width=0.5\textwidth]{mem2}
  \caption{\label{fig:vanNeumann}Architecture d'un ordinateur actuel.}
\end{wrapfigure}
\paragraph{Approche complexe} En pratique, l'organisation d'un ordinateur actuel est plus complexe que le modèle de von Neumann.
La figure \ref{fig:vanNeumann} présente de manière schématique l'organisation actuelle d'un ordinateur.

Le processeur est directement connecté à la mémoire via un \textbf{\textit{bus}} de communication rapide permettant des échanges de données et d'instructions efficaces entre la mémoire et le processeur.
En plus du processeur et de la mémoire, un troisième dispositif, souvent appelé \textit{adaptateur de bus} est connecté au bus processeur-mémoire.
Cet adaptateur permet au processeur d'accéder aux dispositifs de stockage ou aux dispositifs d'entrées-sorties tels que le clavier, la souris ou les cartes réseau.
En pratique, cela se réalise en connectant les différents dispositifs à un autre bus de communication (PCI, SCSI,\dots) et en utilisant un adaptateur de bus qui est capable de traduire les commandes venant du processeur.

\subsubsection*{Mémoires SRAM, DRAM,\dots}
Les technologies les plus courantes pour la mémoire sont les \textit{SRAM} et les \textit{DRAM}.\\

\noindent\begin{tabularx}{\textwidth}{|l|p{0.32\textwidth}|p{0.25\textwidth}|p{0.25\textwidth}|}
  \hline
  \textbf{Type} & \textbf{Description} & \textbf{Avantages} & \textbf{Inconvénients} \\
  \hline \hline
  \textit{SRAM} & L'information est stockée sous la forme d'un courant électrique qui passe ou ne passe pas à un endroit donné.
  & Temps d'accès assez faible. & Grande consommation électrique, ce qui empêche de développer des mémoires de grande capacité. \\
  \hline
  \textit{DRAM} & C'est la présence ou l'absence d'une charge ($\leq$ à quelques dizaines d'électrons) dans un condensateur qui représente la valeur 0 ou 1.
  & Possible d'en construire de très grande taille : jusqu'à \SI{1}{\giga \byte} par \textit{chip}.
  & Performances nettement moins bonnes que les \textit{SRAM}. \\
  \hline
\end{tabularx}
~\\

En pratique, une mémoire \textit{DRAM} actuelle peut être vue comme étant équivalente à une grille.
Les adresses peuvent donc être vues comme étant composées d'un numéro de ligne et d'un numéro de colonne.
Ces deux opérations sont successives.
Lorsque la mémoire a reçu la ligne et ensuite la colonne demandées, avant de pouvoir commencer le transfert de la donnée.
Elles ont donc une latence élevée (par rapport au débit de transfert qui est élevé).
Cela implique que dans une mémoire \textit{DRAM} il est plus rapide de lire ou d'écrire un bloc de 128 bits successifs que quatre blocs de 32 bits à des endroits différents en mémoire.


\subsubsection*{Importance de la mémoire}
Le processeur interagit en permanence avec la mémoire, que ce soit pour charger des données à traiter ou pour charger les instructions\footnote{Certains processeurs utilisent des instructions de taille fixe, par exemple chaque instruction est encodée sous la forme d'un mot de 32 bits.
  D'autres processeurs, comme ceux qui implémentent l'architecture IA32, utilisent des instructions qui sont encodées sous la forme d'un nombre variable de bytes.
Mais cela n'a au final qu'assez peu d'impact sur le développeur de programmes.}.
Les données échangées (données et instructions) sont représentées sous la forme de nombres binaires.
Il est important de prendre conscience du fait que le processeur doit en permanence charger des données et des instructions depuis la mémoire pour pouvoir exécuter un programme.
Ces échanges peuvent donc avoir un impact sur la vitesse d'exécution comme nous le verrons plus tard.

\subsubsection*{Registre}
Outre des unités de calcul, un processeur contient plusieurs registres.
Un \textit{registre} est une zone de mémoire très rapide se trouvant sur le processeur.
Sur les processeurs courants, cette zone de mémoire permet de stocker un mot de 32 bits ou un long mot de 64 bits.\footnote{Les premiers processeurs disposaient d'un registre unique appelé l'\textit{accumulateur}.
Les processeurs actuels en ont généralement une dizaine ou quelques dizaines.}.
Chaque registre est identifié par un nom ou un numéro et les instructions du processeur permettent d'accéder directement aux données se trouvant dans un registre particulier.
Les registres sont les mémoires les plus rapides qui sont disponibles sur un ordinateur.
Malheureusement, il sont en nombre très limité et il est impossible de faire fonctionner des programmes en utilisant uniquement des registres.

\subsubsection*{Dilemme : Performance VS capacité / prix / faisabilité}
Il serait préférable de pouvoir construire un ordinateur équipé uniquement de \textit{SRAM}, mais au niveau de la capacité et du prix c'est impossible\footnote{Sauf dans quelques cas rares d'applications spécifiques qui nécessitent de hautes performances et se contentent d'une capacité limitée.}.
Les ordinateurs actuels contiennent donc à la fois de la mémoire \textit{SRAM} et de la mémoire \textit{DRAM}.
Avec les registres, les \textit{SRAM} et les \textit{DRAM} composent les 3 premiers niveaux de la \textit{hiérarchie de la mémoire}.
Il est utile de voir comment cette hiérarchie de la mémoire est organisée en pratique en évaluant les différentes alternatives\footnote{En 1980 ce n'était pas vraiment utile car la mémoire était nettement plus rapide que le processeur, mais à partir de 1990 on commence à voir cette tendance s'inverser et les mémoires deviennent un frein par rapport aux processeurs dont les performances se sont fortement améliorées.
Voir slides pour les graphes.}.

\paragraph{Première solution : Répartition d'adresses entre \textit{SRAM} et \textit{DRAM}}
Une première solution pour combiner la \textit{SRAM} et la \textit{DRAM} serait de réserver par exemple les adresses basses à la \textit{SRAM} et les adresses hautes à la \textit{DRAM}.
Avec cette solution, le programme stocké dans la \textit{SRAM} pourrait s'exécuter nettement plus rapidement que le programme stocké en \textit{DRAM}.
Il faudrait alors imaginer que l'OS fournisse des appels système permettant aux applications de demander à déplacer certaines parties du programme et des données en \textit{SRAM}.
Ce genre de solution obligerait chaque application à pouvoir déterminer quelles sont les données et les instructions à exécuter en mémoire \textit{SRAM} pour obtenir de meilleures performances.
Théoriquement, c'est envisageable, mais en pratique ça n'a que très peu de chance de fonctionner.


\paragraph{Deuxième solution : La mémoire cache}
Une deuxième solution est d'utiliser le principe de la \textit{\textbf{mémoire cache}}.
Une mémoire cache est une mémoire de faible capacité mais rapide qui est capable de stocker des données provenant de mémoires de plus grande capacité mais plus lentes.
Cette mémoire cache sert d'interface entre le processeur et la mémoire principale.
Toute demande d'accès à la mémoire principale passe par la mémoire cache comme illustré ci-dessous : \\
\begin{center}
  \includegraphics[width=0.5\textwidth]{memcache1}
\end{center}

\subsubsection*{Mémoire cache}

Ce système de mémoire cache est largement utilisé dans les systèmes informatiques afin d'améliorer les performances.
En pratique, les mémoires cache utilisent le \textit{\textbf{principe de localité}}.
Il existe deux types de localité :
\begin{itemize}
  \item La \emph{localité temporelle} : si un processeur accède à la mémoire à l'adresse $A$ à un instant $t$, il est fort probable qu'il y accédera encore dans les instants qui suivent\footnote{Exemple : lors de l'exécution de boucles qui exécutent à de nombreuses reprises les mêmes instructions.}.
  \item La \emph{localité spatiale} : si un programme a accédé à l'adresse $A$ à l'instant $t$, il est fort probable qu'il accédera aux adresses proches de $A$ comme $A+4$ ou $A-4$ dans les instants qui suivent\footnote{Exemple : lorsqu'un programme traite un vecteur stocké en mémoire.}.
\end{itemize}
\begin{wrapfigure}{r}{0.4\textwidth}
  \vspace{-0.5cm}
  \includegraphics[width=0.45\textwidth]{memhierarchie}
  \caption{\label{fig:memhierarchie}Hiérarchie de la mémoire.}
  \vspace{-0.5cm}
\end{wrapfigure}

Les mémoires caches exploitent ces principes de localité en stockant de façon transparente les instructions et les données les plus récemment utilisées.
D'un point de vue physique, on peut voir le processeur comme étant connecté à la (ou les) mémoire(s) cache qui est (sont) elle-même(s) connectée(s) à la mémoire \textit{RAM}.\\


Les opérations de lecture en mémoire se déroulent généralement comme suit :
\begin{enumerate}
  \item[1.] Le processeur a besoin de lire une donnée se trouvant a une adresse $A$.
    Il fournit donc cette adresse $A$ à la mémoire cache.
  \item[2a.] Si la donnée correspondant à $A$ est présente en mémoire cache, celle-ci répond directement au processeur.
  \item[2b.] Sinon, la mémoire cache interroge la mémoire \textit{RAM}, se met à jour et ensuite fournit la donnée demandée au processeur.
\end{enumerate}
Ce mode de fonctionnement permet de profiter de la localité temporelle.
Pour profiter de la localité spatiale, la plupart des caches se mettent à jour en chargeant directement une \textit{ligne de cache} qui peut compter jusqu'à quelques dizaines d'adresses en mémoire\footnote{Ce qui permet de profiter des mémoires \textit{DRAM} qui aujourd'hui sont souvent optimisées pour fournir des débits de transfert élevés pour de longs blocs consécutifs en mémoire.}.

\paragraph{Opération d'écriture} Pour les opérations d'écriture, la situation est plus compliquée.
Si le processeur écrit l'information $x$ à l'adresse $A$ en mémoire, il faudrait idéalement que cette valeur soit écrite simultanément en mémoire cache et en mémoire \textit{RAM} de façon à s'assurer que la mémoire \textit{RAM} contient toujours des données à jour.
Pour ce faire, analysons les stratégies :
\begin{itemize}
  \item la stratégie d'écriture la plus simple est baptisée \emph{write through}.
    Avec cette stratégie, toute demande d'écriture venant du processeur donne lieu à une écriture en mémoire cache et une écriture en mémoire \textit{RAM}.
    Cela garantit qu'à tout moment la mémoire cache et la mémoire \textit{RAM} contiennent la même information.
    Malheureusement cette technique n'est pas performante et n'est donc pas acceptable;
  \item l'alternative est d'utiliser la technique du \emph{write back}.
    Avec cette technique, toute écriture est faite en mémoire cache directement.
    Ce qui permet d'obtenir de très bonnes performances pour les opérations d'écriture.
    La donnée n'est réécrite en mémoire \textit{RAM} que lorsqu'elle doit être retirée de la mémoire cache.
    Cette réécriture est faite automatiquement par la mémoire cache.
    Pour la plupart des programmes, la gestion des opérations d'écriture est transparente.
    Il faut cependant être attentif à la technique d'écriture utilisée lorsque plusieurs dispositifs peuvent accéder directement à la mémoire \textit{RAM} sans passer par le processeur\footnote{C'est le cas notamment des cartes réseaux ou de certains contrôleurs de disque dur.
      Pour des raisons de performance, ces dispositifs peuvent copier des données directement de la mémoire \textit{RAM} vers le réseau ou un disque dur.
    Si une écriture de type \emph{write back} est utilisée, le système d'exploitation doit veiller à ce que les données qui ont été écrites par le processeur en cache aient bien été écrites également en mémoire \textit{RAM} avant d'autoriser la carte réseau ou le contrôleur de disque dur à effectuer un transfert.}.
\end{itemize}

\section{Étude de cas : Architecture IA32}
Cette architecture recouvre un grand nombre de variantes qui ont leur spécificités propres.
L'architecture IA32 est supportée par différents types de processeurs.
Certains utilisent des registres et des bus de données de 32 bits.
D'autres, plus récents, utilisent des registres de 64 bits.
Il y a des différences importantes entre ces deux architectures.
Comme les processeurs récents supportent à la fois les modes 32 bits et 64 bits, nous nous limiterons à l'architecture 32 bits ici.


Un élément important d'un processeur tel que ceux de l'architecture IA32 sont ses registres.
Un processeur IA32 dispose de huit registres génériques.
Ceux-ci sont baptisés \texttt{EAX}, \texttt{EBX}, \texttt{ECX}, \texttt{EDX}, \texttt{EBP}, \texttt{ESI}, \texttt{EDI} et \texttt{ESP}.
Ces registres peuvent stocker des données sous forme binaire.
Dans l'architecture IA32, ils ont une taille de 32 bits.
Cela implique que chaque registre peut contenir un nombre ou une adresse puisque les entiers (\texttt{int} en \clang{}) et les adresses (pointeurs \texttt{*} en \clang{}) sont tous les deux encodés sur 32 bits dans l'architecture IA32.
Cette capacité à stocker des données ou des adresses à l'intérieur d'un même registre est un des points clés de la flexibilité des microprocesseurs.


\texttt{EBP} et \texttt{ESP} sont utilisés dans la gestion de la pile\footnote{Voir aussi la section \ref{manip_de_la_pile} à la page \pageref{manip_de_la_pile}.}.
%TODO Comme nous le verrons plus tard...

Tout processeur contient un registre spécial qui stocke à tout moment l'adresse de l'instruction courante en mémoire.
Ce registre est souvent dénommé le \emph{compteur de programme} ou \emph{program counter} (PC).
Dans l'architecture IA32, il s'agit du registre \texttt{EIP} qui stocke l'\emph{Instruction Pointer} qui joue ce rôle.
Ce registre ne peut être utilisé pour effectuer des opérations arithmétiques.
Il peut cependant être modifié par les instructions de saut et joue un rôle essentiel dans l'implémentation des instructions de contrôle.


\begin{wraptable}{r}{0.4\textwidth}
  \begin{tabular}{|c|c|c|}
    \hline
    \multirow{2}*{\textbf{Type}} & \textbf{Taille} & \textbf{Suffixe} \\
                                 & \textbf{(bytes)} & \textbf{assembleur} \\
    \hline \hline
    \texttt{char} & 1 & \texttt{b} \\
    \hline
    \texttt{short} & 2 & \texttt{w} \\
    \hline
    \texttt{int} & 4 & \texttt{l} \\
    \hline
    \texttt{long int} & 4 & \texttt{l} \\
    \hline
    \texttt{void *} & 4 & \texttt{l} \\
    \hline
  \end{tabular}
  \caption{\label{table:ia32types}Types de données supportés par les processeurs IA32.}
\end{wraptable}
Outre ces registres génériques, les processeurs de la famille IA32 contiennent aussi des registres spécialisés pour manipuler les nombres en virgule flottante (\texttt{float} et \texttt{double})\footnote{Mais cela dépasse la matière de ce cours.}.
Les processeurs IA32 contiennent également des drapeaux regroupés dans le registre \texttt{eflags}.
Ceux-ci sont utilisés pour implémenter différents tests et comparaisons. \\

Les processeurs qui implémentent les spécifications IA32 supportent les types de données repris dans la table \ref{table:ia32types}.
\\

Voyons maintenant les quelques instructions de l'architecture IA32 qui permettent de manipuler des nombres entiers.

\subsection{Les instructions \texttt{mov}}
Les instructions de la famille\footnote{On parle de famille d'instructions car il existe de nombreuses instructions de déplacement en mémoire.
  Les plus simples sont suffixées par un caractère qui indique le type de données transféré.
Exemple : \texttt{movb} permet le transfert d'un byte tandis que \texttt{movl} permet le transfert d'un mot de 32 bits.} \texttt{mov} permettent de déplacer des données entre registres ou depuis la mémoire vers un registre ou d'un registre vers une zone mémoire.\\

Syntaxe générale :
\begin{lstlisting}[language={[x86masm]Assembler}]
mov src, dest ; deplacement de src vers dest
\end{lstlisting}
Il existe une instruction de la famille \texttt{mov} pour chaque type de donnée pouvant être déplacé : \texttt{movb}, \texttt{movw} et \texttt{movl} qui permettent de déplacer respectivement : 1 byte, un mot de 16 bits, et un mot de 32 bits (voir table \ref{table:ia32types}).
\\

En pratique, il y a plusieurs façons de spécifier chaque argument d'une instruction \texttt{mov}\footnote{Certains auteurs parlent alors de \emph{mode d'adressage} pour représenter ces différents types d'arguments même s'il ne s'agit pas toujours d'adresses.}.
Les différents modes sont :
\begin{itemize}
  \item Le mode \emph{registre} : pour spécifier que la source et/ou la destination est un registre.
    Le nom du registre est alors préfixé par \texttt{\%}.
  \item Le mode d'adressage \emph{immédiat} : ne peut être utilisé que pour l'argument source.
    Il permet de placer une constante dans un registre, par exemple pour initialiser sa valeur.
    Il se reconnaît à l'utilisation du symbole \texttt{\$} comme préfixe de la constante.
  \item Le mode d'adressage \emph{absolu} : dans ce mode, l'un des arguments de l'instruction \texttt{mov} est une adresse en mémoire.
  \item Le mode d'adressage \emph{indirect} : au lieu de spécifier directement une adresse, on spécifie un registre dont la valeur est une adresse en mémoire (à peu près pareil que utilisation des pointeurs en langage \clang{}).
    Il se reconnaît à l'utilisation des parenthèses autour du nom du registre source ou destination.
  \item Le mode avec une \emph{base} et un \emph{déplacement}.
    Ce mode peut être vu comme une extension du mode indirect.
    Il permet de lire en mémoire à une adresse qui est obtenue en additionnant un entier positif ou négatif à une adresse stockée dans un registre.
    Ce mode d'adressage joue un rôle important dans le fonctionnement de la pile.
\end{itemize}

\begin{lstlisting}[language={[x86masm]Assembler}, emph={\$,\%,(,),movl},emphstyle={\color{blue}\bfseries}]
; EXEMPLE MODE REGISTRE
movl %eax, %ebx	; deplacement de %eax vers %ebx
movl %ecx, %ecx	; aucun effet

; EXEMPLE MODE IMMEDIAT
movl $0, %eax		; initialisation de %eax a 0
movl $1252, %ecx	; initialisation de %ecx a 1252

; EXEMPLE MODE ABSOLU
movl 0x04, %eax		; place la valeur contenue a l'adresse 0x04 en memoire dans %eax
movl $1252,	%ecx	; initialisation de %ecx a 1252
movl %ecx, 0x08		; remplace le contenu de la memoire a l'adresse 0x08 par 1252

; EXEMPLE MODE INDIRECT
movl $0x08, %eax	; place la valeur 0x08 dans %eax
movl (%eax), %ecx	; place la valeur se trouvant a l'adresse qui est dans
; %eax dans le registre %ecx
movl 0x10, %eax		; place la valeur se trouvant a l'adresse 0x10 dans %eax
movl %ecx, (%eax)	; place le contenu de %ecx a l'adresse qui est contenue
; dans %eax(0x10)

; EXEMPLE MODE AVEC UNE BASE ET UN DEPLACEMENT
movl $0x08,%eax		; place la valeur 0x08 dans %eax
movl 0(%eax), %ecx	; place la valeur se trouvant a l'adresse 0x08 dans le
; registre %ecx
movl 4(%eax), %ecx	; place la valeur se trouvant a l'adresse 0x0C (=0x08+4) dans
; le registre %ecx
movl -8(%eax), %ecx	; place la valeur se trouvant a l'adresse 0x00 (=0x08-8) dans
; le registre %ecx
\end{lstlisting}
%$
L'architecture IA32 supporte encore d'autres modes d'adressage (non vus dans le cours).
Une autre instruction permettant de déplacer de l'information est l'instruction \texttt{leal} (\textit{load effective address}).
Cette instruction place dans le registre destination l'adresse de son argument source plutot que sa valeur.
Par exemple : \texttt{leal 4(\%esp) \%edx} placera dans le registre \texttt{\%edx} l'adresse de son argument source, c'est-à-dire l'adresse contenue dans \texttt{\%esp+4}.

\subsection{Les instructions arithmétiques et logiques}
La deuxième famille d'instructions importantes sur un processeur contient les instructions qui permettent d'effectuer les opérations arithmétiques et logiques.
Les instructions les plus simples sont celles qui prennent un seul argument :
\begin{itemize}
  \item \texttt{inc} : incrémente d'une unité la valeur stockée dans le registre/l'adresse fournie en argument et sauvegarde le résultat de l'incrémentation au même endroit.
    Cette instruction peut être utilisée pour implémenter des compteurs de boucles.
  \item \texttt{dec} : même principe que \texttt{inc} mais pour décrémenter.
  \item \texttt{not} : applique l'opération logique \texttt{NOT} à son argument et stocke le résultat au même endroit.
\end{itemize}
De même que pour \texttt{mov}, il existe une variante de chaque instruction ci-dessus pour chaque type de données : \texttt{incb}, \texttt{incw}, \texttt{incl},\dots\
(Voir de nouveau la table \ref{table:ia32types}.)\\

L'architecture IA32 supporte également des instructions arithmétiques et logiques prenant deux arguments :
\begin{itemize}
  \item \texttt{add} : permet d'additionner deux nombres entiers.
    Prend comme arguments une source et une destination et place dans la destination la somme de ses deux arguments.
  \item \texttt{sub} : permet de soustraire le premier argument du second.
    Stocke le résultat dans le second.
  \item \texttt{mul} : permet de multiplier des nombres entiers non signés.
    (\texttt{imul} permet la multiplication de nombres signés.)
  \item \texttt{div} : permet la division de nombres entiers non signés.
  \item \texttt{shl} (resp. \texttt{shr} : permet de réaliser un décalage logique vers la gauche (resp. droite).
  \item \texttt{xor} : calcule le ou exclusif (\texttt{XOR}) entre ses deux arguments et sauvegarde le résultat dans le second.
  \item \texttt{and} : calcule la conjonction logique entre ses deux arguments et sauvegarde le résultat dans le second.
\end{itemize}


\subsection{Les instructions de comparaison}
Les comparaisons sont nécessaires pour implémenter des tests tels que \texttt{if (condition) \{ ... \} else \{ ... \}}.
Sur les processeurs IA32, les comparaisons utilisent des drapeaux qui sont mis à jour par le processeur après l'exécution de certaines instructions.
Ceux-ci sont regroupés dans le registre \texttt{eflags}.
Les principaux drapeaux sont :
\begin{itemize}
  \item \emph{ZF} (\textit{Zero Flag}) : indique si le résultat de la dernière opération était zéro;
  \item \emph{SF} (\textit{Sign Flag}) : indique si le résultat de la dernière instruction était négatif;
  \item \emph{CF} (\textit{Carry Flag}) : indique si le résultat de la dernière instruction arithmétique non signée nécessitait plus de 32 bits pour être stocké;
  \item \emph{OF} (\textit{Overflow Flag}) : indique si le résultat de la dernière instruction arithmétique signée a provoqué un dépassement de capacité.
\end{itemize}

Nous utiliserons principalement les drapeaux \textit{ZF} et \textit{SF} dans ce ``chapitre''.
Ces drapeaux peuvent être fixés par les instructions arithmétiques standard, mais aussi par :
\begin{itemize}
  \item \texttt{cmp} : effectue l'équivalent d'une soustraction et met à jour les drapeaux \textit{CF} et \textit{SF} mais sans sauvegarder son résultat dans un registre;
  \item \texttt{test} : effectue une conjonction logique (\texttt{AND}) en mettant à jour les drapeaux mais sans sauvegarder son résultat.
\end{itemize}

Ces instructions de comparaison peuvent être utilisées avec les instructions \texttt{set} qui permettent de fixer la valeur d'un registre en fonction des valeurs de certains drapeaux du registre \texttt{eflags}.
Chaque instruction \texttt{set} prend comme argument un registre.
Pour des raisons historiques, ces instructions modifient uniquement les bits de poids faible du registre indiqué et non le registre complet.
\begin{itemize}
  \item \texttt{sete} : met le registre argument à la valeur du drapeau \textit{ZF}.
    Permet d'implémenter une égalité.
  \item \texttt{sets} : met le registre argument à la valeur du drapeau \textit{SF}.
  \item \texttt{setg} : place dans le registre argument la valeur \texttt{\~{}SF \& \~{}ZF} (tout en prenant en compte les dépassements éventuels avec \texttt{OF}).
    Permet d'implémenter la condition \texttt{>}.
  \item \texttt{setl} : place dans le registre argument la valeur \texttt{SF} (tout en prenant en compte les dépassements éventuels avec \texttt{OF}).
    Permet d'implémenter la condition \texttt{$\leq$}.
\end{itemize}

\subsection{Les instructions sauts}
Les instructions de saut sont des instructions de base pour tous les processeurs.
Elles permettent de modifier la valeur du compteur de programme \texttt{\%eip} de façon à modifier l'ordre d'exécution des instructions.
Elles sont nécessaires pour implémenter les tests, les boucles et les appels de fonction.
Les premiers langages de programmation et les langages tels que le BASIC ou le FORTRAN disposent d'une construction similaire avec l'instruction \texttt{goto}.
Cependant, l'utilisation de l'instruction \texttt{goto} dans des programmes de haut niveau rend souvent le code difficile à lire et de nombreux langages de programmation n'ont plus de \texttt{goto}\footnote{Le \clang{} permet encore l'utilisation de \texttt{goto} (contrairement à \java{}) mais son utilisation est fortement déconseillée !}.
Lors de l'exécution d'un \texttt{goto}, le programme saute directement à l'exécution de l'instruction qui suit le label indiqué.


En assembleur, les instructions de saut sont inévitables.
L'instruction de saut la plus simple est \texttt{jmp}.
Elle prend généralement comme argument une étiquette.
Dans ce cas, l'exécution du programme après l'instruction \texttt{jmp} se poursuivra par l'exécution de l'instruction qui se trouve à l'adresse correspondant à l'étiquette fournie en argument.
Il est également possible d'utiliser l'instruction \texttt{jmp} avec un registre comme argument.
Ainsi, l'instruction \texttt{jmp *\%eax} indique que l'exécution du programme doit se poursuivre par l'exécution de l'instruction se trouvant à l'adresse qui est contenue dans le registre \texttt{\%eax}.\\

Il existe plusieurs variantes conditionnelles de l'instruction \texttt{jmp}.
Ces variantes sont exécutées uniquement si la condition correspondante est vérifiée; les plus fréquentes sont :
\begin{itemize}
  \item \texttt{je} : saut si égal (teste \textit{ZF});
  \item \texttt{jne} : inverse de \texttt{je};
  \item \texttt{js} : saut si négatif (teste \textit{SF});
  \item \texttt{jns} : inverse de \texttt{js};
  \item \texttt{jg} : saut si strictement supérieur (teste \textit{SF} et \textit{ZF} et prend en compte un \textit{overflow} éventuel);
  \item \texttt{jl} : inverse de \texttt{jg} (strictement inférieur);
  \item \texttt{jge} : saut si supérieur ou égal (teste \textit{SF} et prend en compte un \textit{overflow} éventuel);
  \item \texttt{jle} : inverse de \textbf{jge}.
\end{itemize}

Ces variantes sont utilisées pour implémenter des expressions \texttt{if(condition)\{ ...
\} else \{ ...\}} en \clang{} ou pour implémenter des boucles \texttt{while} par exemple.

\subsection{Manipulation de la pile}
\label{manip_de_la_pile}
Les instructions \texttt{mov} permettent de déplacer de l'information à n'importe quel endroit de la mémoire.
À côté de ces instructions de déplacement, il y a des instructions qui sont spécialisées dans la manipulation de la pile.
La pile, qui dans un processus Unix est stockée dans les adresses hautes, est essentielle au bon fonctionnement des programmes.
Par convention, dans l'architecture IA32, l'adresse du sommet de la pile est toujours stockée dans le registre \texttt{\%esp}.

\begin{itemize}
  \item \texttt{pushl \%reg} : place le contenu du registre \texttt{\%reg} au sommet de la pile et décrémente dans le registre \texttt{\%esp} l'adresse du sommet de la pile de 4 unités.
  \item \texttt{popl \%reg} : retire le mot de 32 bits se trouvant au sommet de la pile, le sauvegarde dans le registre \texttt{\%reg} et incrémente dans le registre \texttt{\%reg} l'adresse du sommet de la pile de 4 unités.
\end{itemize}

(En pratique, ces instructions de manipulation de pile pourraient être écrites en utilisant \texttt{subl}, \texttt{movl} et \texttt{addl}, voir p74 des notes de cours).

\subsection{Les fonctions et procédures}
Les fonctions et les procédures sont essentielles dans tout langage de programmation.
Une procédure est une fonction qui ne retourne pas de résultat.

Une procédure est un ensemble d'instructions qui peuvent être appelées depuis n'importe quel endroit du programme.
Généralement, une procédure est appelée depuis plusieurs endroits différents d'un programme.
Considérons d'abord une procédure en \clang{} ne prenant aucun argument (\texttt{void uneProcedure()}) : \\
Le processeur doit transférer l'exécution du code à la première instruction de la procédure appelée.
Cela se fait en associant une étiquette à chaque procédure qui correspond à l'adresse de la première instruction de cette procédure.
Il est également nécessaire que la procédure puisse connaître l'adresse de l'instruction qui doit être exécutée à la fin de son exécution.
Dans l'architecture IA32, cela se fait en utilisant la pile.
Vu l'importance des appels de procédure et de fonction, l'architecture IA32 contient 2 instructions dédicacées pour implémenter ces appels :
\begin{itemize}
  \item \texttt{call} : instruction de saut qui transfère l'exécution à l'adresse de l'étiquette passée en argument et en plus sauvegarde au sommet de la pile l'adresse de l'instruction qui la suit.
    Elle est équivalente à une instruction \texttt{push} suivie d'une instruction \texttt{jmp};
  \item \texttt{ret} : instruction de saut qui suppose que l'adresse de retour se trouve au sommet de la pile, retire cette adresse de la pile et fait un saut à cette adresse.
    Elle est équivalente à une instruction \texttt{pop} suivie d'une instruction \texttt{jmp}.
    Dans l'architecture IA32, le registre \texttt{\%esp} contient en permanence le sommet de la pile, il est donc utilisé par \texttt{call} et \texttt{ret}.
\end{itemize}

La raison pour laquelle il faut à chaque fois qu'une procédure descende
le sommet de la pile au début de son exécution et l'augmente à la
fin est pour respecter une convention de l'architecture IA32 qui veut que les adresses de retour des procédures
soient alignées sur des blocs de 16 bytes.

Considérons maintenant une procédure qui prend un argument.
Pour qu'une telle procédure puisse utiliser son argument,
il faut que la procédure appelante puisse placer sa valeur à un endroit où la procédure appelée peut facilement y accéder.
Dans l'architecture IA32, c'est la pile qui joue ce rôle et permet le passage des arguments.
En \clang{}, les arguments sont passés par valeur et ce sera donc la valeur des arguments qui sera placée sur la pile.
La fonction appelante sauvegarde également d'autres registres sur la pile avant l'appel de la fonction.
Ces sauvegardes sont nécessaires car la fonction appelante ne sait pas quels registres seront modifiés par la fonction qu'elle appelle.
Par convention, dans l'architecture IA32, ce sont les registres \texttt{\%eax}, \texttt{\%edx} et \texttt{\%ecx} qui sont sous la responsabilité de la procédure appelante.
Une procédure appelée peut modifier sans limite les valeurs de ces registres.
D'autre part les registres \texttt{\%ebx}, \texttt{\%edi} et \texttt{\%esi} sont sous la responsabilité de la procédure appelée et doivent être sauvés par celle-ci si elle désire les utiliser/modifier.


Une fonction - contrairement aux procédures - retourne un résultat.
Pour ce faire, il faut que la procédure appelante puisse savoir où aller
chercher ce résultat après l'exécution de l'instruction \texttt{ret}.
La valeur de retour d'une fonction est stockée par convention
dans le registre \texttt{\%eax}.\\

En vue du fonctionnement des appels de fonction en assembleur, on comprend aisément que l'utilisation de fonctions récursives en \clang{} a un coût important au niveau de la gestion de la pile.
Ces appels récursifs doivent donc être réservés à des fonctions où l'appel récursif apporte une plus-value claire et ne peut pas être remplacé par une fonction itérative.

\section{Les threads}
(Voir évolution des performances des processeurs dans le cours pages 95-98.)

La notion de thread d'exécution est très importante
dans un système informatique.
Elle permet de comprendre comment un ordinateur équipé d'un seul microprocesseur
peut exécuter plusieurs programmes simultanément mais aussi comment des programmes
peuvent profiter des nouveaux processeurs (\emph{multi-cœurs} ou
\emph{multi-threadés}), capables d'exécuter plusieurs threads simultanément.

Pour rappel : pour qu'un processeur puisse exécuter une séquence d'instructions,
il faut non seulement qu'il implémente chaque instruction
mais également qu'il puisse accéder :
\begin{itemize}
  \item à la mémoire contenant les instructions à exécuter;
  \item à la mémoire contenant les données manipulées
    par cette séquence d'instructions, c'est-à-dire :
    \begin{itemize}
      \item la zone contenant les variables globales;
      \item le tas;
      \item la pile.
    \end{itemize}
  \item aux registres, et plus particulièrement :
    \begin{itemize}
      \item aux registres de données, pour stocker les résultats de chacune des instructions;
      \item au registre \texttt{\%esp}, directement ou indirectement, via les instructions \texttt{push} et \texttt{pop} de manipulation de la pile;
      \item au registre \texttt{\%eix}, qui contient l'adresse de l'instruction en cours d'exécution;
      \item au registre \texttt{eflags}, qui contient l'ensemble des drapeaux.
    \end{itemize}
\end{itemize}

Un processeur multithreadé a la capacité d'exécuter plusieurs programmes simultanément. Pour ce faire, il disposera de copies des registres.
Chacun de ces blocs de registres pourra être utilisé pour exécuter ces programmes
simultanément à raison d'un thread d'exécution par bloc de registres.
Chaque thread d'exécution va correspondre à une séquence différente d'instructions qui va modifier son propre bloc de registres.\\
Cette capacité d'exécuter plusieurs threads d'exécution simultanément n'est pas limitée à un thread d'exécution par programme puisqu'au final, un thread d'exécution n'est finalement qu'une séquence d'instructions qui utilisent un bloc de registres.
En pratique, pour qu'un programme puisse démarrer un nouveau thread d'exécution sur un nouveau bloc de registre, cela nécessite la coopération avec l'OS.
Le mécanisme le plus courant pour ce faire est connu sous le nom de \emph{threads POSIX}.



\subsection{Les threads POSIX}
Les threads POSIX sont supportés par la plupart des variantes Unix et sont souvent implémentés dans une librairie (\texttt{pthreads} sous linux).
Les fonctions importantes de cette librairie sont :
\begin{itemize}
  \item \texttt{\textbf{int} pthread\_create(pthread\_t *\textbf{restrict thread}, \textbf{const} pthread\_attr\_t *\textbf{restrict} attr, \textbf{void} *(*start\_routine)(\textbf{void} *), \textbf{void} *\textbf{restrict} arg);}\\
    Permet de créer un nouveau thread d'exécution\footnote{Il est important de veiller à ce que le quatrième
     argument passé à \texttt{pthread\_create}
     existe toujours (et n'ait pas été modifié) au moment de l'exécution
     effective de la fonction qui démarre le thread lancé.};
  \item \texttt{\textbf{int} pthread\_join(pthread\_t \textbf{thread}, \textbf{void} **value\_ptr);}\\
    Permet de récupérer le résultat d'un thread d'exécution.
    L'appel de \texttt{pthread\_join} ne se terminera que lorsque le thread spécifié se termine;
  \item \texttt{\textbf{void} pthread\_exit(\textbf{void} *retval);}\\
    Le thread qui exécute cette fonction se termine et retourne la valeur \texttt{retval} au thread parent.
    (Également possible avec un \texttt{return};)
  \item \texttt{\textbf{int} pthread\_attr\_setstackaddr(pthread\_attr\_t *attr, \textbf{void} *stackaddr); }\\
    Permet de modifier la taille de la pile d'un thread POSIX (utile si on sait qu'un thread devra allouer un grand tableau auquel il sera le seul à avoir accès).
\end{itemize}

\subsubsection{Variables \texttt{volatile}}
Normalement, dans un programme \clang{}, lorsqu'une variable est définie, ses accès sont contrôlés entièrement par le compilateur.
Si une variable est utilisée dans plusieurs calculs successifs, afin d'obtenir de bonnes performances, il peut être utile de stocker sa valeur dans un registre durant le temps des calculs.
Mais, dans le cas où cette valeur pourrait être modifiée par d'autres threads simultanément, il peut être utile d'indiquer qu'il faut recharger sa valeur avant chaque calcul. Cela se fait en utilisant le qualificatif \texttt{volatile} qui indique au compilateur qu'il doit recharger la variable de la mémoire chaque fois qu'elle est utilisée.
(À utiliser avec précaution, voir partie sur les \textit{mutex} etc.)

\subsubsection{Variable spécifique à un thread}
Pour ce faire, il existe 2 solutions :
\begin{itemize}
  \item utiliser le qualificatif \texttt{\_\_thread} devant une déclaration de variable (supporté par \texttt{gcc} avec la librairie threads POSIX);
  \item utiliser les fonctions fournies par la librairie threads POSIX suivantes : \texttt{pthread\_key\_create}, \texttt{pthread\_key\_set}, \texttt{pthread\_setspecific}, \texttt{pthread\_getspecific} et \texttt{pthread\_key\_delete}.
\end{itemize}
La deuxième solution est plus compliquée à utiliser mais illustre ce qu'il se passe en pratique lorsque le qualificatif \texttt{\_\_thread} est utilisé.

\subsection{Fonctions \textit{thread-safe}}
Certaines fonctions (même de la librairie standard) sont susceptibles d'utiliser des variables globales dans leur exécution, et utilisent l'hypothèse qu'elles sont appelées par un programme séquentiel, ce qui peut poser des problèmes.
Lorsque l'on développe une fonction qui peut être réutilisée, il est important de s'assurer que cette fonction peut être exécutée par plusieurs threads simultanément sans que cela ne pose de problème à l'exécution.
C'est pourquoi lorsque l'on intègre des fonctions provenant de la librairie standard ou d'une autre librairie dans un programme découpé en threads, il est important de vérifier que les fonctions utilisées sont bien \textbf{\textit{thread-safe}}.
La page de manuel \texttt{man 7 pthreads} liste les fonctions qui ne le sont pas.



\section{Threads communicants}
Lorsqu'un programme est décomposé en plusieurs threads, ceux-ci doivent en général communiquer entre eux.

\begin{wrapfigure}{r}{0.4\textwidth}
  \vspace{-0.5cm}
  \includegraphics[width=0.5\textwidth]{memthread}
  \caption{\label{fig:memthread}Organisation de la mémoire après la création d'un thread POSIX.}
  \vspace{-0.7cm}
\end{wrapfigure}
Le programme principal et le thread qu'il a créé partagent 3 zones de mémoire :
\begin{itemize}
  \item le \emph{segment text} (contient l'ensemble des instructions);
  \item le \emph{segment de données} (contient toutes les données statiques, initialisées ou non);
  \item le \emph{heap}.
\end{itemize}
Par contre, le programme principal et le thread qu'il vient de créer ont chacun leur propre contexte et leur propre pile.

\subsection{Loi de Amdahl}
Gene Amdahl considère qu'un programme $P$ peut être découpé en deux parties :
\begin{itemize}
  \item une partie purement séquentielle.
    Il s'agit par exemple de l'initialisation de l'algorithme utilisé, de la collecte des résultats,\dots;
  \item une partie qui est parallélisable.
    Il s'agit en général du cœur de l'algorithme.
\end{itemize}
Plus les opérations réalisées à l'intérieur d'un programme sont indépendantes entre elles, plus le programme est parallélisable et inversement.\\
Pour Amdahl, si le temps d'exécution d'un programme séquentiel est $T$ et qu'une fraction $f$ de ce programme est parallélisable, alors le gain qui peut être obtenu de la parallélisation en $N$ threads est :

\begin{figure}[!htb]
\[ \frac{T}{T ((1-f) + \frac{f}{N}} = \frac{1}{(1-f) + \frac{f}{N}} \]
\caption*{Loi de Amdahl.}
\end{figure}

Cette loi fixe une limite théorique difficile à atteindre et suppose que la parallélisation est parfaite c'est-à-dire que la création et la terminaison des threads n'ont aucun coût en performance.
%\begin{wrapfigure}{r}{0.4\textwidth}
%\vspace{-0.7cm}
%\includegraphics[width=0.5\textwidth]{amdahl}
%\caption{\label{fig:amdahl}Illustration de la loi d'Amdahl}
%\vspace{-0.7cm}
%\end{wrapfigure}
\subsection{Communication entre threads}
Le première façon pour un processus de communiquer des infos avec un thread qu'il a lancé est d'utiliser les arguments de la fonction de démarrage du thread et la valeur retournée par ce thread.
Mais c'est un canal de communication très limité qui ne permet pas d'échange d'information pendant l'exécution du thread.

Un processus peut partager facilement de l'information avec ses threads ou même entre plusieurs threads car tous les threads ont accès aux mêmes variables globales et au même \textit{heap}.
Malheureusement, la modification d'une variable globale ou d'une zone mémoire (allouée par \texttt{malloc}) peut être source de problèmes si plusieurs threads accèdent à la même donnée en même temps.\\
Ce problème d'accès à une même donnée est connu sous le nom de problème de la \emph{section critique} ou de l'\emph{exclusion mutuelle}.
La \emph{section critique} peut être définie comme étant une séquence d'instructions qui ne peuvent jamais être exécutées par plusieurs threads simultanément.
En pratique, on retrouvera une section critique chaque fois que deux threads peuvent modifier ou lire la valeur d'une même zone de la mémoire.
Afin d'éviter ce problème il faut utiliser la coordination entre threads.

\subsection{Coordination entre threads}
\subsubsection{Exclusion mutuelle - Dijkstra}
Le problème de l'exclusion mutuelle à été initialement proposé par Dijkstra (en 1965).
Il peut être reformulé de la façon suivante pour un programme décomposé en threads. \\

Considérons un programme à $N$ threads.
Chaque thread est exécuté cycliquement et possède une section critique et une section non critique.
La durée d'exécution de chaque partie n'est pas connue et peut être différente pour chaque thread.
Le problème de l'exclusion mutuelle consiste à trouver un algorithme qui permet de garantir qu'il n'y aura jamais deux threads qui, simultanément, exécuteront les instructions de leur section critique.\\
\\
Cela revient à dire qu'il n'y aura pas de violation de la section critique.
Cette propriété est une propriété de \textbf{\textit{sureté}} (\textit{safety}).
Dans un programme découpé en threads, une propriété de \textit{sureté} est une propriété qui doit être vérifiée à tout instant de l'exécution du programme.

\paragraph{Conditions à satisfaire pour résoudre le problème de l'exclusion mutuelle}
\begin{enumerate}
  \item Tous les threads doivent être considérés de la même façon, on ne peut faire aucune hypothèse sur la priorité relative des différents threads.
  \item On ne peut faire aucune hypothèse sur la vitesse relative ou absolue d'exécution des différents threads.
  \item Doit permettre à un thread de s'arrêter en dehors de sa section critique sans que cela n'invalide la contrainte d'exclusion mutuelle.
  \item Aucun thread qui souhaite entamer sa section critique ne doit être empêché indéfiniment d'y accéder.
\end{enumerate}

La quatrième contrainte est un exemple de propriété de \textit{\textbf{vivacité}} (\textit{liveness}).
Une propriété de \textit{vivacité} est une propriété qui ne peut pas être éternellement invalidée.

\subsubsection*{Exclusion mutuelle sur monoprocesseurs}
Sur un ordinateur monoprocesseur, un OS multitâche tel que Unix exécute régulièrement des changements de contexte entre threads.
Le \textit{\textbf{contexte}} d'un thread est composé de l'ensemble des contenus des registres qui sont nécessaires à son exécution (y compris le contenu des registres spéciaux tels que \texttt{\%esp}, \texttt{\%eip} et \texttt{\%eflags}).
Ces registres définissent l'état du thread du point de vue du processeur. \\
Pour passer d'un thread $T_1$ à un thread $T_2$, l'OS doit initier un \textbf{\textit{changement de contexte}}.
Pour ce faire il copie le contenu des registres utilisés par $T_1$ vers une zone mémoire lui appartenant puis transfère depuis une autre zone mémoire lui appartenant le contexte de $T_2$.\\

Sur un système Unix, il y a 2 types d'événements qui peuvent provoquer un changement de contexte :
\begin{itemize}
  \item le \textit{hardware} génère une \textit{interruption};
  \item un thread exécute un \textit{appel système bloquant}.
\end{itemize}

\paragraph{Interruption} Une interruption est un signal électronique qui est généré par un dispositif connecté au microprocesseur. De nombreux dispositifs d'entrée-sortie comme les cartes réseau ou les contrôleurs de disque peuvent générer une interruption lorsqu'une information a été lue ou reçue et doit être traitée par le processeur.
En outre, chaque ordinateur dispose d'une horloge temps réel qui génère des interruptions à une fréquence déterminée par l'OS (entre quelques dizaines et quelques milliers de \si{\hertz}).
Ces interruptions nécessitent un traitement rapide de la part de l'OS; c'est pourquoi le processeur vérifie, à la fin de l'exécution de \textit{chaque} instruction, si un signal d'interruption est présent\footnote{Le cours se limite à un seul type de signal d'interruption.}.
Si c'est le cas, le processeur sauvegarde en mémoire le contexte du thread en cours d'exécution et lance une routine de traitement d'interruption faisant partie du système d'exploitation.

\paragraph{Appel système} Un thread exécute un appel système chaque fois qu'il doit intéragir avec l'OS.
Ces appels peuvent être exécutés directement ou via une fonction de la librairie\footnote{La section \texttt{2} du manuel décrit les appels systèmes, la section \texttt{3} décrit les fonctions de la librairie.}.

\begin{itemize}
  \item Un \textbf{Appel système non bloquant} est un appel système que l'OS peut exécuter immédiatement.
    Ce type d'appel retourne en général une valeur qui fait partie de l'OS lui-même (par exemple \texttt{gettimeofday}).
  \item Un \textbf{Appel système bloquant} est un appel système dont le résultat ne peut pas toujours être fourni immédiatement (par exemple la lecture d'informations en provenance de l'entrée standard).
    Dans ce cas, le thread est mis en attente et aucune instruction de ce thread n'est exécutée tant que le résultat n'est pas connu.
    Le contexte du thread est mis en attente dans une zone mémoire gérée par l'OS.
    Il sera redémarré automatiquement lorsque la donnée attendue sera disponible.
\end{itemize}

La figure \ref{fig:appelsbloquant} représente les différents états d'un thread.
Lorsqu'un thread est créé (avec \texttt{pthread\_create}), il est placé dans l'état \textit{Ready}. \\
\begin{wrapfigure}{r}{0.45\textwidth}
  \vspace{-0.5cm}
  \includegraphics[width=0.55\textwidth]{appelsbloquant}
  \caption{\label{fig:appelsbloquant}États d'un thread d'exécution.}
  \vspace{-0.5cm}
\end{wrapfigure}

Les transitions entre les différents états d'un thread sont gérées par l'OS.
Lorsque plusieurs threads d'exécution sont simultanément actifs, l'OS doit arbitrer les demandes d'utilisation du CPU de chaque thread.
Cet arbitrage est réalisé par l'\textit{\textbf{ordonnanceur}} (ou \textbf{\textit{scheduler}}).


\paragraph{\textit{scheduler}} Le \textit{scheduler} est un ensemble d'algorithmes qui sont utilisés par l'OS pour sélectionner le ou les threads qui peuvent utiliser un processeur à un moment donné.
Citons quelques principes de base de fonctionnement de quelques \textit{schedulers} :
\begin{itemize}
  \item \textbf{le \textit{scheduler \textbf{round-robin}}} : ce scheduler maintient en permanence une liste circulaire de l'ensemble des threads qui se trouvent dans l'état \textit{Ready} et un pointeur vers l'élément courant de cette liste.
    En général ce type de \textit{scheduler} limite le temps passé sur un processeur afin d'éviter qu'un thread ne le monopolise.
    Un scheduler \textit{round-robin} est équitable, si $N$ threads sont actifs en permanence, ils recevront chacun $\frac{1}{N}$ de temps CPU disponible.
  \item \textbf{le \textit{scheduler} à priorités} : une priorité est associée à chaque thread.
    Lorsque le \textit{scheduler} doit sélectionner un thread à exécuter, il commence d'abord par parcourir les threads ayant une haute priorité.
    En pratique le \textit{scheduler} maintient une liste circulaire par niveau de priorité et s'il y a plusieurs threads pour un niveau de priorité, il utilisera le principe du \textit{round-robin} pour le niveau en question.
\end{itemize}
Sous Unix, il s'agit d'un \textit{scheduler} à priorité avec un \textit{round-robin} à chaque niveau de priorité, mais la priorité varie dynamiquement en fonction du temps et des opérations d'entrée-sortie effectuées de façon à favoriser les threads interactifs.

\paragraph{Note}
Il est possible à un thread d'indiquer explicitement  qu'il peut être remplacé par un autre thread en utilisant \texttt{pthread\_yield} (par exemple utile si on a un thread qui calcule des statistiques et ne doit pas ralentir le fonctionnement des autres threads).

\paragraph{Problème de l'exclusion mutuelle, le retour !}
Sur une machine monoprocesseur, une violation de la section critique ne serait possible que s'il y a une interruption lorsqu'on est dans celle-ci.
Une solution pour résoudre le problème serait donc de désactiver les interruptions avant la section critique puis de les réactiver après la fin de celle-ci.
Ce serait possible mais il y a quelques problèmes néanmoins :
\begin{itemize}
  \item ça perturbe le fonctionnement de l'OS : sans interruptions, la plupart des opérations d'entrée-sortie et l'horloge sont inutilisables, donc cette désactivation doit être très courte;
  \item il s'agit d'une opération privilégiée sur un microprocesseur. Il faudrait donc imaginer un appel système qui permettrait à un thread de faire la demande auprès de l'OS;
  \item si un thread désactivait les interruptions sans les réactiver après quelques instants, cela rendrait la machine complètement inutilisable puisque sans interruptions, plus aucune opération d'entrée-sortie n'est possible.
\end{itemize}
\paragraph{Conclusion}
Ce n'est pas un mécanisme utilisable\footnote{Bien que ce soit parfois utilisé par certains OS qui l'utilisent à l'intérieur de l'OS même.} !

\subsubsection*{L'algorithme de Peterson}
Cette solution permet à plusieurs threads de coordonner leur exécution de façon à éviter une violation de section critique en utilisant uniquement des variables accessibles à tous les threads.
La solution est applicable à $N$ threads mais nous nous limiterons à 2 threads.

\begin{lstlisting}
#define A 0
#define B 1
int flag[];
flag[A]=false;
flag[B]=false;
// thread A
void* threadA(void* ){
  flag[A]=true;
  turn=B;
  while((flag[B]==true)&&(turn==B)) { /* loop */ }
  section_critique();
  flag[A]=false;
  // ...
}
// thread B
void* threadB(void* ){
  flag[B]=true;
  turn=A;
  while((flag[A]==true)&&(turn==A))
  { /* loop */ }
  section_critique();
  flag[B]=false;
  // ...
}
\end{lstlisting}

Pour arriver à cet algorithme, les pages 114 à 117 du cours expliquent les différents raisonnements et problèmes qui y sont liés.
Il faut être attentif au \textit{livelock} et aux conditions énoncées précédemment pour résoudre l'exclusion mutuelle.
Un \textit{livelock} est une situation dans laquelle plusieurs threads exécutent une séquence d'instructions (par exemple une boucle \texttt{while}) sans qu'aucun thread ne puisse réaliser de progrès.
Un \textit{livelock} est un problème gênant puisque lorsqu'il survient, les threads concernés continuent à utiliser le processeur mais n'exécutent aucune instruction utile. \\

\subsubsection*{Utilisation d'instructions atomiques}
Sur les ordinateurs actuels, il est difficile d'utiliser l'algorithme de Peterson tel que décrit plus haut pour différentes raisons :
\begin{itemize}
  \item les compilateurs optimisent le code et peuvent supprimer les instructions qui semblent inutiles;
  \item sur un ordinateur multiprocesseur, chaque processeur peut réordonner les accès à la mémoire automatiquement afin d'en optimiser les performances. La lecture et l'écriture en mémoire ne se font donc pas toujours dans le même ordre que celui prévu initialement;
\end{itemize}
Pour résoudre ce problème, les architectes de microprocesseurs ont proposé l'utilisation d'opérations atomiques.
Une \textbf{opération atomique} est une opération qui, lorsqu'elle est exécutée sur un processeur, ne peut pas être interrompue par l'arrivée d'une interruption.
De plus, l'exécution d'une instruction atomique par un ou plusieurs processeurs implique une coordination des processeurs pour l'accès à la zone mémoire référencée dans l'instruction.
Via un mécanisme qui sort du cadre de ce cours, tous les accès à la mémoire faits par les instructions atomiques sont réalisées séquentiellement. \\
\\
Considérons l'instruction \texttt{xchg} supportée par les processeurs IA32.
Cette instruction permet d'échanger, de façon atomique, le contenu d'un registre avec une zone de la mémoire.
Elle prend deux arguments : un registre et une adresse en mémoire.
Elle est équivalente à trois instructions \texttt{mov} successives. \\
Avec cette instruction atomique, il est possible de résoudre le problème de l'exclusion mutuelle en  utilisant une zone mémoire (\texttt{lock}) qui prend la valeur \texttt{1} ou \texttt{0}.
Lorsqu'un thread veux exécuter sa section critique, il place la valeur \texttt{1} dans un de ses registres et échange ce registre avec la zone mémoire \texttt{lock} en utilisant \texttt{xchg}.
Si la valeur de son registre est 0, c'est qu'il peut rentrer dans sa section critique, sinon c'est qu'un autre thread est dans la section critique.
Pour quitter la section critique il suffit ensuite de placer la valeur \texttt{0} en utilisant de nouveau \texttt{xchg}.
Le code ci-dessous montre un exemple.
\begin{lstlisting}[language={[x86masm]Assembler}, emph={\$,\%,(,),movl},emphstyle={\color{blue}\bfseries}]
lock:                 ; etiquette, variable
.long   0             ; initialisee a 0

enter:
movl    $1, %eax      ; %eax=1
xchgl   %eax, (lock)  ; instruction atomique, echange (lock) et %eax
; apres execution, %eax contient la donnee qui etait
; dans lock et lock la valeur 1
testl   %eax, %eax    ; met le flag ZF a TRUE si %eax contient 0
jnz     enter         ; retour a enter: si ZF est TRUE
ret

leave:
mov     $0, %eax      ; %eax=0
xchgl   %eax, (lock)  ; instruction atomique
ret
\end{lstlisting}

\subsubsection*{Coordination par \textit{mutex}}
L'algorithme de Peterson et l'utilisation d'instructions atomiques sont des mécanismes de base permettant de résoudre le problème de l'exclusion mutuelle.
Ils sont utilisés par des fonctions de la librairie POSIX threads.
Il est préférable de ne pas les utiliser directement pour des raisons de portabilité et de spécificités matérielles.
Il faut donc utiliser les fonctions de la librairie POSIX threads.

\paragraph{Les mutex}
Un \textbf{mutex}\footnote{Abréviation de \textit{mutual exclusion}.} est une structure de données qui permet de contrôler l'accès à une ressource.
Un \textit{mutex} qui contrôle une ressource peut se trouver dans 2 états :
\begin{itemize}
  \item \textbf{libre} (ou \textit{unlocked})
  \item \textbf{réservé} (ou \textit{locked})
\end{itemize}
Un mutex est toujours associé à une ressource.
Cette ressource peut être une variable globale, une structure de données plus complexe, une base de données, un fichier,\dots\
Les mutex s'utilisent par l'intermédiaire de 2 fonctions :
\begin{itemize}
  \item \textit{lock} (\texttt{pthread\_mutex\_lock}) : pour obtenir le verrou.
    Attend que la ressource se libère si elle est bloquée;
  \item \textit{unlock} (\texttt{pthread\_mutex\_unlock}) : pour libérer le verrou (à la fin de la section critique).
    Si un thread est en attente, \textit{unlock} laisse le verrou mais autorise le (un seul) thread en attente à passer son \textit{lock}.
\end{itemize}


En \clang{}, un mutex est représenté par une structure de données \texttt{pthread\_mutex\_t} qui est définie dans \texttt{pthread.h} et qu'il faut initialiser avec \texttt{pthread\_mutex\_init} et détruire avec \texttt{pthread\_mutex\_destroy} afin de libérer les ressources qui y sont associées.

Montrons que cette solution de mutex répond bien au problème de l'exclusion mutuelle.
La propriété de sûreté est bien respectée puisqu'aucun thread ne pourra entrer dans sa section critique si un autre s'y trouve déjà (et 2 threads ne peuvent y rentrer en même temps).
La propriété de vivacité est respectée si chaque thread exécute \texttt{pthread\_mutex\_unlock} dès qu'il sort de sa section critique, c'est donc une règle à toujours respecter ! Pour qu'un thread ne puisse jamais entrer en section critique, il faudrait qu'il y aie en permanence plusieurs threads en attente et que notre thread ne soit jamais sélectionné par le système lorsque le thread précédent termine sa section critique.


\subsubsection{Le problème des philosophes et \textit{deadlock}}
\begin{wrapfigure}{r}{0.2\textwidth}
  \vspace{-0.5cm}
  \includegraphics[width=0.2\textwidth]{philosophes}
  \caption{\label{fig:philosophes}Problème des philosophes.}
\end{wrapfigure}
Le problème des philosophes est résumé sur la figure \ref{fig:philosophes}.
Chacun veut saisir la baguette à sa droite et à sa gauche, qui sont chacune partagées avec (respectivement) son voisin de droite et de gauche.

Le problème est que si tout le monde commence par prendre la baguette de gauche, il n'y a plus de baguette de droite disponible (puisqu'elle est à gauche de votre voisin de droite) et donc on se trouve dans une impasse.
Il s'agit d'un \textbf{\textit{deadlock}}.
Un programme est en situation de \textit{deadlock} lorsque tous ses threads d'exécution sont bloqués et qu'aucun d'entre eux ne peut être débloqué sans exécuter d'instructions d'un des threads bloqués.
La seule façon de sortir d'un programme dans une situation de \textit{deadlock} est de l'arrêter complètement et de le redémarrer.
C'est donc un problème grave !\\
\paragraph{Attention}
Les tests successifs ne permettent pas toujours de détecter les \textit{deadlocks}. Il se peut qu'ils ne se produisent qu'après un temps assez long.


\paragraph{Solution}
Une solution au problème des philosophes serait d'ordonner les baguettes (leur assigner un numéro par exemple), et de faire en sorte que les philosophes les prennent toujours dans le même ordre comme présenté ci-dessous.
Cette solution fonctionne, néanmoins, il faut être conscient qu'avec cette solution il est possible qu'un seul philosophe mange alors que tous les autres attendent, ce qui est une perte de performance énorme lorsqu'il y a beaucoup de philosophes!
\begin{lstlisting}
void* philosophe ( void* arg )
{
  int *id=(int *) arg;
  int left = *id;
  int right = (left + 1) % PHILOSOPHES;
  while(true) {
    // philosophe pense
    if(left<right) {
      pthread_mutex_lock(&baguette[left]);
      pthread_mutex_lock(&baguette[right]);
    }
    else {
      pthread_mutex_lock(&baguette[right]);
      pthread_mutex_lock(&baguette[left]);
    }
    mange(*id);
    pthread_mutex_unlock(&baguette[left]);
    pthread_mutex_unlock(&baguette[right]);
  }
  return (NULL);
}
\end{lstlisting}


Ce problème des philosophes est à l'origine de la règle de bonne pratique suivante : pour éviter les \textit{deadlocks}, il est nécessaire d'ordonnancer tous les mutex utilisés par le programme dans un ordre strict.
Lorsqu'un thread doit réserver plusieurs mutex en même temps, il doit \textit{toujours} effectuer ses appels à \texttt{pthread\_mutex\_lock} dans l'ordre choisi pour les mutex.
(Sinon \textit{deadlock} possible.)

\subsubsection{Les sémaphores}
Il s'agit d'une autre solution au problème de la coordination entre threads.
Un \textbf{\textit{sémaphore}} est une structure de données qui est maintenue par l'OS et contient :
\begin{itemize}
  \item un entier qui stocke la valeur, $\geq 0$, du sémaphore;
  \item une \textit{queue} qui contient les pointeurs vers les threads qui sont bloqués en attente sur le sémaphore.
\end{itemize}

L'implémentation d'un sémaphore contient 4 fonctions principales :
\begin{itemize}
  \item une fonction d'initialisation du sémaphore : (\texttt{int sem\_init(sem\_t *sem, int pshared, unsigned int value);});
  \item une fonction permettant de détruire le sémaphore et de libérer les ressources associées : (\texttt{int sem\_destroy(sem\_t *sem);});
  \item une fonction \texttt{post} qui permet d'incrémenter la valeur du sémaphore ou de débloquer un thread en attente (s'il y en a un) : (\texttt{int sem\_post(sem\_t *sem);});
  \item une fonction \texttt{wait} qui permet de tester la valeur du sémaphore, si elle est $>0$, décrémente le sémaphore et continue, sinon bloque le thread et attend qu'un autre thread fasse un \texttt{post} : (\texttt{int sem\_wait(sem\_t *sem);}).
\end{itemize}

Dans le cadre de ce cours nous nous limitons au sémaphores POSIX.
Pour pouvoir les utiliser il faut importer \texttt{semaphore.h} qui contient les différentes signatures (dont celles reprises dans la liste ci-dessus) et la structure de données de type \texttt{sem\_t}.


\paragraph{Exclusion mutuelle}~\\
Les sémaphores permettent de résoudre le problème de l'exclusion mutuelle.
En fait lorsque le sémaphore est initialisé à \texttt{1}, on peut l'utiliser de manière semblable à un mutex.
Néanmoins il y a des différences importantes : un sémaphore est conçu pour être manipulé par différents threads et il est très possible qu'un thread exécute \texttt{sem\_wait} et qu'un autre exécute \texttt{sem\_post}.
Pour les mutex, certaines implémentations supposent que c'est le même thread qui exécute le \texttt{lock} et le \texttt{unlock}.
Lorsque ces opérations doivent être effectuées dans des threads différents, il est donc préférable d'utiliser des sémaphores à la place des mutex.

\paragraph{Problème du rendez-vous}~\\
Ce problème est rencontré lorsqu'une application découpée en $N$ threads doit attendre la fin de l'exécution d'une première phase dans les $N$ threads avant de pouvoir passer à la suite.
Chaque thread peut être résumé par une première phase, suivie d'un endroit de ``rendez-vous'' pour tous les threads et d'une deuxième phase.
La solution est la suivante :
\begin{lstlisting}
premiere_phase();

pthread_mutex_lock(&mutex);		//section critique pour count
count++;
if(count==N) {					// si tous les threads sont arrives
  sem_post(&rendezvous);
}
pthread_mutex_unlock(&mutex);	//fin de section critique
sem_wait(&rendezvous);			//attente a la "barriere"
sem_post(&rendezvous);			//liberation d'un autre thread en attente

seconde_phase();
\end{lstlisting}
Cette solution permet de résoudre le problème du rendez-vous avec un nombre fixe de threads\footnote{Certaines implémentations de la librairie threads POSIX implémentent une barrière similaire à la solution ci-dessus.
  Une barrière est une structure de données de type \texttt{pthread\_barrier\_t}.
  Elle s'initialise en utilisant la fonction \texttt{pthread\_barrier\_init} qui prend 3 arguments : un pointeur vers une barrière, des attributs optionnels et le nombre de threads qui doivent avoir atteint la barrière pour que celle-ci s'ouvre.
  La fonction \texttt{pthread\_barrier\_destroy} permet de détruire une barrière.
Enfin, la fonction \texttt{pthread\_barrier\_wait} qui prend comme argument un pointeur vers une barrière et synchronise les threads participants à cette barrière.}.

\paragraph{Problème des producteurs-consommateurs}~\\
Soit une application découpée en deux types de threads (dont le nombre n'est pas connu ni fixe à priori) :
\begin{itemize}
  \item les \textit{producteurs} : produisent des données et placent le résultat dans une zone mémoire accessible aux consommateurs;
  \item les \textit{consommateurs} : utilisent les données produites par les producteurs.
\end{itemize}
Ces deux types de threads communiquent en utilisant un buffer qui a une capacité limitée à $N$ \textit{slots} comme sur la figure \ref{fig:prodcons}
\begin{figure}[h!]
  \centering\includegraphics[width=0.5\textwidth]{prodcons}
  \caption{\label{fig:prodcons}Problème des producteurs-consommateurs.}
\end{figure}
Le buffer étant partagé, il est nécessaire d'utiliser un mutex pour protéger son accès.
Un producteur ne doit être bloqué que si tout le buffer est rempli et inversement, un consommateur ne doit être bloqué que si tout le buffer est vide.
Le problème peut être résolu avec 2 sémaphores comme le montrent les extraits de code ci-dessous.
\begin{lstlisting}
...
// Dans la fonction principale : initialisation
#define N 10 // nbre de slots du buffer
pthread_mutex_t mutex; 	sem_t empty; sem_t full;

pthread_mutex_init(&mutex, NULL);
sem_init(&empty, 0 , N);  // empty compte le nbre de slot vide => N = buffer vide
sem_init(&full, 0 , 0);   // full compte le nbre de slot rempli => 0 = buffer vide
...
// Le Producteur
void producer(void){
  int item;
  while(true){
    item=produce(item);
    sem_wait(&empty); 		     // attente d'un slot libre
    pthread_mutex_lock(&mutex);  	// section critique
    insert_item();
    pthread_mutex_unlock(&mutex);	// fin de section critique
    sem_post(&full); 			// il y a un slot rempli en plus
  }
}

// Le Consommateur
void consumer(void){
  int item;
  while(true){
    sem_wait(&full); 			// attente d'un slot rempli
    pthread_mutex_lock(&mutex); 	// section critique
    item=remove(item);
    pthread_mutex_unlock(&mutex);
    sem_post(&empty);              // il y a un slot libre en plus
  }
}
\end{lstlisting}

\paragraph{Problème des \textit{readers-writers}}~\\
Soit de nouveau une application découpé en deux types de threads (dont le nombre n'est pas connu ni fixe à priori) :
\begin{itemize}
  \item les lecteurs (\textit{readers}), qui lisent des données partagées mais ne les modifient pas;
  \item les écrivains (\textit{writers}), qui modifient des données partagées.
\end{itemize}
Plusieurs \textit{readers} peuvent lire en même temps, mais lorsqu'un \textit{writer} modifie les données, il ne peut y avoir d'autres \textit{writers} ni de \textit{readers} qui utilisent les données.
Lorsqu'on cherche une solution à ce problème, il faut faire attention à ne pas donner priorité aux \textit{readers} (ce qui serait plus simple).
Une solution au problème est présentée dans les extraits de code ci-dessous\footnote{Certaines implémentations de la librairie threads POSIX contiennent des \textit{read-write} \textit{locks} qui s'appuient sur des sémaphores pour résoudre le problème des \textit{readers-writers}\dots}.
\begin{lstlisting}
/* Initialisation */
pthread_mutex_t mutex_readcount; 	        // protege readcount
pthread_mutex_t mutex_writecount; 	        // protege writecount
pthread_mutex_t z; 				        // un seul reader en attente
sem_t wsem;       				        // acces exclusif a la db
sem_t rsem;					        // pour bloquer des readers
int readcount=0;
int writecount=0;
sem_init(&wsem, 0, 1);
sem_init(&rsem, 0, 1);

/* Writer */
while(true){
  think_up_data();
  pthread_mutex_lock(&mutex_writecount)   // section critique - writecount
  writecount=writecount+1;
  if(writecount==1) {			       // si c'est le premier writer qui arrive
    sem_wait(&rsem);
  }
  pthread_mutex_unlock(&mutex_writecount);// fin de la section critique - writecount
  sem_wait(&wsem);					  // section critique, un seul writer a la fois
  write_database();
  sem_post(&wsem);				       // fin de la section critique
  pthread_mutex_lock(&mutex_writecount);  // section critique - writecount
  writecount=writecount-1;
  if(writecount==0) {				  // depart du dernier writer
    sem_post(&rsem);
  }
  pthread_mutex_unlock(&mutex_writecount);// fin de la section critique - writecount
}

/* Reader */
while(true){
  pthread_mutex_lock(&z);			  // 1e exclusion mutuelle, un seul reader en attente sur rsem
  sem_wait(&rsem);

  pthread_mutex_lock(&mutex_readcount);	  // exclusion mutuelle, readercount
  readcount=readcount+1;
  if (readcount==1) {				  // si arrivee du premier reader
    sem_wait(&wsem);
  }
  pthread_mutex_unlock(&mutex_readcount); // fin exclusion mutuelle, readercount
  sem_post(&rsem);  				  // liberation du prochain reader
  pthread_mutex_unlock(&z);			  // fin 1e exclusion mutuelle
  read_database();
  pthread_mutex_lock(&mutex_readcount);	  // exclusion mutuelle, readcount
  readcount=readcount-1;
  if(readcount==0) {				  // si depart du dernier reader
    sem_post(&wsem);
  }
  pthread_mutex_unlock(&mutex_readcount); // fin exclusion mutuelle, readcount
  use_data_read();
}
\end{lstlisting}


\section{Processus}
Un \textbf{\textit{processus}} peut être défini comme étant une instance de programme qui est en train d'être exécutée sur un ou plusieurs processeurs sous le contrôle d'un système d'exploitation.
Un processus comprend donc un ensemble d'instructions pour le processeur, les données qui sont stockées en mémoire et un ou plusieurs (si plusieurs threads) contextes.
En outre, l'OS maintient un certain nombre de structures de données qui sont nécessaires au bon fonctionnement du processus.
Ces structures de données sont créées au démarrage du processus, mises à jour durant la vie de celui-ci puis supprimées lorsqu'il s'arrête.

\subsection{Les librairies}
Lorsqu'un programme s'exécute à l'intérieur d'un processus, il exécute des instructions de différentes ``origines'' :
\begin{itemize}
  \item les instructions écrites par le programmeur, provenant d'un ou de plusieurs modules et regroupées dans un exécutable;
  \item Les instructions des librairies standard du système.
\end{itemize}
Si on analyse la compilation avec \texttt{gcc}, on constatera que le code des librairies standard n'est pas inclus mais que seuls les appels aux fonctions y sont indiqués.
Cela explique la taille réduite des exécutables sous Linux et de nombreuses variantes Unix.
Un programme peut utiliser deux types de librairies :
\begin{itemize}
  \item une \textbf{librairie statique} (\textit{static library}) est une librairie de fonctions qui est intégrée directement avec le programme.
    Elle fait entièrement partie de l'exécutable. \\
    \textbf{Avantage} Portabilité. \\
    \textbf{Désavantage} Poids.
  \item une \textbf{librairie partagée} (\textit{shared library}) est un ensemble de fonctions qui peuvent être appelées par un programme mais sont stockées dans un seul fichier sur le disque.
    Ce fichier unique est utilisé automatiquement par tous les programmes qui utilisent des fonctions de la librairie.\\
    \textbf{Avantages} Poids, pas de copies inutiles.
\end{itemize}

Il est parfois intéressant de créer une librairie qui peut être liée de façon statique, par exemple pour une exécution sur un autre ordinateur. Pour ce faire il faut compiler les fichiers objet correspondant aux différents modules de la librairie (avec \texttt{gcc}). Ensuite, il faut regrouper les différents modules dans une archive qui constituera la librairie. Par convention, toutes les librairies ont un nom qui commence par \texttt{lib} et se termine par l'extension \texttt{.a}. Sous Linux, cette opération est réalisée par l'utilitaire \texttt{ar}\footnote{Voir page de manuel. En bref : \texttt{ar r libname.a module.o} permet l'ajout d'un module objet. \texttt{ar d libname.a module.o} permet la suppression d'un module objet d'une librairie et \texttt{ar tv libname.a} permet de lister le contenu de la librairie.}.

L'archive contenant la librairie peut être liée en utilisant le \textit{linker} à n'importe quel programme qui en utilise une ou plusieurs fonctions. Avec \texttt{gcc} ça donne par exemple ça : \texttt{gcc --static -g -o executable libname.a exemple.o}. L'argument \texttt{--static} force le compilateur à inclure le code de la librairie dans l'exécutable. \\

Lorsqu'un programme est compilé de façon à utiliser une librairie dynamique, c'est l'OS qui analyse le programme lors de son chargement et intègre automatiquement les fonctions des librairies qui sont nécessaires à son exécution. L'entête de l'exécutable contient de l'information générée par le compilateur qui permet de localiser les librairies dynamiques qui doivent être intégrées\footnote{L'utilitaire \texttt{ldd} permet de lister les librairies partagées d'un exécutable.}.
\subsection{Les appels système}
\begin{figure}[h!]
  %\begin{wrapfigure}{r}{0.4\textwidth}
  %\vspace{-0.5cm}
  \centering\includegraphics[width=0.6\textwidth]{appelssystemes}
  \caption{\label{fig:appelssystemes}Appels systèmes.}
  %\vspace{-0.5cm}
  %\end{wrapfigure}
\end{figure}

Outre l'utilisation de fonctions de librairies, les programmes doivent interagir avec l'OS.
Un OS tel que Unix contient des utilitaires tels que \texttt{ls}, \texttt{grep},\dots\
et un noyau ou \textit{kernel}.
Le \textit{\textbf{kernel}} contient les fonctions de base du système d'exploitation qui lui permettent à la fois d'interagir avec le matériel et de gérer les processus en mémoire.
Parmi les fonctions de base, il y en a un petit nombre (de quelques dizaines à quelques centaines) qui sont utilisables par les processus lancés par les utilisateurs.
Ce sont les appels système.
Un \textbf{\textit{appel système}} est une fonction du \textit{kernel} qui peut être appelée par n'importe quel processus.
Pour un appel système on a :
\begin{enumerate}
  \item appeler le kernel.\\
    L'adresse de retour est automatiquement sauvegardée sur la pile lors de l'instruction qui fait appel au kernel (comme avec \texttt{calll});
  \item quel appel système ? \\
    Le numéro de l'appel système est placé dans le registre \texttt{\%eax}, cela permet à la routine de l'OS de savoir de quel appel système il s'agit;
  \item passer les arguments. \\
    Sous Linux, les arguments d'un appel système sont placés par convention dans des registres.
    Sur IA32, le premier argument est placé dans le registre \texttt{\%ebx}, le deuxième dans \texttt{\%ecx},\dots\
    Cela permet au kernel de facilement récupérer les arguments d'un appel système en lisant le contenu des registres.
  \item exécuter l'appel système;
  \item retourner le résultat.\\
    À la fin de l'appel système, le résultat est placé dans \texttt{\%eax} et \texttt{errno} est mis à jour en cas d'échec;
  \item retour au processus appelant.
\end{enumerate}

Les processeurs actuels fonctionnent au minimum avec deux modes :
\begin{itemize}
  \item le \textbf{mode utilisateur} où quelques instructions spécifiques de manipulation du matériel et certaines adresses mémoires ne sont pas utilisables;
  \item le \textbf{mode protégé} où toutes les instructions du processeur et toutes les adresses mémoire sont utilisables.
\end{itemize}
Le noyau de l'OS s'exécute en mode protégé tandis que les processus utilisateurs s'exécutent en mode utilisateur.
Ces derniers ne peuvent donc pas directement exécuter les instructions permettant une interaction avec des dispositifs matériels; pour cela, il faut passer par l'OS.

Lorsqu'un utilisateur démarre, le processeur est placé en mode protégé et le kernel se charge. Il initialise différentes structures de données et lance \texttt{init} qui est le premier processus du système. Dès que \texttt{init} a été lancé, le processeur passe en mode utilisateur et exécute les instructions de ce processus. Après cette phase de démarrage, les instructions du kernel sont exécutées tant qu'aucune interruption matérielle ne survient ou qu'un processus utilisateur exécute un appel système. Lorsqu'une interruption matérielle survient, elle place automatiquement le processeur en mode protégé et le kernel exécute la routine de traitement d'interruption correspondant à l'interruption qui est apparue. Un appel système démarre par l'exécution d'une instruction spéciale (parfois appelée \textit{interruption logicielle}) qui place le processeur en mode protégé et puis démarre l'exécution d'une instruction placée à une adresse spéciale en mémoire\footnote{Sur certains processeurs de la famille IA32, c'est l'instruction \texttt{int 0x80}, sur d'autres c'est \texttt{syscall} qui permet ce passage du mode utilisateur vers le mode protégé.}.

\subsection{Création d'un processus}
Considérons par exemple un utilisateur qui exécute la commande \texttt{/usr/bin/expr 1 + 2} depuis un shell \texttt{bash} interactif. Pour exécuter cette commande, il faut exécuter un nouveau processus contenant les instructions assembleur se trouvant dans \texttt{/usr/bin/expr}, lui passer les arguments \texttt{1 + 2}, l'exécuter, récupérer sa valeur de retour et la retourner au \texttt{shell} qui pourra l'utiliser et poursuivre son exécution. Les architectes de Unix ont choisis de construire un appel système pour chacune de ces opérations\footnote{Cet appel système est défini dans \texttt{unistd.h}.} : \texttt{pid\_t fork(void)}. Après exécution de \texttt{fork}, il y a 2 copies du même processus en mémoire. Le processus qui a appelé \texttt{fork} est le \textit{processus père}, tandis que celui qui a été créé est le \textit{processus fils}. L'appel de \texttt{fork} retournera deux valeurs différentes aux processus père et au processus fils :
\begin{itemize}
  \item \texttt{0} pour le processus fils;
  \item \texttt{>0} pour le processus père. Cette valeur correspond à l'identifiant du processus fils créé;
  \item \texttt{-1} en cas d'erreur. Dans ce cas, \texttt{errno} est mis à jour.
\end{itemize}
Contrairement au thread, les données en mémoire sont toutes copiées et donc même la modification d'une variable globale ou d'une zone mémoire n'aura aucun impact sur l'autre processus. (Pour connaître les moyens de communication entre processus, voir la section \ref{communicationproc} à la page \ref{communicationproc}.) \\

Le kernel gère les processus et attribue un identifiant (de type \texttt{pid\_t} sous Unix) à chaque processus. L'appel système \texttt{getpid} permet de récupérer l'identifiant du processus courant tandis que \texttt{getppid} permet de récupérer l'identifiant du processus père. \\

Après l'appel de \texttt{fork}, les 2 processus partagent certaines ressources qui sont gérées par le kernel. Notamment \textit{stdin}, \textit{stdout} et \textit{stderr}. Il faut donc que des précautions soient prises afin que les écritures sur la sortie standard s'affichent correctement par exemple. En réalité, les fonctions telles que \texttt{printf} et \texttt{putchar} de la librairie standard utilisent l'appel système \texttt{write} qui est le seul permettant d'écrire sur un flux tel que \textit{stdout}. L'utilisation à outrance de cet appel système est coûteuse pour les performances d'une application. C'est pourquoi la librairie standard utilise un buffer dans lequel elle stocke temporairement les données avant de les écrire en une fois via \texttt{write}\footnote{Ce buffer peut être contrôlé avec \texttt{setvbuff} et \texttt{setbuf}. Par exemple, pour le désactiver : \texttt{setbuf(stdout, NULL}.}. Il est possible de ``vider''\footnote{C'est à dire de forcer l'écriture sur le flux concerné.} immédiatement le buffer en utilisant la fonction \texttt{\textbf{int} fflush(\textbf{FILE} *stream)}.

\subsection{Fin d'un processus}
Comme nous l'avons déjà vu, un programme \clang{} peut se terminer de 2 façons :
\begin{itemize}
  \item par l'exécution de \texttt{return ...}  dans la fonction \texttt{main};
  \item par un appel explicite à \texttt{exit(...)}.
\end{itemize}
Ces fonctions utilisent en fait la fonction de la librairie \texttt{exit}.
Il est possible de définir une ou plusieurs fonctions à exécuter
lors de la terminaison d'un processus en utilisant \texttt{\textbf{int} atexit(\textbf{void} (*function)(\textbf{void}))}.
 De cette manière, lorsque \texttt{exit} est appelé, elle lance d'abord
 les fonctions de terminaison définies puis termine correctement le processus.
 Cela est utile, par exemple, lorsqu'un processus utilise une mémoire
 partagée entre plusieurs processus afin de libérer les ressources. Ensuite
 l'appel système \texttt{exit} est appelé : c'est le seul appel système qui
 n'a pas de valeur de retour.
 Cet appel système permet au processus qui se termine de retourner
 un statut à son processus père. Pour récupérer ce statut, un processus
 père doit utiliser l'appel système \texttt{waitpid} via \texttt{\textbf{pid\_t} waitpid(\textbf{pid\_t} pid, \textbf{int} *status, \textbf{int} options)}.
 Cet appel système est un appel système bloquant. Si le pid passé en premier
 argument est négatif, cela signifiera qu'on attend n'importe quel processus fils. \\
Un processus qui lance un processus fils avec \texttt{fork} \textit{doit}
attendre la terminaison de son processus fils en utilisant \texttt{waitpid}.
Différentes macros telles que \texttt{WEXISTATUS} et \texttt{WTERMSIGN} peuvent
être utilisées (\texttt{WEXISTATUS} pour extraire la valeur de retour et
\texttt{WTERMSIGN} pour extraire la raison de la terminaison abrupte).
Elles sont décrites en détail dans \texttt{man waitpid}. \\

Lorsque le père se termine avant le processus fils, le processus fils est dit \textbf{\textit{orphelin}}
et le kernel lui attribue l'identifiant \texttt{1} (correspondant à \texttt{init}) comme père.
Un \textit{\textbf{processus zombie}}, quant à lui, est un processus qui s'est terminé
mais dont la valeur de retour n'a pas encore été récupérée par son père\footnote{Dans ce cas, le kernel libère l'ensemble des ressources du processus fils et ne conserve qu'une petite structure de données contenant, entre autres, son identifiant, l'identifiant du père, et sa valeur de retour. En pratique, il faut éviter \^{}\^{}.}.

\subsection{Exécution d'un programme}
Pour exécuter un programme, il existe l'appel système \texttt{execve}.
Celui-ci remplace l'image en mémoire du processus par l'image de l'exécutable passé en argument, et son exécution démarre à la fonction \texttt{main} de ce dernier.\\
\texttt{\textbf{int} execve(\textbf{const} \textbf{char} *path, \textbf{char} *\textbf{const} argv[], \textbf{char} *\textbf{const} envp[]);}\\
\texttt{execve} ne retourne une valeur de retour qu'en cas d'échec. En effet, dans le cas contraire, tout ce qui se trouve après \texttt{execve} ne sera pas exécuté puisque tout est remplacé par le nouveau programme. Dans le cas d'un processus ayant lancé des threads, ceux-ci seraient automatiquement supprimés puisque c'est toute l'image qui est remplacée. Par contre, pour les flux standard (\textit{stdout},\dots), il est préférable de forcer leur écriture avec \texttt{fflush} car ce n'est pas fait automatiquement.\\

Les valeurs retournées par un processus fils sont stockées sur 8 bits. La plus grande valeur positive est donc 127 (utilisée en cas d'erreur). \\

En \clang{}, il existe des variantes à \texttt{execve} : \texttt{execl}, \texttt{execp}, \texttt{execle} et \texttt{execv}. Celles-ci diffèrent de \texttt{execve} par leur manière de spécifier les arguments. \\
La fonction \texttt{system} de la librairie permet d'exécuter une commande du shell directement depuis un programme.\\

En plus des exécutable compilé, Unix et Linux supportent aussi l'exécution de \textit{programmes interprétés}. Un \textbf{\textit{programme interprété}} est un programme écrit dans un langage qui doit être utilisé via un \textit{interpréteur}.
Un \textit{\textbf{interpréteur}} est un programme qui lit des commandes sous la forme de texte et exécute directement les instructions correspondant à ces commandes. Le plus connu est \texttt{bash} mais citons également \texttt{awk} (manipulation de textes), \texttt{perl} (textes mais aussi d'autres applications), \texttt{python} (langage de programmation complet),\dots \\

Voyons comment \texttt{execve} fonctionne :
\begin{enumerate}
  \item vérifie que le programme est bien exécutable : le système de fichiers contient des métadonnées, dont un bit\footnote{En pratique 3 bits, en fonction de l'utilisateur : voir \ref{sysfichierutilisateur} page \pageref{sysfichierutilisateur}.} de permission qui indique si le fichier est exécutable ou non;
  \item vérifie le type de fichier : par convention, le début d'un fichier contient une séquence d'octets ou de caractères qui indiquent le type de fichier dont il s'agit\footnote{Ce type de fichier peut être testé avec la commande \texttt{file}.} :
    \begin{enumerate}[a)]
      \item soit il s'agit d'un fichier directement exécutable.
        Sous les systèmes Linux actuels, ce fichier sera au format \texttt{elf}
        et débute par une entête qui contient une chaîne de caractères
        utilisée comme marqueur ou ``chaîne magique'';
      \item soit le fichier est en langage interprété et débute alors par \texttt{\#!} suivi du nom complet de l'interpréteur à utiliser et de ses paramètres éventuels à utiliser.
    \end{enumerate}
\end{enumerate}
En pratique, on peut définir (et créer) n'importe quel interpréteur. Il suffit qu'il s'agisse d'un exécutable. Celui-ci recevra le texte du fichier à interpréter. Cette facilité d'ajouter de nouveaux interpréteurs de commande est une des forces des OS de la famille Unix.

\subsection{Table des processus}
Un OS tel que Linux maintient certaines infos à propos de chaque processus dans une \textbf{\textit{table de processus}}. Ces infos peuvent être obtenues via \texttt{ps}, \texttt{top},\texttt{pstree},\dots\ En fait, tous ces utilitaires utilisent les informations contenues dans le répertoire \texttt{/proc}. Ce répertoire contient plusieurs entrées (fichiers et répertoires). Citons le répertoire \texttt{/proc/\textit{pid}/} où \texttt{\textit{pid}} est l'identifiant du processus. Ce répertoire contient notamment :
\begin{itemize}
  \item \texttt{cmdline} : ligne de commande de lancement;
  \item \texttt{environ} : variables d'environnement;
  \item \texttt{status} : état actuel du processus : identifiant, identifiant du père,\dots;
  \item \texttt{limits} : limites actuelles imposées par le système pour le processus;
  \item \texttt{task} : répertoire qui contient pour chaque thread lancé par le processus un sous-répertoire avec les infos sur le thread;
  \item \texttt{maps} : représente de façon textuelle la table des segments de mémoire qui sont partagés.
\end{itemize}

\section{Communication entre processus}
\label{communicationproc}
Pour la communication entre processus on peut utiliser un \textit{pipe} s'ils ont un ancêtre commun, ou une \textit{fifo}. Une \textit{fifo} peut être créée en utilisant la commande \texttt{mkfifo} ou la fonction \texttt{mkfifo} qui s'utilise comme l'appel système \texttt{open}. Pour créer une nouvelle \textit{fifo} il suffit de lui donner un nom (chaîne de caractères). Tout processus connaissant ce nom pourra l'utiliser.
\subsection{Signaux}
Un \textit{signal} est une forme d'interruption logicielle. Un \textit{\textbf{signal}} Unix est un mécanisme qui permet à un processus de réagir de façon asynchrone à un évènement qui s'est produit. Il en existe 2 types :
\begin{itemize}
  \item \textit{signal synchrone} : directement causé par l'exécution d'une instruction du processus. Par exemple, le signal \texttt{SIGFPE} qui est généré par l'OS quand un processus provoque une exception lors du calcul d'expressions mathématiques (ex : division par 0);
  \item \textit{signal asynchrone} : cause externe au processus (ex : provoqué par \texttt{kill}).
\end{itemize}
L'OS prévoit par défaut le traitement de tous les signaux, mais il est possible de redéfinir ce traitement avec l'appel système \texttt{signal} qui permet d'associer un \textit{handler} à chaque signal. Unix permet également d'envoyer un signal avec l'appel système \texttt{kill}.\\
\begin{tabularx}{\textwidth}{l|p{0.615\textwidth}|c}
  \textbf{Signal} & \textbf{Provoqué lorsqu'une} & \textbf{Par défaut} \\
  \hline \hline
  \texttt{SIGALRM} & Une alarme définie par la fonction \texttt{alarm} ou \texttt{setitimer} a expiré. & Terminaison. \\
  \hline
  \texttt{SIGBUS} & Erreur au niveau matériel. & Terminaison. \\
  \hline
  \texttt{SIGSEGV} & Erreur dans l'accès à la mémoire. & Terminaison. \\
  \hline
  \texttt{SIGFPE} & Erreur au niveau de l'utilisation des fonction mathématiques. &  Terminaison. \\
  \hline
  \texttt{SIGTERM} & Utilisé par défaut par \texttt{kill} pour demander la fin du processus. & Terminaison. \\
  \hline
  \texttt{SIGKILL} & Pour forcer la terminaison. Ne peut être redéfini et ignoré. & Terminaison. \\
  \hline
  \texttt{SIGUSR1} et \texttt{SIGUSR2} & Peuvent être utilisés par des processus sans conditions particulières. & Terminaison. \\
  \hline
  \texttt{SIGCHLD} & Indique qu'un processus fils s'est arrêté ou a fini son exécution. & Ignoré. \\
  \hline
  \texttt{SIGHUP} & À l'origine, pour indiquer que la connexion avec le terminal avait été rompue. Parfois utilisé par des processus serveur pour indiquer qu'il faut recharger leur fichier de config. & Terminaison. \\
  \hline
  \texttt{SIGINT} & Envoyé lorsqu'on tape \texttt{Ctrl-C} dans un shell. & Terminaison. \\
  \hline
\end{tabularx}

\subsubsection{Envoi de signaux}
\texttt{\textbf{int} kill(\textbf{pid\_t} pid, \textbf{int} sig);}\\
\texttt{pid} peut être :
\begin{itemize}
  \item \texttt{>0} : le \texttt{pid} du processus;
  \item \texttt{0} : pour tous les processus du même groupe de processus\footnote{Par défaut un processus appartient au même groupe que son parent. L'appel système \texttt{setpgid} permet de le changer. En pratique, c'est fait par le shell lorsqu'on utilise les pipes (\texttt{|}) afin de pouvoir arrêter tous les processus avec \texttt{Ctrl-C si nécessaire}.};
  \item \texttt{-1} : pour tous les processus pour lesquels le processus a les permissions pour envoyer un signal;
  \item \texttt{<-1} : pour tous les processus qui font partie du groupe \texttt{-pid}.
\end{itemize}
\subsubsection{Traitement de signaux}
Deux appels système sont possibles pour spécifier comment un signal doit être traité : \texttt{signal} et \texttt{sigaction}. \\
\texttt{\textbf{typedef} \textbf{void} (*\textbf{sighandler\_t})(\textbf{int});\\
\textbf{sighandler\_t} signal(\textbf{int} signum, \textbf{sighandler\_t} handler);}\\
Pour spécifier le traitement par défaut on utilise \texttt{SIG\_DFL} en argument pour ignorer le signal \texttt{SIG\_IGN}. \texttt{signal} renvoie l'ancien \textit{handler} utilisé ou \texttt{SIG\_ERR} en cas d'erreur.\\

Il faut être attentif à ce que la fonction \textit{handler} puisse bien s'exécuter à n'importe quel moment de l'exécution (alors que d'autres instructions étaient en cours d'exécution). Il n'est cependant pas possible d'utiliser les mutex pour les signaux car il faut que le traitement du signal soit terminé pour qu'on puisse retourner à la fonction dans laquelle on se trouvait. Il est important de déclarer les variables globales utilisées par la gestion du signal comme étant \texttt{volatile} afin de forcer à recharger la valeur avant chaque utilisation. Mais cela ne suffit pas, car un signal peut interrompre le processus juste après qu'il ait rechargé la valeur et juste avant qu'il ne l'utilise. C'est pourquoi il est préférable de n'utiliser que des variables du type \texttt{sig\_atomic\_t} qui garantissent que les accès se feront de manière atomique. Il faut également être attentif à ne pas utiliser des fonctions de la librairie standard qui pourraient interférer avec elles-mêmes si elles sont en cours d'utilisation par le processus principal (par exemple, si le \textit{handler} modifie \texttt{errno}, alors qu'on l'utilise déjà). \\

Pour le traitement des signaux par un OS, il y a deux stratégies.
\begin{itemize}
  \item Considérer qu'un signal est un message envoyé par le noyau ou par un processus à un autre processus. Le noyau contient une \textit{queue} qui stocke tous les signaux destinés à un processus donné. Chaque fois que le noyau réactive un processus, il vérifie si la \textit{queue} associée contient un ou plusieurs messages concernant des signaux. Si c'est le cas, il appelle la fonction de traitement du signal.\\
    \textbf{Avantage} Tous les signaux sont reçus.\\
    \textbf{Inconvénient} Il faut maintenir une queue de taille variable pour chaque processus.\\
  \item Représenter l'ensemble des signaux qu'un processus peut recevoir sous la forme de drapeaux binaires (un drapeau par signal). Avec cette stratégie, lors de l'envoi d'un signal, on modifie le drapeau correspondant sur le processus destination (sauf si ce processus ignore ce type de signal). Chaque fois que le noyau réactive un processus, il vérifie les drapeaux relatifs aux signaux du processus. Si un drapeau est \texttt{TRUE}, il appelle la fonction de traitement correspondante. \\
    \textbf{Avantage} Il suffit d'un bit par signal. \\
    \textbf{Inconvénient} Aucune garantie sur la délivrance des signaux. Le nombre de signaux reçus n'est pas fiable.
\end{itemize}
La plupart des variantes de Unix utilisent la deuxième stratégie. \\

Un \textbf{\textit{appel système lent}} est un appel système dont l'exécution peut être interrompue par la réception d'un signal comme par exemple \texttt{sleep}, \texttt{read},\dots\ Lorsqu'un signal survient pendant l'exécution d'un tel appel système, celui-ci est automatiquement interrompu pour laisser place au traitement du signal et est terminé ensuite en retournant une erreur et en mettant \texttt{errno = EINTR}.

\subsubsection{Traitement de signaux asynchrones}
Après réception d'un signal asynchrone, il faudrait pouvoir continuer le code autre part que là où il s'est arrêté. Pour ce faire, on a les fonctions \texttt{int setjmp(jmp\_buf env);} et \texttt{int sigsetjmp(sigjmp\_buf env, int savesigs);}. Voici un exemple de leur utilisation.
\begin{lstlisting}
#include ...
sigjmp_buf buf;
static void sigfpe_handler(int);

int main (int argc, char *argv[]){
  if(signal(SIGFPE,sigfpe_handler)==SIG_ERR) {
    perror("signal");
    exit(EXIT_FAILURE);
  }
  for(int i=1;i<argc;i++) {
    char *endptr; int r;
    long val=strtol(argv[i],&endptr,10);
    if(*endptr=='\0') {
      r=sigsetjmp(buf,1);  // faut-il ignorer le resultat ?
      if(r==0){
        int resultat=1252/(int) val;
        printf("1252/%d=%d\n",(int) val,resultat);
      }
      else {
        printf("%d/%d=NaN\n",n,(int) val);
      }
    }
    else{
      printf("Argument incorrect : %s\n",argv[i]);
    }
  }
  return(EXIT_SUCCESS);
}

static void sigfpe_handler(int signum){
  siglongjmp(buf,1);      // ignorer la donnee
}
\end{lstlisting}
\subsubsection{Temporisateurs}
Il est possible d'envoyer un signal après un certain temps en utilisant \texttt{setitimer} ou \texttt{alarm} afin d'arrêter un appel système bloquant après un certain temps : si on ne veut laisser que 5 secondes à l'utilisateur pour taper un caractère de réponse par exemple.
\begin{lstlisting}
...
if(signal(SIGALRM, sig_handler)==SIG_ERR)==SIG_ERR){ perror("signal"); exit(EXIT_FAILURE); }
if(siginterrupt(SIGALRM,true)<0){	// Indique qu'il faut arreter les appels systemes si on recoit SIGALRM
  perror("siginterrupt"); exit(EXIT_FAILURE);
}
...
char c;
alarm(5);
int r = read(STDIN_FILENO, &c, 1);
if((r==1)){
  alarm(0); 			// reset timer
  ...			     // On utilise la reponse donnee
} else {
  ... 				// On utilise une valeur par defaut
}
...

static void sig_handler(int signum){
  // rien a faire, read sera interrompu
}
\end{lstlisting}
Si le système est surchargé, il est possible qu'il y ait 5 secondes qui passent entre la ligne 8 et la ligne 9. Pour éviter ce problème il faudra donc faire appel à \texttt{siglongjmp} et \texttt{sigsetjmp} afin de savoir si un signal \texttt{SIGALRM} a déjà été reçu.
\subsection{Sémaphores}
Il n'est pas possible d'utiliser la fonction \texttt{sem\_init} vue dans le cas des threads car les processus ne partagent pas nécessairement la même zone mémoire. Par contre, il est possible d'utiliser un sémaphore nommé. Un \textbf{\textit{sémaphore nommé}} est identifié par un \textit{nom}. Sous Linux, ce nom correspond à un fichier dans le dossier virtuel \texttt{/dev/shm}, et tout processus qui connaît le nom \emph{et} a les autorisations d'y accéder peut l'utiliser. \\
\texttt{\textbf{sem\_t} *sem\_open(\textbf{const char} *name, \textbf{int} oflag);\\
  \textbf{sem\_t} *\textbf{sem\_open}(\textbf{const char} *name, \textbf{int} oflag, \textbf{mode\_t} mode, \textbf{unsigned int} value);\\
  \textbf{int} sem\_close(\textbf{sem\_t} *sem);\\
\textbf{int} sem\_unlink(\textbf{const char} *name);}\\
En cas d'erreur, \texttt{sem\_open} retourne \texttt{SEM\_FAILED} et met à jour \texttt{errno}. Les sémaphores nommés peuvent être créés et supprimés comme des fichiers. Ils utilisent des ressources limitées, il faut donc bien les supprimer (avec \texttt{sem\_unlink} une fois qu'ils ne sont plus nécessaires).

\subsection{Partage de fichiers}
Comme l'écriture dans un fichier sur un dispositif de stockage est relativement lente, l'OS maintient un buffer qui permet de ne pas devoir attendre l'écriture réelle sur le dispositif avant de continuer le processus. Pour forcer l'écriture de ce buffer sur le dispositif, on peut utiliser l'appel système \texttt{fsync} (ou \texttt{sync} si on veut le faire pour toutes les données).\\

Lors de l'ouverture d'un fichier sous Unix, le kernel maintient une structure de données (\textit{open file object}) qui contient le mode, l'offset pointeur et la référence vers le fichier sur le système d'exploitation. Lorsque deux programmes ouvrent un même fichier, ils possèdent chacun un \textit{open file object} différent tandis que si un fichier est ouvert avant un \texttt{fork}, le père et le fils possèdent le même \textit{open file object}, ce qui peut poser problème si on déplace l'offset pointeur. Pour éviter ce problème, il faut utiliser \texttt{\textbf{ssize\_t} pread(\textbf{int} fd, \textbf{void} *buf, \textbf{size\_t} count, \textbf{off\_t} offset);} et \texttt{\textbf{ssize\_t} pwrite(\textbf{int} fd, \textbf{const void} *buf, \textbf{size\_t} count, \textbf{off\_t} offset);}
 qui garantissent que les opérations d'écriture et de lecture qui sont effectuées se font de manière atomique et donc à l'offset pointeur voulu.\\

Il existe aussi un système de \textit{lock} similaires aux mutex. En théorie il existe deux techniques :
\begin{itemize}
  \item \textit{mandatory locking} : c'est l'OS qui vérifie qu'aucun accès fait au fichier ne viole les \textit{locks};
  \item \textit{advisory locking} : c'est le processus qui doit vérifier.
\end{itemize}
Certains Unix supportent le \textit{mandatory locking} mais la plupart ne supportent que l'\textit{advisory locking} (qui est plus facile à implémenter et plus performant). \\
Il existe deux appels systèmes : \texttt{\textbf{int} flock(\textbf{int} fd, \textbf{int} operation);} et \texttt{fcntl}. \texttt{operation} peut prendre les valeurs :
\begin{itemize}
  \item \texttt{LOCK\_SH} : \textit{lock} partagé; plusieurs processus peuvent posséder un même lock vers le fichier;
  \item \texttt{LOCK\_EX} : \textit{lock} exclusif;
  \item \texttt{LOCK\_UN} : pour supprimer un \textit{lock}.
\end{itemize}
L'appel système \texttt{fcntl} et la fonction \texttt{lockf} sont plus flexibles et permettent de placer des \textit{locks} sur une partie de fichier.\\

Le noyau maintient pour chaque fichier ouvert une liste de \textit{locks}. Sous Linux, on peut visualiser l'état de ces \textit{locks} avec \texttt{cat /proc/locks}. À noter que \texttt{EOF} indique la fin du fichier.



\section{Fichiers et répertoires}

\subsection{Gestion des utilisateurs}
Unix est un OS multi-utilisateur ce qui impose des contraintes de sécurité :
\begin{itemize}
  \item il doit être possible d'identifier et/ou d'authentifier les utilisateurs;
  \item il doit être possible d'exécuter des processus appartenant à plusieurs utilisateurs simultanément et de déterminer quel utilisateur est responsable de chaque opération;
  \item l'OS doit fournir des mécanismes simples de contrôle d'accès aux différentes ressources (mémoire, stockage,\dots);
  \item il doit être possible d'allouer certaines ressources à un utilisateur particulier à un moment donné.
\end{itemize}

Les systèmes Unix utilisent le processus \texttt{login} pour la connexion d'un utilisateur. Ce processus appartient initialement à \textit{root} puis exécute l'appel système \texttt{setuid} afin d'appartenir à l'utilisateur puis exécute \texttt{execve} pour lancer le premier shell de l'utilisateur. L'appel système \texttt{setuid} ne peut évidemment être appelé que par un processus appartenant à \texttt{root}. Un processus peut récupérer son \textit{userid} avec l'appel système \texttt{getuid}.\\

Sur Unix, le fichier \texttt{/etc/passwd} contient pour chaque utilisateur le nom d'utilisateur (\textit{username}), le mot de passe (sur les anciennes versions de Unix), l'identifiant de l'utilisateur (\textit{userid}), l'identifiant de son groupe principal, son nom et son prénom, son répertoire de démarrage et son shell.\\

En pratique, on associe parfois des droits d'accès à un groupe d'utilisateurs plutôt qu'à un utilisateur particulier. Le groupe principal d'un utilisateur est défini dans \texttt{/etc/passwd} tandis que les groupes secondaires le sont dans \texttt{/etc/group}.
\subsection{Systèmes de fichiers}
Tous les dispositifs de stockage (disque dur, lecteur CD/DVD, clé USB,\dots) offrent en pratique une interface similaire pour le système d'exploitation. Cette interface se résume en 2 fonctions, une de lecture d'un secteur et une d'écriture. En règle générale, un \textit{\textbf{secteur}} peut stocker un bloc de 512 octets. Chaque secteur est identifié par une adresse. La plupart des implémentations sont optimisées pour pouvoir lire ou écrire sur plusieurs secteurs consécutifs, mais la plus petite unité de lecture ou d'écriture est le \textit{secteur}. La plupart des OS (dont Unix) fournissent une interface de plus haut niveau aux programmes : les fichiers et répertoires. Cette abstraction est appelée un \textit{\textbf{système de fichiers}} ou \textit{file system}. Il existe des centaines de systèmes de fichiers; Linux en supporte quelques dizaines. \\

En simplifiant, un système de fichiers Unix utilise le principe qu'un \textit{fichier} est une suite ordonnée d'octets. Un nom est associé à cette suite d'octets. Cette suite d'octets sera stockée dans un ou plusieurs secteurs, consécutifs ou non. Rien ne garantit que la taille d'un fichier sera un multiple du nombre d'octets dans un secteur, donc l'OS doit être capable de gérer des secteurs partiellement remplis.\\

Sous Unix, le lien entre les différents secteurs qui composent un fichier se fait grâce à l'utilisation d'inodes. Un \textit{\textbf{inode}} est une structure de données stockée sur le disque (en pratique, un ensemble contigu de secteurs, souvent au début du disque) et qui contient notamment les métadonnées suivantes d'un fichier :
\begin{itemize}
  \item \texttt{uint16 mode} : contient un ensemble de drapeaux binaires avec les permissions associées au fichier;
  \item \texttt{uid\_t uid} : le propriétaire du fichier;
  \item \texttt{gid\_t gid} : le groupe auquel appartient le fichier;
  \item \texttt{uint32 size} : la taille du fichier en bytes;
  \item \texttt{uint32 atime} : l'instant de dernier accès;
  \item \texttt{uint32 mtime} : l'instant de dernière modification;
  \item \texttt{uint32 ctime} : l'instant de création;
  \item \texttt{uint16 nlinks} : le nombre de liens vers ce fichier;
  \item \texttt{uint16 zone[10]} : la liste ordonnée des secteurs qui contiennent le fichier.
\end{itemize}
Sous Unix, le nom du fichier n'est pas directement associé au fichier lui-même, il est stocké dans les répertoires. Un \textit{repertoire} est un fichier qui a un format spécial. Il contient une suite d'entrées qui contiennent chacune un nom (de fichier ou de répertoire), une indication de type (qui permet notamment de distinguer fichiers et répertoires) et le numéro de l'inode qui contient les métadonnées du fichier ou répertoire concerné. \\

Dans un système de fichiers Unix, l'ensemble des répertoires et fichiers est organisé sous la forme d'un arbre. La racine de cet arbre est le répertoire \texttt{/}. Le système de fichiers Unix permet aussi d'intégrer facilement des systèmes de fichiers se trouvant sur différents dispositifs de stockage. Cela peut se faire en pratique par un administrateur système avec la commande \texttt{mount} ou via le fichier \texttt{/etc/fstab}. \\

Tout répertoire contient 2 répertoires spéciaux : \texttt{.} qui est un alias vers le répertoire lui-même, et \texttt{..} qui est un alias vers le répertoire parent du répertoire courant. \\

\subsubsection{Permissions}
\label{sysfichierutilisateur}
Les métadonnées qui sont associées à chaque fichier ou répertoire contiennent des bits de permission pour 3 types de permissions et d'autorisation : \texttt{r} = lecture, \texttt{w} = écriture/modification et \texttt{x} = exécution.
Ces bits de permission sont regroupés en 3 blocs : les permissions applicables par un processus de l'utilisateur propriétaire, les permissions applicables par un processus appartenant au même groupe que le fichier et les permissions applicables par les autres processus. Ces bits de permission peuvent être modifiés par la commande \texttt{chmod}\footnote{Voir note page 177 du syllabus pour plus d'informations sur les représentations des bits de permission et l'utilisation de \texttt{chmod}.}. \\

\subsubsection{Répertoire courant}
Un processus peut utiliser le nom complet d'un fichier commençant par \texttt{/} (\texttt{/home/damien/Bureau/exemple.txt}) ou son nom \textit{relatif} (\texttt{Bureau/exemple.txt}). Pour les noms relatifs, le kernel maintient pour chaque processus le \textit{répertoire courant} dans sa table des processus. Par défaut, il s'agit du répertoire à partir duquel le programme a été lancé. Un processus peut changer son répertoire avec l'appel système \texttt{\textbf{int} chdir(\textbf{const} \textbf{char} *path);}\footnote{Depuis le shell, on utilise la commande \texttt{cd} pour changer de répertoire, et la commande \texttt{pwd} pour connaître le répertoire courant.}.

\subsubsection{Appels systèmes}
\begin{itemize}
  \item \texttt{stat} : permet de récupérer les métadonnées d'un fichier ou d'un répertoire.\\
    $\implies$ commande \texttt{stat};
  \item \texttt{chmod} et \texttt{chown} : permettent de modifier respectivement le mode (permissions) et le propriétaire ou le groupe d'un fichier.\\
    $\implies$ commandes \texttt{chmod}, \texttt{chown} et \texttt{chgrp};
  \item \texttt{utime} : permet de modifier un \textit{timestamp} associé à un fichier/répertoire. \\
    $\implies$ commande \texttt{touch};
  \item \texttt{rename} : permet de changer le nom d'un fichier/répertoire.\\
    $\implies$ commande \texttt{rename};
  \item \texttt{mkdir} et \texttt{rmdir} : Permettent de créer/supprimer un répertoire.\\
    $\implies$ commandes \texttt{mkdir} et \texttt{rmdir};
  \item \texttt{opendir}, \texttt{closedir} et \texttt{readdir} : permettent de consulter le contenu d'un répertoire;
  \item \texttt{link} et \texttt{unlink} : permettent de créer ou supprimer des ``liens'' vers un fichier. Le compteur de liens \texttt{nlinks} est mis à jour pour l'inode en question. Lorsqu'un inode ne contient plus de liens, il est supprimé. \\
    $\implies$ commandes \texttt{ln} et \texttt{rm}.
\end{itemize}

\subsubsection{Utilisation des fichiers}
Lorsqu'un processus veut accéder à un fichier, il peut utiliser les appels systèmes \texttt{open}, \texttt{read}/\texttt{write} et \texttt{close}. (Il est également possible d'utiliser les fonctions \texttt{fopen}, \texttt{fread}, \texttt{fwrite} et \texttt{fclose} proposées par la librairie standard.) \\
\texttt{\textbf{int} open(\textbf{const char} *pathname, \textbf{int} flags); \\
\textbf{int} open(\textbf{const char}* pathname, \textbf{int} flags, \textbf{mode\_t} mode);} \\
\texttt{flags} peut prendre une valeur parmi :
\begin{itemize}
  \item \texttt{O\_RDONLY}, \texttt{O\_WRONLY} et \texttt{O\_RDWR};
  \item \texttt{O\_CREAT}, \texttt{O\_APPEND}, \texttt{O\_TRUNC}, \texttt{O\_CLOSEXEC}\footnote{Spécifique à Linux, si le fichier doit être automatiquement fermé lors de l'exécution de \texttt{execve}.} et \texttt{O\_SYNC}\footnote{Indique que les opérations d'écriture doivent être faites immédiatement, sans être mises en attente dans les buffers du kernel.};
  \item Une disjonction logique (opérateur \texttt{|}) entre les drapeaux précédents.
\end{itemize}
Lors de l'exécution de \texttt{open} (et uniquement à ce moment-là), l'OS vérifie si le processus a les permissions suffisantes pour accéder au fichier. Si c'est le cas, l'OS l'ouvre et retourne un \textit{descripteur de fichier}. Sous Unix, un \textbf{\textit{descripteur de fichier}} est représenté sous la forme d'un entier positif : \texttt{open} retournera le plus petit descripteur de fichier disponible. Par convention, \texttt{0} = \textit{stdin}, \texttt{1} = \textit{stdout}, \texttt{2} = \texttt{stderr}. Toutes les opérations qui sont faites sur un fichier se font en utilisant le \textit{descripteur de fichier} comme référence au fichier. Un \textit{descripteur de fichier} est une ressource limitée dans un OS tel qu'Unix, il faut donc fermer le fichier en fin d'utilisation et ne pas ouvrir inutilement un grand nombre de fichiers. Pour fermer : \\
\texttt{\textbf{int} close(\textbf{int} fd);}\\
Par défaut l'OS ferme les descripteurs \texttt{0}, \texttt{1} et \texttt{2} à la fermeture d'un processus. \\

Lorsqu'un fichier a été ouvert, le kernel maintient les références vers l'\textit{inode} du fichier ainsi qu'un \textit{offset pointer} qui indique la position actuelle de la tête de lecture/écriture. Il est possible de déplacer cet offset pointeur en utilisant l'appel système \texttt{lseek} : \\
\texttt{\textbf{off\_t} lseek(\textbf{int} fd, \textbf{off\_t} offset, \textbf{int} whence);}\\
L'argument \texttt{whence} permet de définir si la position doit être calculée de manière absolue (\texttt{SEEK\_SET}), s'il faut l'additionner avec la valeur actuelle (\texttt{SEEK\_CUR}) ou s'il faut l'additionner à la fin du fichier (\texttt{SEEK\_END}).\\

Pour lire et écrire on dispose de deux fonctions : \\
\texttt{\textbf{ssize\_t} read(\textbf{int} fd, \textbf{void} *buf, \textbf{size\_t} count);}\\
\texttt{\textbf{ssize\_t} write(\textbf{int} fd, \textbf{const} \textbf{void} *buf, \textbf{size\_t} count);}\\
Ces deux fonctions permettent d'écrire des séquences contigües d'octets. Lorsqu'un fichier est envoyé via Internet (par exemple), et lu sur un autre ordinateur, cela peut poser plusieurs problèmes :
\begin{itemize}
  \item les ordinateurs n'utilisent pas spécialement tous le même nombre d'octets pour représenter un certain type de données\footnote{Sur un ancien IA32, les entiers sont représentés sur 32 bits = 4 bytes, sur les plus récents, ils sont représentés sur 64 bits = 8 bytes};
  \item Les fabricants de processeurs utilisent plusieurs techniques pour représenter les entiers sur 16 et 32 bits en mémoire (figure \ref{fig:biglittleendian}) :
    \begin{itemize}
      \item le \textit{big endian} (utilisé sur les PowerPC);
      \item le \textit{little endian} (utilisé sur les processeurs IA32).
    \end{itemize}
\end{itemize}
\begin{figure}[!h]
  \centering\includegraphics[width=0.3\textwidth]{bigendian}
  \includegraphics[width=0.3\textwidth]{littleendian}
  \caption{\label{fig:biglittleendian} \textit{Big-endian} et \textit{little-endian}.}
\end{figure}

\paragraph{Note}
Il est possible d'obtenir un nom de fichier unique à partir d'un template en utilisant la fonction \texttt{ \textbf{int} mkostemp (\textbf{char} *template [, \textbf{int} flags]);}. En utilisant \texttt{unlink} directement après la création du fichier, cela supprime le fichier du système de fichiers mais il reste accessible par le processus qui l'a ouvert $\implies$ fichier temporaire.


\subsubsection{Les pipes}
Un \textit{\textbf{pipe}} est un flux de bytes unidirectionnel qui relie deux processus qui ont un ancêtre commun. L'un des processus écrit sur le \textit{pipe}, tandis que l'autre peut lire sur le \textit{pipe}. Un \textit{pipe} est créé en utilisant l'appel système \texttt{pipe} : \\
\texttt{\textbf{int} pipe(\textbf{int} fd[2])}\\
Chaque fois qu'une donnée est écrite sur \texttt{fd[1]}, elle peut être lue avec \texttt{fd[0]}.
Un \textit{pipe} a une capacité limitée\footnote{\SI{4}{\kilo\byte} sur les versions de Linux avant 2.6.11 x86-32, \SI{64}{\kilo\byte} sur Linux après 2.6.11.};
lorsqu'un pipe est rempli, le processus qui effectue \texttt{write} est bloqué.


En pratique, les pipes sont utilisés par le shell avec \texttt{|}. Exemple : \texttt{cat exemple.txt | grep "word"}. La sortie standard de \texttt{cat} est reliée avec l'entrée standard de \texttt{grep}.

\section{Mémoire virtuelle}
\subsection{La mémoire virtuelle}
\begin{wrapfigure}{r}{0.4\textwidth}
  \vspace{-0.5cm}
  \includegraphics[width=0.4\textwidth]{mmu}
  \caption{\label{fig:mmu}\textit{MMU} et mémoire virtuelle.}
\end{wrapfigure}
Avec la \textit{\textbf{mémoire virtuelle}}, deux types d'adresses sont utilisées sur le système : les \textit{adresses virtuelles} et les adresses réelles ou physiques. Une \textit{\textbf{adresse virtuelle}} est une adresse qui est utilisée à l'intérieur d'un programme.  Une \textit{\textbf{adresse physique}} est l'adresse qui est utilisée au niveau des puces de RAM pour les opérations d'écriture et de lecture. Ce sont les adresses physiques qui sont échangées sur le bus auquel la mémoire est connectée. \\
Le rôle du \textit{\textbf{MMU}} ou \textbf{\textit{Memory Management Unit}} est de traduire les adresses virtuelles en adresses physiques. \\

La longueur des adresses virtuelles et la longueur des adresses physiques ne doivent pas être nécessairement identiques. Sur les ordinateurs bons marchés par exemple, les adresses virtuelles sont plus longues; ils utilisent une quantité réduite de mémoire RAM. Inversement on peut utiliser des adresses physiques plus longues que les adresses virtuelles (sur les serveurs par exemple).\\

Un autre avantage de la mémoire virtuelle est qu'elle permet, à condition de pouvoir avoir une conversion spécifique à chaque processus, de partager efficacement la mémoire entre processus tout en leur permettant d'utiliser les mêmes adresses virtuelles. \\
Le \textit{MMU} est capable d'effectuer des traductions d'adresses virtuelles spécifiques à chaque processus ce qui permet non seulement que 2 adresses virtuelles identiques pointent vers 2 adresses physiques différentes mais aussi que 2 adresses virtuelles différentes puissent pointer vers 1 adresse physique (utile pour éviter de copier les librairies partagées). \\
\subsection{La mémoire virtuelle}
\begin{wrapfigure}{r}{0.5\textwidth}
  \vspace{-0.5cm}
  \includegraphics[width=0.5\textwidth]{memvirt}
  \caption{\label{fig:memvirt}Organisation de la mémoire virtuelle.}
\end{wrapfigure}
Un autre avantage encore est la possibilité de combiner mémoire RAM et dispositif de stockage (disque dur, disque SSD,\dots) pour obtenir une mémoire virtuelle de plus grande capacité que la mémoire RAM.

\subsubsection{Fonctionnement de la mémoire virtuelle}
La difficulté de gestion est que la mémoire est organisée en octets tandis que les dispositifs de stockage utilisent des secteurs de données. Le temps d'accès diffère également.\\

L'unité intermédiaire utilisée par la mémoire virtuelle est la \textit{\textbf{page}}. Une page est une zone de mémoire contigüe dont la taille peut varier. Une taille courante est de 4096 octets.\\

Lorsqu'un programme est chargé en mémoire (\texttt{execve}), il est automatiquement découpé en pages. Ces pages peuvent être stockées dans n'importe quelle zone de la mémoire RAM mais doivent être à des adresses qui sont contiguës. Une \textit{adresse virtuelle} est alors composée d'un ensemble de bits. Les bits de poids fort identifient la \textit{page}, tandis que ceux de poids faible identifient la position de la donnée par rapport au début de cette \textit{page}.\\
\begin{figure}[!h]
  \centering
  \includegraphics[width=0.5\textwidth]{memtradadresses}
  \caption{Traduction d'adresses avec une table des pages.}
\end{figure}\\
Avec ce principe de \textit{pages}, un mécanisme de traduction d'adresses peut se baser sur une \textit{\textbf{table de pages}}. Cette \textit{table de pages} est stockée en mémoire RAM et contient une ligne pour chaque page existant dans la mémoire virtuelle. Cette table de pages contient :
\begin{itemize}
  \item le \textit{\textbf{bit de validité}} qui indique si la page est en mémoire RAM ou non;
  \item l'adresse en mémoire RAM à laquelle la page est actuellement stockée (si elle est en RAM);
  \item des bits de permission géré par l'OS : \textit{R} bit (lecture), \textit{W} bit (écriture) et \textit{X} bit (exécution).
\end{itemize}
\\

L'adresse de la table des pages est stockée dans un registre du processeur.
L'utilisation de ce registre permet d'avoir une table des pages pour chaque processus.
Pour cela il suffit qu'une zone de mémoire soit réservée pour chaque processus
et que l'OS y stocke la table des pages du processus.
Lors du changement de contexte, l'OS modifie alors le registre de la table des pages.

En terme de sécurité,
il faut éviter qu'un processus ne puisse modifier sa table des pages
lui-même sans contrôle. Pour ce faire on utilise les bits de permission.
Un segment de code qui ne contient que des instructions sera par exemple
stocké avec les bits \textit{R} et \textit{X} mais pas le bit \textit{W}.
Le \textit{stack} ainsi que le \textit{heap} seront placés dans des pages avec les bits \textit{R}
et \textit{W} mais pas \textit{X}.
Un accès interdit à une page provoquera une \texttt{Segmentation Fault}.

Les bits de permission sont gérés par l'OS mais il peut parfois être utile de les modifier pour certaines pages. Cela se fait avec \texttt{\textbf{int} mprotect(\textbf{const void} *addr, \textbf{size\_t} len, \textbf{int} prot)} où \texttt{prot} peut prendre les valeurs \texttt{PROT\_NONE}, \texttt{PROT\_READ}, \texttt{PROT\_WRITE}, \texttt{PROT\_EXEC} ou une disjonction logique de celles-ci. Si la protection demandée est plus \textit{faible} que l'actuelle, l'OS produira une \texttt{Segmentation Fault}.

La traduction se fait comme suit :

\begin{enumerate}
  \item l'adresse virtuelle arrive au MMU, il regarde combien de bits de
    poids faible on a
    (si une page fait \SI{4}{\kilo\byte}, ça fait $2^{12}$ bytes
    donc 14 bits de poids faible.)
    Les bits de poids fort donnent l'indice dans la table des pages en binaire
    (11001 signifie que c'est la 25ème entrée de la table des pages);
  \item Le MMU regarde si la partie de la table des pages où il y a l'entrée
    25 est dans la TLB (sorte de cache pour la table des pages).
    Dans tous les cas, il regarde, dans la table des pages,
    l'entrée à l'indice 25.
  \item Il regarde le bit de validité de l'entrée.
    \begin{itemize}
      \item Si c'est 1, c'est qu'elle est dans la RAM,
        il regarde alors les bits de permission pour voir s'il a le droit
        de faire ce qu'il veut faire (lire, écrire ou exécuter)
        (sinon, \texttt{Segmentation Fault}).
        Il met le bit de réference à 1 et il regarde les autres bits pour voir
        à quel multiple de la taille d'une page, la page est.
        Par exemple, si ça vaut 1011 (11 en binaire), c'est que c'est à l'adresse physique
        $11\cdot 2^{12}$ (avec des pages de \SI{4}{\kilo\byte}).
        S'il a écrit dedans, il met le \textit{dirty bit} à \texttt{TRUE}.
      \item Si c'est 0,
        il regarde les bits de permission, s'ils sont tous à \texttt{FALSE},
        c'est que la page est invalide (\texttt{Segmentation Fault}),
        sinon, c'est que la page est sur le disque.
        Il regarde s'il a les permissions et s'il ne les a pas, \texttt{Segmentation Fault}.
        Sinon, il ramène la page dans la RAM et met le \textit{dirty bit} à \texttt{FALSE}
        (pour dire que pour l'instant, la page est exactement pareille dans
        la RAM que dans la \textit{swap} donc s'il faut par la suite la remettre
        dans la \textit{swap}, il ne faudra même pas faire de copie)
        puis il met le bit de référence à \texttt{TRUE} et s'il écrit,
        il met le \textit{dirty bit} à \texttt{TRUE} aussi.
    \end{itemize}
  \item Une fois qu'il a l'adresse physique de début de la page,
    il ajoute à ça l'\textit{offset} (les bits de poids faible de l'adresse virtuelle)
    et il a l'adresse physique exacte :).
\end{enumerate}

Tous les $x$ temps, il remet les bits de référence à \texttt{FALSE}.

Il ne faut pas confondre ça avec \lstinline|mmap|.

\begin{itemize}
  \item Quand la RAM déborde,
    l'OS met les pages les moins utilisées sur le disque dans une partition
    \textit{swap} ou un fichier de \textit{swap}
    (celles qui ont le bit de référence à \texttt{FALSE} et \textit{dirty bit} à \texttt{FALSE}
    en préférence car ça veut dire qu'elles n'ont pas été utilisées
    récemment et qu'elles sont déjà en \textit{swap} de manière inchangée).
    Quand on a à nouveau besoin de cette page, on la remet en RAM.
  \item \lstinline{mmap} prend de la mémoire dans le
    système de fichier (\textit{file system})
    et la met dans le \textit{heap} en RAM.
    Si le système a besoin de place,
    il peut très bien la remettre sur le disque.
    À ce moment là,
    je sais pas trop s'il la remettra où elle était avant
    (c'est à dire dans le système de fichiers)
    (il le fera sans doute s'il est malin) ou s'il la met en \textit{swap}.
\end{itemize}

\subsubsection{Mémoire partagée}
Il est possible qu'une même page en mémoire physique soit utilisée par plusieurs processus différents. Par exemple, dans le cas des threads (créés par l'OS), lorsqu'on crée un thread, on initialise sa table des pages en copiant toutes les valeurs de son ``père'' mis à part celles qui correspondent au \textit{stack}. De cette manière, le thread a accès aux mêmes variables globales, segment text,\dots \\

En utilisant la table des pages intelligemment il est également possible de permettre à deux processus distincts d'avoir accès à la même zone mémoire physique. Ce qui leur permettra de communiquer plus efficacement qu'avec des \textit{pipes} par exemple. Cette technique porte le nom de \textit{\textbf{mémoire partagée}}. Pour ce faire deux techniques existent :
\begin{itemize}
  \item l'OS copie la table des pages du processus $P_1$ dans la table des pages de $P_2$;
  \item l'OS crée une nouvelle page pouvant être partagée. Elle appartient au noyau mais est accessible à $P_1$ et $P_2$ en modifiant leur table des pages. \\
    \textbf{Avantages} Meilleur contrôle possible par l'OS, peut vivre après la terminaison d'un processus.
\end{itemize}
Linux utilise la deuxième solution. La mémoire partagée peut y être utilisée avec les appels système \texttt{shmget} (pour créer ou vérifier l'accès), \texttt{shmat} (pour ajouter de la mémoire à la table des pages) et \texttt{shmdt} (pour détacher un segment de mémoire).\\

\begin{wrapfigure}{r}{0.3\textwidth}
  \vspace{-0.5cm}
  \includegraphics[width=0.3\textwidth]{mempart}
  \caption{\label{fig:mempart}Organisation de la mémoire d'un processus.}
\end{wrapfigure}
Il faut faire attention aux pointeurs en mémoire partagé ! En pratique, il ne vaut mieux pas les utiliser\dots\\

Les segments de mémoire partagée sont gérés par le noyau, ils persistent donc après la terminaison du processus qui les a créés. Le nombre de segments partagés est limité. Il ne faut donc pas qu'il y en ait qui restent alors qu'ils ne sont plus utilisés. Il est possible de supprimer un segment partagé en utilisant l'appel système \texttt{shmctl}. En pratique, le noyau détruit un segment de mémoire partagée uniquement lorsqu'il n'y a plus de processus qui y sont attachés. On peut donc faire cette suppression juste après \texttt{shmat} de manière à être sûr que le segment sera supprimé si plus aucun processus n'est actif dessus (utilisable par exemple si on utilise la mémoire partagée pour communiquer entre un processus père et un fils).


\subsubsection{Implémentation de \textit{fork}}
Afin d'optimiser le fonctionnement de \textit{fork}, il n'y a pas de réelle copie des pages du processus père. En réalité, le système utilise le \textit{copy-on-write}.
Le noyau copie toutes les entrées de la table des pages du processus père vers la table des pages du processus fils et les marque d'un bit $p$ pour indiquer qu'elles sont en \textit{copy-on-write}.
Si un processus tente un accès en écriture sur une de ces pages, le MMU interrompt l'exécution du processus et force l'exécution d'une routine d'interruption du noyau.
Si le processus a effectivement les autorisations d'écriture, le noyau alloue une nouvelle page physique et y recopie la page où la tentative a eu lieu. La table des pages est mise à jour et le processus peut continuer. Cette technique de \textit{\textbf{copy-on-write}} permet de ne copier que les pages qui sont effectivement modifiées par le processus père ou le processus fils.
\subsection{Fichiers mappés en mémoire}
\begin{figure}[!h]
  \centering \includegraphics[width=0.7\textwidth]{mmap}
  \caption{\label{fig:mmap}Fichier mappés en mémoire.}
\end{figure}
Grâce à la mémoire virtuelle il est possible de placer le contenu d'un fichier ou une partie dans une zone de mémoire du processus.
Cette opération peut être effectuée en utilisant l'appel système \texttt{mmap}.
\texttt{mmap} prend entre autres un argument qui spécifie si les pages du fichier sont mappées dans chaque processus (avec \texttt{MAP\_PRIVATE}) ou si plusieurs processus peuvent accéder et modifier la page (avec \texttt{MAP\_SHARED}).
Dans le premier cas, une écriture n'est pas répercutée sur les autres processus.
Les changements faits sur un fichier mappé ne sont pas immédiatement faits dans le fichier sur le dispositif de stockage.
On peut utiliser \texttt{msync} qui permet de demander si cette écriture doit être faite (avec le drapeau \texttt{MS\_SINC} il attend la fin, tandis qu'avec \texttt{MS\_ASYNC} il ne fait que démarrer l'écriture). \\
À la fin de l'utilisation d'un fichier mappé, le processus doit utiliser l'appel système \texttt{munmap}.
\subsection{Utilisation des dispositifs de stockage}
Comme nous l'avions vu plus haut, les pages peuvent ne pas se trouver en mémoire RAM.
Dans ce cas, soit elles n'existent plus, soit elles sont stockées sur un dispositif de stockage.
Sous Linux on utilise une partition \textit{swap} pour stocker les pages qui ne sont pas en mémoire RAM.
Le fonctionnement de la mémoire virtuelle peut alors être vu de la façon suivante :
le \textit{MMU} est intégré directement sur le processeur et comprend un \textit{TLB} (\textit{Translation Lookaside Buffer}) qui sert de cache pour les entrées de la table des pages du processus qui est en train de s'exécuter.
Si la page demandée ne se trouve pas en mémoire RAM, il s'occupera de la rapatrier (ce qui peut prendre quelques dizaines de millisecondes).
Tant que cette page n'est pas disponible en mémoire RAM, le processus est mis à l'état bloqué et l'OS effectue un changement de contexte pour exécuter un autre processus.
\subsection{Stratégie de remplacement de pages}
C'est l'OS qui prend en charge le transfert des pages entre les dispositifs de stockage et la mémoire.
Tant que la RAM n'est pas remplie, il suffit de ramener une ou plusieurs pages du dispositif de stockage vers la mémoire RAM.
En général, l'OS utilisera le principe de localité. Par contre, si la mémoire RAM est pleine, il faut une stratégie de remplacement des pages.

Une première stratégie de remplacement de pages pourrait être de sauvegarder les identifiants des pages dans une file \textit{FIFO}. C'est facile à implémenter mais les premières pages arrivées ne sont pas spécialement les moins utilisées.

Une autre stratégie serait de maintenir les statistiques d'utilisation de chaque page afin de prédire les pages qui seront nécessaires dans le futur.
Cette stratégie nécessiterait que le \textit{TLB} mette à jour les statistiques à chaque accès à une page : difficile, et peu performant.

Face à ces problèmes, la plupart des stratégies de remplacement de pages s'appuient sur 2 bits qui se trouvent dans chaque entrée de la table des pages.
C'est facilement implémentable et ça n'augmente pas trop la mémoire occupée par une entrée de la table des pages.
\begin{itemize}
  \item Le \textit{bit de référence} est mis à \texttt{TRUE} par le \textit{MMU} dans le \textit{TLB} à chaque accès (R/W) à une donnée se trouvant dans la page en question.
  \item Le \textit{bit de modification} ou \textit{dirty bit} est mis à \texttt{TRUE} par le \textit{MMU} chaque fois qu'une opération d'écriture est réalisée.
\end{itemize}
Lorsqu'une entrée de la table des pages est retirée du \textit{TLB}, que ce soit à l'occasion d'un changement de contexte ou parce que le \textit{TLB} était plein, les valeurs de ces 2 bits sont recopiées.  \\

Afin de savoir quelles sont les pages en mémoire auxquelles des processus accèdent actuellement, l'OS remet régulièrement à \texttt{FALSE} les bits de validité. \\

En utilisant une file \textit{FIFO} et le \textit{bit de référence}, il est maintenant possible de faire comme suit : si la première page a son bit de référence mis à \texttt{TRUE}, elle est remise en fin de file et on teste la suivante.
Lorsqu'on trouve une page qui a son bit de référence à \texttt{FALSE}, elle peut être retirée de la mémoire.

Il est également possible d'utiliser le \textit{bit de référence} et le \textit{dirty bit}.
L'OS va dans ce cas remettre régulièrement tous les bits de référence à \texttt{FALSE}.
L'algorithme de remplacement peut alors classer les pages en 4 catégories :
\begin{center}
  \begin{tabular}{|c|c|l|}
    \hline
    \textbf{Bit de} & \multirow{2}*{\textit{\textbf{Dirty bit}}} & \multirow{2}*{\textbf{Signification}} \\
    \textbf{référence} & & \\
    \hline
    \multirow{2}*{\texttt{FALSE}} & \multirow{2}*{\texttt{FALSE}} & N'ont pas été utilisées récemment \\
    & & et sont identiques à la version déjà sur disque.\\
    \hline
    \multirow{2}*{\texttt{FALSE}} & \multirow{2}*{\texttt{TRUE}} & N'ont pas été utilisées récemment\\
    & & mais doivent être mises à jour sur disque. \\
    \hline
    \multirow{2}*{\texttt{TRUE}} & \multirow{2}*{\texttt{FALSE}} & Ont été utilisées récemment \\
    & &  mais ne doivent pas être mises à jour sur disque.\\
    \hline
    \multirow{2}*{\texttt{TRUE}} & \multirow{2}*{\texttt{TRUE}} & Ont été utilisées récemment \\
    & & et doivent être mises à jour sur disque.\\
    \hline
  \end{tabular}
\end{center}


\subsection{Interactions entre le processus et la mémoire}
Linux comprend plusieurs appels systèmes qui permettent à un processus d'influencer la stratégie de remplacement du noyau.
C'est par exemple utilisé par les applications de cryptographie pour éviter qu'une clef en mémoire ne soit sauvegardée sur un disque dur.
Les appels système \texttt{mlock} et \texttt{munlock} peuvent être utilisés pour ce faire.
Il faut néanmoins être vigilant avec ces appels système et en pratique ils ne seront utilisés que pour les applications cryptographiques et les processus avec des exigences temps réel.

\subsection{\texttt{execve} et la mémoire virtuelle}
\texttt{execve} utilisera un fichier mappé accessible en écriture pour les instructions de l'exécutable et un fichier mappé accessible en lecture/écriture pour les zones des chaînes de caractères et les variables. Ce dernier sera en \textit{copy-on-write}.


%\begin{lstlisting}
%char *string;
%int* v = (int *) string;
%\end{lstlisting}

%\section{Arguments}
%Variables d'env.
%Arguments.
%Pour beaucoup d'OS, ils sont dans un endroit au dessus de la pile de taille
%fixe. Il y a une limite sur la longueur de tous les args et pas sur leur
%nombre souvent.
%
%struct:
%regarde le plus long et leur donne tous ça
%ex:
%char : 1
%int : 4
%short : 2
%4 + 4 + 4 = 12
%char : 1
%long : 8
%short : 2
%8 + 8 + 8 = 24
%char : 1
%long[3] : 8
%short : 2
%8 + 3*8 + 8 = 40
%char : 1
%char : 1
%short : 2
%4 WTF :o
%32 bits - paquets de 4
%64 bits - paquets de 8

%int pid = fork();
%-> -1 pour père => fils existe pas
%-> >0 -> père et fils a pid = pid
%-> 0 -> fils


%\n ne flush pas tout le temps !!!
%flush est plus sûr. Crazy :o

\end{document}
