\section{Forme standard et variantes}

\subsection{Problème d'affectation continu}

	Intéressons-nous maintenant
	à une formulation continue du problème d'affectation.

	La seule chose qui change
	par rapport au problème d'affectation discret (\sectionref{affectation})
	est la contrainte
	\[
	x_{ij} \in \{0, 1\}\,, \quad \forall i,j\,.
	\]
	Comme on se trouve maintenant dans une situation continue,
	elle se transforme en
	\[
	x_{ij} \in \interval{0}{1}\,, \quad \forall i,j\,.
	\]

\subsection{Forme géométrique}

	La forme géométrique est une certaine façon
	de représenter un problème d'optimisation linéaire.

	Par convention, un problème d'optimisation
	est un problème de minimisation.
	En effet, maximiser et minimiser sont équivalents,
	à condition de changer le signe:
	\[
	\max c^T x \iff -\min -c^T x\,.
	\]

	En ce qui concerne les contraintes,
	on essaie d'avoir un système de la forme
	\[
	\begin{tabular}{|ccccccccc|}
		\hline
		\multicolumn{9}{|c|}{$a_1$} \\
		\hline
		\multicolumn{9}{|c|}{$a_2$} \\
		\hline
		\multicolumn{9}{|c|}{\multirow{5}{*}{$A$}}
		\\
		&&&&&&&&\\
		&&&&&&&&\\
		&&&&&&&&\\
		&&&&&&&&\\
		\hline
		0 & 0 & 0 & 0 & \multicolumn{1}{|c|}{1} & 0 & 0 & 0 & 0 \\
		\hline
	\end{tabular}
	\cdot
	\begin{tabular}{|c|}
		\hline
		\multirow{9}{*}{$x$}
		\\
		\\
		\\
		\\
		\\
		\\
		\\
		\\
		\\
		\hline
	\end{tabular}
	\ge
	\begin{tabular}{|c|}
		\hline
		$b_1$ \\
		\hline
		$b_2$ \\
		\hline
		\multirow{5}{*}{$b$}
		\\
		\\
		\\
		\\
		\\
		\hline
		0 \\
		\hline
	\end{tabular}\,.
	\]
	On remarque que toutes les contraintes sont de la forme
	\[
	a_i^T x \ge b_i\,.
	\]
	Pour arriver à cela,
	il faut savoir transformer toute contrainte
	en une contrainte de cette forme.
	Plusieurs règles permettent d'arriver à ce résultat:
	\[
	a_i^T x \le b_i \iff -a_i^T x \ge -b_i\,,
	\]
	\[
	a_i^T x = b_i \iff \left(a_i^T x \ge b_i\right) \land \left(-a_i^T x \ge -b_i\right)\,.
	\]

	Notons que les contraintes de la forme
	\[
	a_i^T x \ne b_i
	\]
	ne sont pas admises car on ne peut pas les mettre sous la forme désirée.

	Par défaut, les $x_i$ sont dits ``libres'',
	c'est-à-dire qu'il n'y a pas de contrainte dessus \textit{a priori}.

	Si on veut mettre une contrainte dessus, par exemple de la forme
	\[
	x_i \ge 0\,,
	\]
	il suffit de rajouter une ligne à la matrice $A$
	(la dernière ligne dans l'exemple).
	Évidemment, les règles de conversion sont ici aussi valables.

	Tout problème d'optimisation linéaire
	peut être mis sous forme géométrique.

\subsection{Forme standard}

	Un problème sous forme standard est également
	un problème de minimisation par défaut.
	Cependant, les contraintes deviennent maintenant des égalités.

	Il faut donc de nouveau une règle
	pour transformer les contraintes
	pour un problème sous forme géométrique
	en celles pour un problème standard:
	\[
	a_i^T x \ge b_i \iff \left(a_i^T x - s_i = b_i\right) \land \left(s_i \ge 0\right)\,.
	\]
	On rajoute donc des variables $s_i$ appelées
	``variables d'écart'' (\emph{slack variables}).

	Une autre différence entre les deux formes est
	que les variables ne sont plus libres
	lorsqu'on passe sous forme standard.

	Pour transformer une variable libre
	en une variable plus grande ou égale à zéro,
	il suffit de la scinder en deux:
	\[
	x_i = x_i^+ - x_i^-\,, \quad \forall i\,,
	\]
	avec
	\[
	x_i^+, x_i^- \ge 0\,, \quad \forall i\,.
	\]

	Cependant, ceci n'est pas efficace
	car on double le nombre de variables.
	Heureusement, on peut se passer de cette augmentation de la complexité.
	Si on choisit une variable $x^-$ telle que
	\[
	x^- = x_1^- = x_2^- = \dots = x_n^- \ge 0\,,
	\]
	le prix à payer n'est que d'une seule variable.

	La forme géométrique et la forme standard sont donc équivalentes.

\subsection{Valeur absolue}

	Il peut arriver dans un problème d'optimisation
	que l'on soit confronté à une valeur absolue
	(notamment lorsqu'on fait de la \emph{régression linéaire}).

	Prenons par exemple la fonction objectif suivante:
	\[
	\min_x \abs{x_1} + x_2\,.
	\]
	Résoudre ce problème revient en fait à résoudre
	\[
	\left\{
	\renewcommand{\arraystretch}{1.5}
	\begin{array}{c@{\quad} r c r@{\quad} l}
		\min\limits_x & x_1 & + & x_2\,, & \textnormal{si } x_1 \ge 0\,,\\
		\min\limits_x & -x_1 & + & x_2\,, & \textnormal{sinon.}
	\end{array}
	\right.
	\]

	Cependant, dédoubler ne fonctionne que pour les petits problèmes,
	à peu de variables.

	Imaginons devoir résoudre le problème de minimisation suivant:
	\[
	\min_x \sum_{i=1}^{100} \abs{x_i - \alpha_i}\,, \quad x,\alpha \in \R^{100}\,.
	\]
	Un problème équivalent est le problème
	\[
	\min_{x,t} \sum_{i=1}^{100} t_i\,,
	\]
	où l'on a posé que
	\[
	\abs{x_i - \alpha_i} \ge t_i\,.
	\]
	On transforme maintenant cette contrainte en une contrainte linéaire,
	de sorte à obtenir le problème suivant
	\[
	\renewcommand{\arraystretch}{1.5}
	\begin{array}{c@{\quad} l c r@{\quad} l}
		\min\limits_{x,t} & {\displaystyle \sum_{i=1}^{100}} t_i &&&\\
		\textnormal{s.t.} & x_i - \alpha_i & \le & t_i\,, & \forall i\,,\\
		& x_i - \alpha_i & \ge & -t_i\,, & \forall i\,.\\
	\end{array}
	\]
	On peut ensuite transformer ce problème
	pour le mettre sous forme géométrique ou standard,
	comme détaillé dans les sections précédentes.

	Cette méthode fonctionne car la valeur absolue est une fonction convexe.

\subsection{Normes}

	Il existe plusieurs normes possibles.
	Voici quelques exemples:

	\begin{itemize}
		\item la norme $\ell_1$ définie par
		\[
		\norm{x}_1 \coloneqq \sum_i \abs{x_i}\,;
		\]
		\item la norme $\ell_2$ définie par
		\[
		\norm{x}_2 \coloneqq \sqrt{\sum_i x_i^2}\,;
		\]
		\item la norme $\ell_p$ définie par
		\[
		\norm{x}_p \coloneqq \left(\sum_i \abs{x_i}^p\right)^{1/p}\,;
		\]
		\item la norme $\ell_\infty$ définie par
		\[
		\norm{x}_\infty \coloneqq \max_i \abs{x_i}\,.
		\]
	\end{itemize}
