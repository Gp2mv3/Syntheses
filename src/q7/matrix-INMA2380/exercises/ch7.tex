\section{Positive matrices}

\exo{1}
Show that for all \(\mathbf{x} \gneq 0 \in \R^n\), \(\rho \mathbf{x} \leq A\mathbf{x}\) if and only if \(\rho \leq r(\mathbf{x})\).

\begin{solution}
	The following inequalities are equivalent
	\begin{align*}
	\rho \mathbf{x} & \leq A\mathbf{x}\\
	\rho x_i & \leq [A\mathbf{x}]_i & \forall i: x_i \neq 0\\
	\rho & \leq \frac{[A\mathbf{x}]_i}{x_i} & \forall i: x_i \neq 0\\
	\rho & \leq \min_{i: x_i \neq 0} \frac{[A\mathbf{x}]_i}{x_i}.
	\end{align*}
\end{solution}

\exo{3}
Show that if \(\abs{\lambda_2(S)} < \rho(S)\), then
\[
\lim_{n \to \infty} S^n = \mathbf{x}[1, 1, \dots, 1]
\]
where \(\mathbf{x}\) is the Perron eigenvector of \(S\), normalized such that \(\sum x_i = 1\).

\begin{solution}
	This result can be seen as a sort of consequence of the power method
	applied on the columns of $S$
	($S^\infty = S^\infty
	\begin{bmatrix}
	a_{:1} & \cdots & a_{:n}
	\end{bmatrix}$).
	
	Let's prove it simply using the Jordan form of $S$.
	Without loss of generality, the eigenvalues of S are $1 = \rho(S) > \abs{\lambda_2} \geq \cdots \geq \abs{\lambda_k}$).
	\begin{equation}
	T^{-1}ST =
	\begin{bmatrix}
	1 & 0\\
	0 &
	\diag_{i = 2, \ldots, k}
	\{J_i\}
	\end{bmatrix} \triangleq D \label{D}
	\end{equation}
	where
	\[ J_i =
	\begin{bmatrix}
	\lambda_i & 1 &  & 0\\
	& \lambda_i & \ddots &\\
	& & \ddots & 1\\
	0 & & & \lambda_i
	\end{bmatrix}.
	\]
	We have
	\begin{align*}
	S^k & =
	T
	\begin{bmatrix}
	1 & 0\\
	0 &
	\diag_{i = 2, \ldots, k}
	\{J_i^k\}
	\end{bmatrix}
	T^{-1}.
	\end{align*}
	We can check now that
	\begin{align*}
	J_i^k & =
	\begin{bmatrix}
	\lambda_i^k & \binom{k}{1}\lambda_i^{k-1} & \binom{k}{2}\lambda_i^{k-2} & \cdots\\
	& \lambda_i^k & \ddots & \\
	& & \ddots & \binom{k}{1} \lambda_i^{k-1}\\
	0 & & & \lambda_i^k
	\end{bmatrix}\\
	J_i^k & =
	\lambda_i^k
	\begin{bmatrix}
	1 & \binom{k}{1}\lambda_i^{-1} & \binom{k}{2}\lambda_i^{-2} & \cdots\\
	& 1 & \ddots & \\
	& & \ddots & \binom{k}{1}\lambda_i^{-1}\\
	0 & & & 1
	\end{bmatrix}
	\end{align*}
	and $\binom{k}{j} \lambda_i^{-j}$ is a polynomial in $k$ while $\lambda_i^k$ is a decreasing exponential ($\abs{\lambda_i} < 1$) in $k$ so
	$J_i^k$ converges to $0$ and $S^k$ to
	\begin{align}
	T
	\begin{bmatrix}
	1 & 0\\
	0 & 0
	\end{bmatrix}
	T^{-1}
	& =
	t_{:1}(t^{-1})_{1:}
	\end{align}
	
	However, since $T^{-1}T = I$, $(t^{-1})_{1:}t_{:1} = 1$ and $(t^{-1})_{1:}t_{:j} = 0 = (t^{-1})_{j:}t_{:1}$ for $j \neq 1$.
	We can see that
	\begin{align*}
	St_{:1}
	& = TDT^{-1}t_{:1}\\
	& = TD\mathbf{e}_1\\
	& = T\mathbf{e}_1\\
	& = t_{:1}\\
	(t^{-1})_{1:}S
	& = (t^{-1})_{1:}TDT^{-1}\\
	& = \mathbf{e}_1^TDT^{-1}\\
	& = \mathbf{e}_1^TT^{-1}\\
	& = (t^{-1})_{1:},
	\end{align*}
	so $t_{:i}$ is an eigenvector of 1.
	Since the geometric multiplicity is 1, $t_{:i}$ is a multiple of $\mathbf{x}$,
	the normalised ($\1^\top t_{:i} = 1$) Perron eigenvector.
	Also $(t^{-1})_{1:}$ is a multiple of the \emph{left} eigenvector $\1^\top$.
	So, there are $\alpha,\beta$ such that
	\begin{align*}
	t_{:i} & = \alpha \mathbf{x}\\
	(t^{-1})_{1:} & = \beta \1^\top
	\end{align*}
	but since $(t^{-1})_{1:}t_{:1} = 1$, $\alpha\beta = 1$ so
	\[ \lim_{n \to \infty} S^n = \mathbf{x}\1^\top. \]
\end{solution}