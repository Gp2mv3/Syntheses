\section{Unitary transformations and the Singular Value Decomposition}

\exo{2}
Assuming that all the diagonal elements of \(\Lambda\) are distinct, show that the matrix \(U_{up}\) is necessarily diagonal and consists only of phases:
\[
U_{up} = \diag\{e^{i\psi_1}, \dots, e^{i \psi_n}\}.
\]

\begin{solution}
	Let $U_{up} = [u_{ij}]_{i,j=1}^{n}$.
	We must have
	\[ U_{up}\Lambda = \Lambda U_{up}. \]
	At the position $i,j$, we have
	\[ u_{ij} \lambda_j = \lambda_i u_{ij} \]
	or
	\[ u_{ij} (\lambda_j - \lambda_i) = 0. \]
	If $i \neq j$, this means that $u_{ij} = 0$ since $\lambda_j - \lambda_i \neq 0$.
	
	$U_{up}$ must therefore be diagonal.
	However it also needs to be hermitian for $UU_{up}$ to be Hermitian.
	Indeed, we need to have
	\begin{align*}
	UU_{up} U_{up}^*U^* & = I\\
	U_{up} U_{up}^* & = U^*U\\
	U_{up} U_{up}^* & = I.
	\end{align*}
	This means that we need to have $1 = u_{ii}\overline{u_{ii}} = \abs{u_{ii}}^2$
	so $u_{ii}$ is on the unit circle and is a phase.
\end{solution}

\exo{2}
Show that if \(X\) satisfies
\begin{itemize}
	\item (1), then \(AX\) is a projection;
	\item (1) and (3), then \(AX\) is an orthogonal projection;
	\item (2), then \(XA\) is a projection;
	\item (2) and (4), then \(XA\) is an orthogonal projection.
\end{itemize}

\begin{solution}
	\begin{itemize}
		\item
		\begin{align*}
		AXAX
		& = (AXA)X\\
		& = AX.
		\end{align*}
		\item
		$AX$ is a projection since (1) is satisfied.
		
		From Theorem~3.6, $\Ker(AX) = \Ima((AX)^*)^\perp$.
		Therefore, we can just show that $\Ima((AX)^*) = \Ima(AX)$ which is obvious
		since (3) is satisfied.
		\item
		\begin{align*}
		XAXA
		& = (XAX)A\\
		& = XA.
		\end{align*}
		\item
		$XA$ is a projection since (2) is satisfied.
		
		From Theorem~3.6, $\Ker(XA) = \Ima((XA)^*)^\perp$.
		Therefore we can just show that $\Ima((XA)^*) = \Ima(XA)$ which is obvious
		since (4) is satisfied.
	\end{itemize}
\end{solution}

\exo{3}
How can we define the notion of canonical angles between two spaces of different dimension?

% i feel like there's some fuckery going on with  matrix dimensions here :(

\begin{solution}
	Let $\mathcal{S}_1$ be of dimension $m$ and $\mathcal{S}_2$ be of dimension $n < m$.
	We can have $n$ canonical angles using
	\begin{align*}
	S_1^*S_2
	& = U_1
	\begin{pmatrix}
	\Sigma\\0
	\end{pmatrix}
	U_2^*\\
	& =
	\begin{pmatrix}
	U_{1,1} & U_{1,2}
	\end{pmatrix}
	\begin{pmatrix}
	\Sigma\\0
	\end{pmatrix}
	U_2\\
	& = U_{1,1} \Sigma U_2,
	\end{align*}
	with $\Sigma = \cos(\Theta)$, where $\theta_i$ are the angles between the $n$ vectors of $S_1U_{1,1}$
	and the $n$ vectors of $S_2U_2$.
\end{solution}

\exo{4}
Show that for every positive semidefinite matrix \(H\) and every unitary matrix \(Q\), we have
\[
\trace(HQ) \leq \trace(H).
\]

\begin{solution}
	\emph{Hint:}
	Use the property $\trace(AB) = \trace(BA)$.
	
	Since $H$ is Hermitian, there is a unitary $U$ and diagonal $\Lambda$ such that $H = U \Lambda U^*$.
	Let's first analyse the RHS
	\begin{align*}
	\trace(H) & = \trace(U \Lambda U^*)\\
	& = \trace(\Lambda U^*U)\\
	& = \trace(\Lambda)\\
	& = \sum_{i=1}^n \lambda_i.
	\end{align*}
	For the LHS, we first need to analyse $Q$.
	It is unitary, so its eigenvalues are on the unit circle therefore $\abs{x^* Q x} \leq 1$ for all $x$ such that $\norm{x}=1$.
	
	Using the triangle inequality and the fact that the $\lambda_i$ are positive
	\begin{align*}
	\trace(HQ)
	& = \trace(U \Lambda U^* Q)\\
	& = \trace(\Lambda U^* Q U)\\
	& = \sum_{i=1}^n \lambda_i u_{:i}^* Q u_{:i}\\
	& \leq \abs{\sum_{i=1}^n \lambda_i u_{:i}^* Q u_{:i}}\\
	& \leq \sum_{i=1}^n \abs{\lambda_i} \, \abs{u_{:i}^* Q u_{:i}}\\
	& = \sum_{i=1}^n \lambda_i \abs{u_{:i}^* Q u_{:i}}\\
	& \leq \sum_{i=1}^n \lambda_i.
	\end{align*}
\end{solution}

\exo{3}
How could you extend the polar decomposition to the case \(m \neq n\)?

\begin{solution}
	If $A$ is $m \times n$, then $H$ is $m \times r$ and $Q$ is $r \times n$ for some $r$.
	We want $H$ to be positive semidefinite so we need $H$ to be square for it to be defined.
	That means that $Q$ is $m \times n$.
	
	The problem with the proof when $m \neq n$ is that we cannot say
	$U \Sigma V^* = U \Sigma U^* U V^*$ since the product is not defined because $U$ is $m \times m$
	and $V$ is $n \times n$.
	\begin{itemize}
		\item If $m < n$, we have
		\begin{align*}
		A
		& = U
		\begin{pmatrix}
		\Sigma & 0
		\end{pmatrix}
		\begin{pmatrix}
		V_1 & V_2
		\end{pmatrix}^*\\
		& = U \Sigma V_1^*\\
		& = (U \Sigma U^*) (U V_1^*)
		\end{align*}
		with $V_1^*V_1 = I$ (but $V_1V_1^* \neq I$, since $I$ has full rank but $V_1$ does not have full row rank)
		since
		\begin{align*}
		I
		& =
		\begin{pmatrix}
		V_1 & V_2
		\end{pmatrix}^*
		\begin{pmatrix}
		V_1 & V_2
		\end{pmatrix}\\
		& =
		\begin{pmatrix}
		V_1^*V_1 & V_1^*V_2\\
		V_2^*V_1 & V_2^*V_2
		\end{pmatrix}.
		\end{align*}
		
		Therefore $QQ^* = (U V_1^*) (U V_1^*)^* = I$ but $Q^*Q = (U V_1^*)^* (U V_1^*) = V_1V_1^* \neq I$.
		\item If $m > n$, we have
		\begin{align*}
		A
		& =
		\begin{pmatrix}
		U_1 & U_2
		\end{pmatrix}
		\begin{pmatrix}
		\Sigma \\ 0
		\end{pmatrix}
		V^*\\
		& = U_1 \Sigma V^*\\
		& = (U_1 \Sigma U_1^*) (U_1 V^*)
		\end{align*}
		with $U_1^*U_1 = I$ but $U_1U_1^* \neq I$ like for the previous point.
		
		This time it's $Q^*Q = I$ and $QQ^* \neq I$.
	\end{itemize}
\end{solution}

\exo{3}
Show that the polar decomposition of \(B^\top A\) leads to an optimal rotation \(Q\) that minimizes \(\norm{AQ^\top - B}_F^2\).

\begin{solution}
	\emph{Hint} Use the property $\norm{A}_F = \trace(A^\top A) = \trace(AA^\top)$ and the property $\trace(AB) = \trace(BA)$.
	
	We have (also using $\trace(A^\top) = \trace(A)$).
	
	\begin{align*}
	\norm{AQ^\top - B}_F^2
	& = \trace((AQ^\top - B)(AQ^\top - B)^\top)\\
	& = \trace((AQ^\top - B)(QA^\top - B^\top))\\
	& = \trace(AQ^\top QA^\top) + \trace(BB^\top) - \trace(AQ^\top B^\top ) - \trace(BQA^\top)\\
	& = \trace(AA^\top) + \trace(BB^\top) - \trace(B^\top AQ^\top) - \trace(QA^\top B)\\
	& = \norm{A}_F^2 + \norm{B}_F^2 - \trace(B^\top AQ^\top) - \trace(B^\top AQ^\top)\\
	& = \norm{A}_F^2 + \norm{B}_F^2 - 2\trace(B^\top AQ^\top)\\
	& = \norm{A}_F^2 + \norm{B}_F^2 - 2\trace(\tilde{H}\tilde{Q} Q^\top)\\
	& \geq \norm{A}_F^2 + \norm{B}_F^2 - 2\trace(\tilde{H})
	\end{align*}
	using Exercise~3.4 since $\tilde{Q}Q^\top$ is unitary and $\tilde{H}$ is Hermitian positive semidefinite.
	Taking $Q = \tilde{Q}$, we have equality. It is therefore the optimal rotation.
\end{solution}

\exo{3}
Construct a matrix \(B\), with \(\mathop{\mathrm{rank}}(B) \leq s\), that is different from (3.15) and reaches the same bound on \(\norm{A - B}\).

\begin{solution}
	For $s_i \in [\sigma_i - \sigma_{s+1}(A), \sigma_i + \sigma_{s+1}(A)]$ for $i = 1, \ldots, s$,
	and
	\[ B = \sum_{i=1}^s \mathbf{u}_i s_i \mathbf{v}_i^\top, \]
	we have
	\[ A - B = \sum_{i=1}^s \mathbf{u}_i(\sigma_i - s_i)\mathbf{v}_i^\top + \sum_{i=s+1}^r \mathbf{u}_i\sigma_i \mathbf{v}_i^\top. \]
	which also has its maximum singular value equal to $\sigma_{s+1}(A)$ by definition of the $s_i$.
\end{solution}