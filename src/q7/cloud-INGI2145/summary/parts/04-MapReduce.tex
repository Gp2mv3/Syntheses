
\begin{figure}[!h]
    \centering
    \begin{tikzpicture}[node distance=2cm]
        \node[draw, rectangle] (I0) {Input split 0};
        \node[draw, rectangle, below=0cm of I0] (I1) {Input split 1};
        \node[draw, rectangle, below=0cm of I1] (I2) {Input Split 2};

        \node[draw, circle, right=of I0 ] (W2) {Worker};
        \node[draw, circle, below=of W2 ] (W1) {Worker};
        \node[draw, circle, above=of W2 ] (W3) {Worker};

        \node[draw, minimum height=1cm,rectangle, right=of W1 ] (F1) {};
        \node[draw, minimum height=1cm, rectangle, right=of W2 ] (F2) {};
        \node[draw, minimum height=1cm, rectangle, right=of W3 ] (F3) {};

        \node[draw, rectangle, minimum height=1cm, right=0cm of F1 ] (FF1) {};
        \node[draw, rectangle, minimum height=1cm,right=0cm of F2 ] (FF2) {};
        \node[draw, rectangle, minimum height=1cm, right=0cm of F3 ] (FF3) {};

        \node[draw, circle, above right=1cm and 2.5cm of FF1 ] (R1) {Reducer};
        \node[draw, circle, below right=1cm and 2.5cm of FF3 ] (R2) {Reducer};

        \node[draw, rectangle, right=of R1 ] (O1) {Output file 0};
        \node[draw, rectangle, right=of R2 ] (O2) {Ouput file 1};

        \draw (I0.0) edge[->](W1);
        \draw (I1.0) edge[ ->](W3);
        \draw (I2.0) edge[ ->](W2);

        \draw (W1.0) edge[->] (F1.180);
        \draw (W2.0) edge[->] node 
        {\rotatebox{90}{ \textcolor{red}{\textbf{map}: (key, val) $\rightarrow$ (red\_key, val)}}} (F2.180);
        \draw (W3.0) edge[->] (F3.180);

        \draw (FF1.0) edge[->] (R1.180);
        \draw (FF1.0) edge[->] (R2.180);
        \draw (FF2.0) edge[->] node[below=-2.5cm]
        {\rotatebox{90}{ \textcolor{red}{\textbf{shuffled}: redistribution by output's key}}} (R2.180);
        \draw (FF2.0) edge[->] (R1.180);
        \draw (FF3.0) edge[->] (R1.180);
        \draw (FF3.0) edge[->] (R2.180);

        \draw (R1.0) edge[->] node[above=-2cm]
        {\rotatebox{90}{ \textcolor{red}{\textbf{reduce}: (red\_key, \{set of values\}) $\rightarrow$ result}}} (O1.180); 
        \draw (R2.0) edge[->] (O2.180);

        \node[below=1cm of W1] (2) {Map phase};
        \node[left=of 2] (1) {Input files};
        \node[right=0.8cm of 2] (3){Intermediate files};
        \node[right=0.7cm of 3] (4){Reduce phase};
        \node[right=1cm of 4] (5){Output files};


    \end{tikzpicture}

    \centering
    \begin{itemize}
        \item \textbf{File system} distributed across all nodes with replication
        \item \textbf{Driver program} on the master to keeping all node busy
        \item \textbf{Runtime system} which control nodes
    \end{itemize}
    \caption{MapReduce where mapper and reducer should be \textbf{stateless}
    }
\end{figure}


A variety of different tasks can be expressed 
as a single-­pass MapReduce program which are specifically designed
for \textbf{batch operation} over large amounts of data:
\begin{itemize}
    \item filter, collect, aggregate, join on shared element
\end{itemize}

\paragraph{Not for MapReduce}
\begin{itemize}
    \item sorting don't work in the abstract model (but the
        implementation support it)
    \item algorithms that depend on shared global state during 
        processing are difficult to implement.
    \item Process live data at high throughput and low latency

\end{itemize}


\subsection{Failure}
On worker crash we rely on the file system being shared 
across all the nodes. 
\begin{itemize}
    \item If the node wrote its output and then crashed, 
        the file system is likely to have a copy of the complete output.
    \item If the node crashed before finishing its output, the master 
        see that the job isn’t making progress, and restarts the 
        job elsewhere on the system
\end{itemize}

$\Rightarrow$ Hadoop jobs can always complete as long as there is a
worker alive because the master redistribute the jobs to other worker.
(of course, we have fewer nodes to do work...)

Note that the master can't fail to redistribute the jobs.

\subsection{Optimization}

\begin{enumerate}
    \item \textit{locality}: Master tries to do work on nodes that 
        have replicas of the data
    \item \textit{Stragglers}: re-execute slow machines task somewhere else.

    \item \textit{Combiner}: use between mapper and reducer in order to be more efficient.
        Typically, it's job is to pass $(xyz, k)$ instead of $k$ copies of $(xyz, 1)$.
\end{enumerate}

\subsection{Single-Pass algorithm}

\begin{itemize}
	%% Should not the Intersection check the size of the values?
	\item \textbf{Aggreation} Compute 
	\item \textbf{Filtering} Remove item that does not sastifies a property
	\item \textbf{Intersection} Return the intersection bewteen two set (
	remove duplicated value that appears in the two set).
	\item \textbf{Join} Combine two set according to a common properties
\end{itemize}

\subsection{Shuffle}

\begin{itemize}
    \item \textbf{Sorting on key}
        Runtime guarantees that reduce keys will be 
        presented to reduce in sorted order. Shuffle really
        consists of two parts: (1) Partition and (2) Sort.

    \item \textbf{Sorting on value} To sort by value, a composite key containing 
    the value to sort must be used. In that case, the key comparator must take
    into account that the key is composed. 
\end{itemize}

\subsection{Iterative}
\begin{tikzpicture}
    \node[rectangle, draw] (IM) {Map};
    \node[rectangle, draw, right= of IM] (IR) {Reduce};

    \node[rectangle, draw, above right= of IR] (CM) {Map};
    \node[rectangle, draw, right= of CM] (MR) {Reduce};

    \node[rectangle, draw, right= of MR] (TM) {Map};
    \node[rectangle, draw, right= of TM] (TR) {Reduce};

    \node[rectangle, draw, below right= of TR] (OM) {Map};
    \node[rectangle, draw, right= of OM] (OR) {Reduce};

    \draw (IM) edge[->] node[below=1cm, text width=2cm] {Init state} (IR);
    \draw (CM) edge[->] node[above=0.5cm, text width=2cm] {Iterative} (MR);
    \draw (TM) edge[->] node[above=0.5cm, text width=2cm] {Test} (TR);
    \draw (OM) edge[->] node[below=1cm, text width=2cm] {Output result} (OR);

    \draw (IR) edge[->, bend left] (CM);
    \draw (MR) edge[->, ] (TM);
    \draw (TR) edge[->, bend left] (OM);
\end{tikzpicture}

Iterative MapReduce can be done if the reduce
output is compatible with map input but this require to passing the
entire state and doing a lot of network and disk I/O.


\subsection{Graphs algorithm}
$G = (V, E)$ where $V$ is vertices, $E$ edges of the form $(v_1, v_2, cost, attr)$
where $v_1, v_2 \in V$.

\begin{itemize}
    \item \textbf{Single Source Shortst Path (SSSP)}: based on dijkstra algorithm idea but parallelized.
        \begin{description}
            \item[Init]: for each node $id$, $<\infty, -, \{<succId, cost>\}>$
            \item[Map]: for each node $id$, $<dst, next, \{<succId, cost>\}>$:
                \begin{itemize}
                    \item emit $id$, $<dst, next, \{<succId, cost>\}>$
                    \item for each successor:
                        \begin{itemize}
                            \item emit $succId, <dst+cost, id>$ 
                        \end{itemize}
                \end{itemize}
            \item[Reduce]: emit $id$, $<minDst, nextWithMinDst, \{<succId, cost>\}>$
        \end{description}

        This algorithm is based on a \textit{wave} which go on at each iteration.

    \item \textbf{k-clustering}: the idea is to assign $k$ random centroid and move them 
        until be stable.
        \begin{description}
            \item[Init]: choose random point
            \item[Map]: Assign each point to the closest centroid
                $$S_i^{(t)} = \{ x_j : x_j - m_i^{(t)} \leqslant x_j - m_i^{(* t )} , i* = 1,..., k \}$$
            \item[Reduce]: Recenter with $m_i$ the new centroid for its points
                $$m_i^{(t+1)} = \frac{1}{|S_i^{(t)}|} \sum_{x_j \in S_i^{(t)}} x_j$$
        \end{description}

    \item \textbf{Classification with naïve Bayes}: where it's \textit{naïve} because probability
        of events are independent.
        $$\textrm{Probability messages "XYZ" is SPAM?} = \frac{p(spam) p(containsXYZ | spam)}
        {p(containsXYZ)}$$ 

        \begin{itemize}
            \item \texttt{p(spam)} : Nbr spam email / Nbr email
            \item \texttt{p(containsXYZ)} : Nbr emails with XYZ / Nbr emails
            \item \texttt{p(containsXYZ|spam)} : Nbr emails with XYZ / Nbr emails with XYZ
        \end{itemize}

        \begin{tabular}{m{2cm}cm{13cm}}
            Nbr spam with XYZ &:
            & 
            \begin{description}
                \item[map]: for each message $m <class, \{words\}>$, emit $<word, class> \rightarrow 1$
                \item[reduce]: emit $<word, class> \rightarrow count$
            \end{description}
        \end{tabular}

        \begin{tabular}{m{2cm}cm{12cm}}
            Nbr email with XYZ&:
            & 
            \begin{description}
                \item[map]: for each message $m <class, \{words\}>$, emit $<word> \rightarrow 1$
                \item[reduce]: emit $<word> \rightarrow count$
            \end{description}
        \end{tabular}

    \item \textbf{PageRank}: The idea is to allow $\frac{1}{N}$ vote par page
        at the initialization, and each page vote for all the page it has a
        link to. To ensure fairness, pages voting for more than one page must
        split their vote equally between them. Voting proceeds in rounds: in
        each round, each page has the number of votes it received in the
        previous round.


        \begin{itemize}
            \item \textsc{Random surfer model}: Imagine a random surfer, who starts on a 
                random page and, in each step
                \begin{enumerate}
                    \item Click on a random link on the page with probability $d$ 
                    \item Jump to a random page with probability $1-d$ 
                \end{enumerate}
                The PageRank of a page can be interpreted 
                as the fraction of steps the surfer spends on 
                the corresponding page


            \item \textsc{Naïve PageRank}
                $$rank_i = \sum_{j \in B_i} \frac{1}{N_j} rank_j \quad \textrm{where }N_i \textrm{ is
                the outgoing link of i and} B_i \textrm{ the ingoing link of i}$$ 

                This can't be able to manage vertex which have no outgoing edge.

                \begin{tabular}{m{7cm}m{7cm}}
                    \textbf{Sinks} & \textbf{Hogs}\\
                    \begin{tikzpicture}
                        \node[rectangle, draw] (G) {Google};
                        \node[rectangle, draw, below= of G] (A) {Amazon};
                        \node[rectangle, draw, right= of A] (Y) {Yahoo};

                        \draw[->] (G) -| (Y);
                        \draw[->] (G.300) -- (A.60);
                        \draw[<-] (G.240) -- (A.120);
                        \draw[->] (A) -- (Y.180);
                        \draw[->] (A) -- (Y.180);
                    \end{tikzpicture}
                    &
                    \begin{tikzpicture}
                        \node[rectangle, draw] (G) {Google};
                        \node[rectangle, draw, below= of G] (A) {Amazon};
                        \node[rectangle, draw, right= of A] (Y) {Yahoo};

                        \draw[->] (G) -| (Y);
                        \draw[->] (G.300) -- (A.60);
                        \draw[<-] (G.240) -- (A.120);
                        \draw[->] (A) -- (Y.180);
                        \draw[->] (A) -- (Y.180);
                        \draw[->, loop right] (Y) edge[loop right] (Y);
                    \end{tikzpicture}\\
                    PageRank is lost after each round and $\forall_i rank_i = 0$ & 
                    PageRank is accumulates on Yahoo and $\forall_i rank_i = 0$ behalf 
                    $rank_{yahoo} = 1$
                \end{tabular}

            \item \textsc{Improved PageRank}
                $$rank_i = 1-d + d \sum_{j \in B_i} \frac{1}{N_j} rank_j \quad \textrm{where }N_i \textrm{ is
                the outgoing link of i and} B_i \textrm{ the ingoing link of i}$$ 
        \end{itemize}

        \begin{description}
            \item[Init]: page $p <1/Nn, \{outgoingLink\}>$
            \item[Map]: page $p$ propagate $\frac{1}{N_p} * d * weigth_p$
            \item[Reduce]: page $p$ = $1-d + \sum_{incomingWeight}$
        \end{description}

\end{itemize}


