\documentclass[en,skiptoc]{../../../eplnotes}

\hypertitle{Secure Electronic Circuits and Systems}{8}{ELEC}{2760}
{Master students 2019}
{Fran√ßois--Xavier Standaert}

This document completes the holes in the slides.

\section*{Lecture 1}

\paragraph{Slide 5: What does perfect secrecy mean?} An encryption scheme $<Enc, Dec>$ with message space $\mathcal{M}$ is \textbf{perfectly secret} if for every probability distribution over $\mathcal{M}$, every message $m \in \mathcal{M}$ and for every ciphertext $c \in \mathcal{C}$, we have 
$$Pr[M = m | C = c ] = Pr[M = m]$$

\paragraph{Slide 8: Break $x, x' \in \{0, 1\}^n$ encrypted with  $k \in \{0, 1\}^n$}
We can deduce $c \oplus c' = x \oplus x'$ with $c = k \oplus x$. Then we can deduce where the two messages differ and break the OTP. 
\paragraph{Slide 9: A recovers k with Pr $\approx$ } $\frac{2^{50}.2^{25}}{2^{128}}$ = $2^{-53}$

\paragraph{Slide 14: What happens if $BC_k(x_1) = BC_k(x_2)$?} 
It means that $x_1 = x_2$ because $BC_k$ is a one-to-one function

\paragraph{Slide 16: Why do we need attacks?}
\begin{itemize}
    \item If we understand the attacks, we understand the security behind.
    \item We can improve security
\end{itemize}

\paragraph{Slide 17: Can a $BC_k$ really be indistinguishable from p (random permutation)?}
\begin{itemize}
    \item Block cipher: number of n-bit keys = $2^n$
    \item Permutations: number of n-bit permutations = $(2^n) !$
\end{itemize}
As $2^n \ll (2^n) !$, we can deduce that a block cipher is distinguishable from a random permutation.
\section*{Lecture 2}

\paragraph{Slide 3}
\begin{enumerate}
    \item $Pr[P = p] = \frac{1}{(2^n)!}$
    \item $Pr[p(x) = y] = \frac{1}{2^n} = Pr[Y = y]$ 
    \item Yes it should be a bijection in order to decrypt a cipher.
    \item $2^n$ bijections. 
    \item Not needed by the definition.
\end{enumerate}

\paragraph{Slide 5: It is tight?}

Yes it is tight. To break it, an adversary has the complexity $O(\sqrt{2^n}) = O(2^{\frac{n}{2}}))$. \newline
But it is not efficient, we need $2n\textrm{ [1PRG]}\cdot n \textrm{ [nPRG]}\cdot 3\textrm{ [rounds]} = 6n^2$ [1PRG]. There are $2n$ 1PRG per nPRG with n-bit expansion, its size is thus $2n$.

\paragraph{Slide 16:}
\begin{itemize}
    \item \textbf{Probability of success of one table}: $PS_{tab} = \frac{mt}{2^n}$
    \item \textbf{increasing m and t is useful up to roughly:} $m \cdot t^2 = 2^n$. Above this value, the probability that the additional keys in the table are new is negligible.
\end{itemize}

\paragraph{Slide 17: }
\begin{itemize}
    \item \textbf{Online attack time complexity}: T = $O(rt)$ = $O(2^{\frac{2n}{3}})$
    \item \textbf{Memory complexity}: M = $O(mr)$ = $O(2^{\frac{2n}{3}})$
\end{itemize}
\paragraph{Slide 18: }
\begin{itemize}
    \item Exhaustive  key search = $2^{112}$
    \item Meet-in-the-middle attack = $2.2^{56}$
\end{itemize}

\paragraph{Slide 20: }
\begin{itemize}
    \item For OFB, we can mount a known plaintext attack because the first bit will always be XOR with the fixed IV. Then we can do the following attack: 
    $$ c_0 \oplus c_0' = m_0 \oplus m_0' $$
    Moreover, we can do the same method for all the other rounds because $R_1,R_2,\dots$ are identical at each encryption:
    $$ c_1 \oplus c_1' = m_1 \oplus m_1',\qquad c_2 \oplus c_2' = m_2 \oplus m_2', \dots $$
    \item For CFB, we apply the same attack as OFB for the first round but the other rounds have different $R_1,R_2,\dots$ at each encryption. 
    \item The CBC is better, but it still gives information if there are 2 identical ciphertexts.
\end{itemize}

\paragraph{Slide 21: }
\begin{itemize}
    \item If a collision occurs, then it means that the attacker receives the same ciphertexts $i$ and $j$:
    $$ c_i = c_j \qquad \Longrightarrow \qquad E(m_{i} \oplus c_{i-1}) = E(m_{j} \oplus c_{j-1}) $$
    We can thus extract
    $$ m_{i} \oplus c_{i-1} = m_{j} \oplus c_{j-1} $$
    \item We can evaluate the probability of no collision as (using the birthday paradox)
    $$ Pr[\textrm{no collision}] = \Pi^q_{i=1} (1 - \frac{i}{2^n}) \simeq \Pi^q_{i=1} e^{-\frac{i}{2^n}} \simeq e^{-\frac{q^2}{2^n}} $$
    Then the probability of a collision is
    $$ Pr[\textrm{collision}] = 1 - e^{\frac{-q^2}{2^n}} $$
    To avoid a collision, we cannot use more than $q=O(2^{n/2})$ plaintexts.
\end{itemize}

\paragraph{Slide 23: }
\begin{itemize}
    \item Yes, there exist keys where DES is an involution ($E_K(E_K(x)) = x$). They appear when the 16 subkeys generated by the key scheduling algorithm are identical. In this case, the DES rounds are identical and also correspond to the inverse round, the decryption is thus equivalent to the encryption. Based on the DES key scheduling, there are 4 weak keys, whose: 
    \begin{enumerate}
        \item $0^n$
        \item $1^n$
    \end{enumerate}
    \item $$DES_{\overline{k}}(\overline{x}) \rightarrow R_1L_1 =
    (\overline{R_0}, \overline{L_0} \oplus f_{\overline{k}}(\overline{R_0})) =^1
    (\overline{R_0}, \overline{L_0 \oplus f_k(R_0)}) =
    \overline{(R_0, L_0 \oplus f_k(R_0))}$$
    Which means $DES_{\overline{k}}(\overline{x}) = \overline{DES_k(x)}$.
    
    \textbf{WARNING$^1$: } We have done the following, according to boolean algebra and the definition of $f_k(X) = g(k \oplus X)$, 
    $$ \overline{L_0} \oplus f_{\overline{k}}(\overline{R_0}) =
    \overline{L_0} \oplus g(\overline{k} \oplus \overline{R_0}) =
    \overline{L_0} \oplus g(k \oplus R_0) =
    \overline{L_0} \oplus f_{k}(R_0) = 
    \overline{L_0 \oplus f_{k}(R_0) } 
    $$
    This feature of the DES reduces by 2 the number of keys that the attacker needs to test under CPA, because he can obtain the encryption of $\bar{x}$ with $\bar{k}$ by simply inverting the ciphertext resulting from the encryption of $x$ with $k$. 
\end{itemize}
\paragraph{Slide 24: }
\begin{itemize}
    \item \textbf{One DES round}: We can build an efficient attack to find the 32-bit key. First we obtain $f_k(R_0) = R_1 \oplus L_0$. Then, as the function is composed of 8 SBOX taking 4-bit keys, we can do exhaustive key search on this small key size, leading to a computation time of $8\cdot 2^4$ instead of $2^{32}$. 
    \item \textbf{Slide attack}: We generate some pairs $(x_0,y_0)$ and $(x_1,y_1)$, for each of them we check if it is a slid pair: we retrieve $k$ resulting from $f_k(x_0)=x_1$ and check if it also verifies $f_k(y_0)=y_1$. If it is the case, we have done a slide attack and retrieved the right key. This method is particularly efficient since it only requires to compute at most $2^{n/2}$ pairs (stated by the birthday paradox), and retrieving the key from the pair (via $f_k(x_0)=x_1$) is ultra fast ($8\cdot 2^4$ with the same assumptions as the last point). Finally, it is worth noting that the number of pairs is even reduced from $2^{n/2}$ to $2^{n/4}$ if the function $f$ is the Feistel function since $P=(R_0, L_0 \oplus f_{k}(R_0))$, only the right half depends on the key!
\end{itemize}
\section*{Lecture 3}

\paragraph{Slide 3} 

\begin{itemize}
    \item \textbf{Linear function:} $L(a+b) = L(a) + L(b)$, like the XOR function.
    \item There are $2^{2^n}$ $n$-bit Boolean functions.
    \item There are $2^n$ $n$-bit linear Boolean functions.
    \item A linear permutation cannot be a good block cipher (structural issue), because a good block cipher needs to be non linear in order to avoid the attacker to make some links between the variables (linear cryptanalysis).
    \item \textbf{Linear cryptanalysis:} constructing a linear relation (approximation) between $x,y$ and $k$ with a high bias (probability highly different from 1/2). Then it consists to use these relations with known $x$ and $y$ to derive $k$.
\end{itemize}

\paragraph{Slide 4}

\begin{align*}
  \Pr[V_1 \oplus V_2 = 0]
  & = p_1p_2 + (1-p_1)(1-p_2)\\
  & = 1 + 2p_1p_2 - p_1 - p_2\\
  & = \frac{1}{2} + 2(1/4 + p_1p_2 - p_1/2 - p_2/2)\\
  & = \frac{1}{2} + 2(p_1 - 1/2)(p_2 - 1/2)\\
  & = \frac{1}{2} + 2\varepsilon_1 \varepsilon_2.
\end{align*}
where
\( \varepsilon_i = p_i - 1/2 \)
is called the \emph{bias}.
We can generalise it by induction.

\paragraph{Slide 5}

\textbf{Relation to linear cryptanalysis?} Each $V_i$ can be seen as a linear approx of the form
$$ (\oplus x_i) \oplus (\oplus y_i) \oplus (\oplus k_i) = 0$$
The goal is to find a relation between the variables in the s-boxes, for example $V_1 = (x_1 \oplus k_1) \oplus (x_4 \oplus k_4) \oplus y_2$.

\paragraph{Slide 7}

Number of samples required: $N \propto 1 / \epsilon^2$.

\paragraph{Slide 10}

4 bits to guess per approx (the number of inputs of one s-box).

\paragraph{Slide 11}

How to prevent cryptanalysis:
\begin{itemize}
    \item By increasing the data complexity:
    \begin{itemize}
        \item Increase the number of rounds
        \item Increase the number of \textit{active} s-boxes \textbf{in the approximation}
        \item Reduce the bias of the s-boxes (in the approximation), with fewer linear relation
    \end{itemize}
    \item By increasing the time complexity:
    \begin{itemize}
        \item Increase the number of \textit{active} s-boxes \textbf{in the first round}
    \end{itemize}
    \item Which solution is most effective? Data complexity is much more practical and meaningful.
\end{itemize}

\paragraph{Slide 13}

\textbf{Is the AES a Feistel cipher?} No, it is a key alternating cipher, a substitution permutation network.

\paragraph{Slide 19}

Limitations/assumptions?
\begin{itemize}
    \item Independent keys
    \item Key equivalence: $LB(a,b,K) \simeq ELB(a,b)$
    \item $\lim_{R\to\infty}LCB(\hat{\Omega}_{best})=0$
    \item $\lim_{R\to\infty}LB(a,b) \neq 0$
\end{itemize}

\paragraph{Slide 20}

$AES_k(AES_k(x))$ is not stronger than $AES_k(x)$ against linear cryptanalysis. The bias remains the same between the input and the output.

An explanation can be found in the section 2.3 of the document "Experimenting Linear Cryptanalysis". 

\paragraph{Slide 22}

$$EDP(a,b) = \frac{1}{(2^n)!}\sum_p 1_{p(x\oplus a)=p(x)\oplus b} = \frac{2^n (2^n-2)!}{(2^n)!} = \frac{1}{2^n-1} $$

\paragraph{Slide 24}

$$ (x^6 + x^4 + x^2 + x + 1) \oplus (x^7 + x + 1) = x^7 + x^6 + x^4 + x^2 $$

\paragraph{Slide 25}

$$ a(x) \cdot b(x) \mod m(x) = x^7 + x^5 + x^4 + x^3 + 1 $$

\section*{Lecture 4}

\paragraph{Slide 21} min memory S1 = $2^8 \times 8=2048$, min memory S2 = $(2^4\times 4) \times 6=384$
$$S1 = 88\times LB1 = 8\times LB2$$
$$S2 = 12\times LB1 = 6\times LB2$$



\section*{Lecture 5}

\paragraph{Slide 13} 
\begin{itemize}
    \item $E_{cycle} =\frac{P}{f} = 6nJ = \frac{6\times 10^{-3}}{10^6}J$
    \item $E_{cycle} = 24nJ$
\end{itemize}

\paragraph{Slide 19}

Remark: it is $T_0(a_0)\oplus T_1(a_1)\oplus T_2(a_2)\oplus T_3(a_3)$.


\section*{Lecture 6}

\paragraph{Slide 18}
\begin{itemize}
    \item Improve measurement setup or combine different channels
    \item Adaptive selection of the traces 
    \item Improved leakage model with profiling, characterization;
    \item Exploit multiple samples, multivariate statistics (e.g. choose y and z): higher order attack, template attack
    \item Different statistical tests: difference of mean, correlation analyser, Bayesian classification
    \item Try to remove the noise, filtering
    \item Improve the model (Hamming weight) with profiling, supervised machine learning
\end{itemize}

\paragraph{Slide 26}
\begin{itemize}
    \item 32-bit $\rightarrow$ $N = 40$
    \item 128-bit $\rightarrow$ $N = 160$
\end{itemize}
This is not completely correct because the value of c will vary according to 2 things: 
\begin{itemize}
    \item decrease when the granularity increases
    \item level of confidence on the traces (this is what I heard)
\end{itemize}


\section*{Lecture 7}

\paragraph{Slide 4} 
\begin{itemize}
    \item unprotected implementation: $\epsilon = 0$
    \item d-share encoding: $\epsilon = d-1$
    \item $M = 2^{n\times d}\times n$ because the output of $\mathrm{corr}(y_1,y_2,\dots,y_d)$ is of size $n$ and there are $2^{nd}$ possible inputs.
\end{itemize}
\paragraph{Slide 5}  $L(y) = L(y_1) \oplus L(y_2) \oplus ... \oplus L(y_d)$.
Performance overheads: $O(d)$
\paragraph{Slide 6} 
\begin{itemize}
    \item It is correct 
    \item It is not 2-probing secure since if we manage to learn $c_1 = a_1b$ and if $c_1=1$ then we know that $a_1=1$ and $b=1$.
\end{itemize}

\paragraph{Slide 7} The d factor appears because every share is going to be used d times. An attacker could thus reduce the noise by a factor d by averaging the noise. 

\paragraph{Slide 7} $O(d^2)$
Randomise before compression:

$$\begin{pmatrix}
0 & r_1 & r_2\\
-r1 & 0 & r_3\\
-r2 & -r3 & 0
\end{pmatrix}$$

\paragraph{Slide 9} 
$$N = \frac{c}{MI(Y_i:L_{Y_i})^d}$$
It is a good countermeasure because we pay a quadratic factor and we obtain a an exponential order in d.\\
How to ensure sufficiently noise shares?
\begin{itemize}
    \item By adding algorithmic noises
    \item By adding physical noise
    \item By decreasing the signal (SNR)
\end{itemize}

\paragraph{Slide 10} $\epsilon =0$ 

\end{document}
