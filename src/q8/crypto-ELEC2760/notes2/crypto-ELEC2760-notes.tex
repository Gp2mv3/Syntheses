\documentclass[en,skiptoc]{../../../eplnotes}

\hypertitle{Secure Electronic Circuits and Systems}{8}{ELEC}{2760}
{Master students 2019}
{Fran√ßois-Xavier Standaert}

\newcommand{\xor}{\oplus} % XOR operation

This document completes the holes in the slides.

\section*{Lecture 1}

\paragraph{Slide 5: What does perfect secrecy mean?} An encryption scheme $<Enc, Dec>$ with message space $\mathcal{M}$ is \textbf{perfectly secret} if for every probability distribution over $\mathcal{M}$, every message $m \in \mathcal{M}$ and for every ciphertext $c \in \mathcal{C}$, we have 
$$Pr[M = m | C = c ] = Pr[M = m]$$

\paragraph{Slide 8: Break $x, x' \in \{0, 1\}^n$ encrypted with  $k \in \{0, 1\}^n$}
We can deduce $c \oplus c' = x \oplus x'$ with $c = k \oplus x$. Then we can deduce where the two messages differ and break the OTP. 
\paragraph{Slide 9: A recovers k with Pr $\approx$ } $\frac{2^{50}.2^{25}}{2^{128}}$ = $2^{-53}$

\paragraph{Slide 14: What happens if $BC_k(x_1) = BC_k(x_2)$?} 
It means that $x_1 = x_2$ because $BC_k$ is a one-to-one function

\paragraph{Slide 16: Why do we need attacks?}
\begin{itemize}
    \item If we understand the attacks, we understand the security behind.
    \item We can improve security
\end{itemize}

\paragraph{Slide 17: Can a $BC_k$ really be indistinguishable from p (random permutation)?}
\begin{itemize}
    \item Block cipher: number of n-bit keys = $2^n$
    \item Permutations: number of n-bit permutations = $(2^n) !$
\end{itemize}
As $2^n \ll (2^n) !$, we can deduce that a block cipher is distinguishable from a random permutation.
\section*{Lecture 2}

\paragraph{Slide 3}
\begin{enumerate}
    \item $Pr[P = p] = \frac{1}{(2^n)!}$
    \item $Pr[p(x) = y] = \frac{1}{2^n} = Pr[Y = y]$ 
    \item Yes it should be a bijection in order to decrypt a cipher.
    \item $2^n$ bijections. 
    \item Not needed by the definition.
\end{enumerate}

\paragraph{Slide 5: It is tight?}

Yes it is tight. To break it, an adversary has the complexity $O(\sqrt{2^n}) = O(2^{\frac{n}{2}}))$. \newline
But it is not efficient, we need $2n\textrm{ [1PRG]}\cdot n \textrm{ [nPRG]}\cdot 3\textrm{ [rounds]} = 6n^2$ [1PRG]. There are $2n$ 1PRG per nPRG with n-bit expansion, its size is thus $2n$.

\paragraph{Slide 16:}
\begin{itemize}
    \item \textbf{Probability of success of one table}: $PS_{tab} = \frac{mt}{2^n}$
    \item \textbf{increasing m and t is useful up to roughly:} $m \cdot t^2 = 2^n$. Above this value, the probability that the additional keys in the table are new is negligible.
\end{itemize}

\paragraph{Slide 17: }
\begin{itemize}
    \item \textbf{Online attack time complexity}: T = $O(rt)$ = $O(2^{\frac{2n}{3}})$
    \item \textbf{Memory complexity}: M = $O(mr)$ = $O(2^{\frac{2n}{3}})$
\end{itemize}
\paragraph{Slide 18: }
\begin{itemize}
    \item Exhaustive  key search = $2^{112}$
    \item Meet-in-the-middle attack = $2.2^{56}$
\end{itemize}

\paragraph{Slide 20: }
\begin{itemize}
    \item For OFB, we can mount a known plaintext attack because the first bit will always be XOR with the fixed IV. Then we can do the following attack: 
    $$ c_0 \oplus c_0' = m_0 \oplus m_0' $$
    Moreover, we can do the same method for all the other rounds because $R_1,R_2,\dots$ are identical at each encryption:
    $$ c_1 \oplus c_1' = m_1 \oplus m_1',\qquad c_2 \oplus c_2' = m_2 \oplus m_2', \dots $$
    \item For CFB, we apply the same attack as OFB for the first round but the other rounds have different $R_1,R_2,\dots$ at each encryption. 
    \item The CBC is better, but it still gives information if there are 2 identical ciphertexts.
\end{itemize}

\paragraph{Slide 21: }
\begin{itemize}
    \item If a collision occurs, then it means that the attacker receives the same ciphertexts $i$ and $j$:
    $$ c_i = c_j \qquad \Longrightarrow \qquad E(m_{i} \oplus c_{i-1}) = E(m_{j} \oplus c_{j-1}) $$
    We can thus extract
    $$ m_{i} \oplus c_{i-1} = m_{j} \oplus c_{j-1} $$
    \item We can evaluate the probability of no collision as (using the birthday paradox)
    $$ Pr[\textrm{no collision}] = \Pi^q_{i=1} (1 - \frac{i}{2^n}) \simeq \Pi^q_{i=1} e^{-\frac{i}{2^n}} \simeq e^{-\frac{q^2}{2^n}} $$
    Then the probability of a collision is
    $$ Pr[\textrm{collision}] = 1 - e^{\frac{-q^2}{2^n}} $$
    To avoid a collision, we cannot use more than $q=O(2^{n/2})$ plaintexts.
\end{itemize}

\paragraph{Slide 23: }
\begin{itemize}
    \item Yes, there exist keys where DES is an involution ($E_K(E_K(x)) = x$). They appear when the 16 subkeys generated by the key scheduling algorithm are identical. In this case, the DES rounds are identical and also correspond to the inverse round, the decryption is thus equivalent to the encryption. Based on the DES key scheduling, there are 4 weak keys, whose: 
    \begin{enumerate}
        \item $0^n$
        \item $1^n$
    \end{enumerate}
    \item $$DES_{\overline{k}}(\overline{x}) \rightarrow R_1L_1 =
    (\overline{R_0}, \overline{L_0} \oplus f_{\overline{k}}(\overline{R_0})) =^1
    (\overline{R_0}, \overline{L_0 \oplus f_k(R_0)}) =
    \overline{(R_0, L_0 \oplus f_k(R_0))}$$
    Which means $DES_{\overline{k}}(\overline{x}) = \overline{DES_k(x)}$.
    
    \textbf{WARNING$^1$: } We have done the following, according to boolean algebra and the definition of $f_k(X) = g(k \oplus X)$, 
    $$ \overline{L_0} \oplus f_{\overline{k}}(\overline{R_0}) =
    \overline{L_0} \oplus g(\overline{k} \oplus \overline{R_0}) =
    \overline{L_0} \oplus g(k \oplus R_0) =
    \overline{L_0} \oplus f_{k}(R_0) = 
    \overline{L_0 \oplus f_{k}(R_0) } 
    $$
    This feature of the DES reduces by 2 the number of keys that the attacker needs to test under CPA, because he can obtain the encryption of $\bar{x}$ with $\bar{k}$ by simply inverting the ciphertext resulting from the encryption of $x$ with $k$. 
\end{itemize}
\paragraph{Slide 24: }
\begin{itemize}
    \item \textbf{One DES round}: We can build an efficient attack to find the 32-bit key. First we obtain $f_k(R_0) = R_1 \oplus L_0$. Then, as the function is composed of 8 SBOX taking 4-bit keys, we can do exhaustive key search on this small key size, leading to a computation time of $8\cdot 2^4$ instead of $2^{32}$. 
    \item \textbf{Slide attack}: We generate some pairs $(x_0,y_0)$ and $(x_1,y_1)$, for each of them we check if it is a slid pair: we retrieve $k$ resulting from $f_k(x_0)=x_1$ and check if it also verifies $f_k(y_0)=y_1$. If it is the case, we have done a slide attack and retrieved the right key. This method is particularly efficient since it only requires to compute at most $2^{n/2}$ pairs (stated by the birthday paradox), and retrieving the key from the pair (via $f_k(x_0)=x_1$) is ultra fast ($8\cdot 2^4$ with the same assumptions as the last point). Finally, it is worth noting that the number of pairs is even reduced from $2^{n/2}$ to $2^{n/4}$ if the function $f$ is the Feistel function since $P=(R_0, L_0 \oplus f_{k}(R_0))$, only the right half depends on the key!
\end{itemize}
\section*{Lecture 3: Block ciphers II: linear and differential cryptanalysis}

\paragraph{Slide 3} 

\begin{itemize}
    \item \textbf{Linear function:} $L(a+b) = L(a) + L(b)$, like the XOR function.
    \item There are $2^{2^n}$ $n$-bit Boolean functions.
    \item There are $2^n$ $n$-bit linear Boolean functions.
    \item A linear permutation cannot be a good block cipher (structural issue), because a good block cipher needs to be non linear in order to avoid the attacker to make some links between the variables (linear cryptanalysis).
    \item \textbf{Linear cryptanalysis:} constructing a linear relation (approximation) between $x,y$ and $k$ with a high bias (probability highly different from 1/2). Then it consists to use these relations with known $x$ and $y$ to derive $k$.
\end{itemize}

\paragraph{Slide 4}

\begin{align*}
  \Pr[V_1 \oplus V_2 = 0]
  & = p_1p_2 + (1-p_1)(1-p_2)\\
  & = 1 + 2p_1p_2 - p_1 - p_2\\
  & = \frac{1}{2} + 2(1/4 + p_1p_2 - p_1/2 - p_2/2)\\
  & = \frac{1}{2} + 2(p_1 - 1/2)(p_2 - 1/2)\\
  & = \frac{1}{2} + 2\varepsilon_1 \varepsilon_2.
\end{align*}
where
\( \varepsilon_i = p_i - 1/2 \)
is called the \emph{bias}.
We can generalise it by induction.

\paragraph{Slide 5}

\textbf{Relation to linear cryptanalysis?} Each $V_i$ can be seen as a linear approx of the form
$$ (\oplus x_i) \oplus (\oplus y_i) \oplus (\oplus k_i) = 0$$
The goal is to find a relation between the variables in the s-boxes, for example $V_1 = (x_1 \oplus k_1) \oplus (x_4 \oplus k_4) \oplus y_2$.

\paragraph{Slide 7}

Number of samples required: $N \propto 1 / \epsilon^2$.

\paragraph{Slide 10}

4 bits to guess per approx (the number of inputs of one s-box).

\paragraph{Slide 11}

How to prevent cryptanalysis:
\begin{itemize}
    \item By increasing the data complexity:
    \begin{itemize}
        \item Increase the number of rounds
        \item Increase the number of \textit{active} s-boxes \textbf{in the approximation}
        \item Reduce the bias of the s-boxes (in the approximation), with fewer linear relation
    \end{itemize}
    \item By increasing the time complexity:
    \begin{itemize}
        \item Increase the number of \textit{active} s-boxes \textbf{in the first round}
    \end{itemize}
    \item Which solution is most effective? Data complexity is much more practical and meaningful.
\end{itemize}

\paragraph{Slide 13}

\textbf{Is the AES a Feistel cipher?} No, it is a key alternating cipher, a substitution permutation network.

\paragraph{Slide 19}

Limitations/assumptions?
\begin{itemize}
    \item Independent keys
    \item Key equivalence: $LB(a,b,K) \simeq ELB(a,b)$
    \item $\lim_{R\to\infty}LCB(\hat{\Omega}_{best})=0$
    \item $\lim_{R\to\infty}LB(a,b) \neq 0$
\end{itemize}

\paragraph{Slide 20}

$AES_k(AES_k(x))$ is not stronger than $AES_k(x)$ against linear cryptanalysis. The bias remains the same between the input and the output.

An explanation can be found in the section 2.3 of the document "Experimenting Linear Cryptanalysis". 

\paragraph{Slide 22}

$$EDP(a,b) = \frac{1}{(2^n)!}\sum_p 1_{p(x\oplus a)=p(x)\oplus b} = \frac{2^n (2^n-2)!}{(2^n)!} = \frac{1}{2^n-1} $$

\paragraph{Slide 24}

$$ (x^6 + x^4 + x^2 + x + 1) \oplus (x^7 + x + 1) = x^7 + x^6 + x^4 + x^2 $$

\paragraph{Slide 25}

$$ a(x) \cdot b(x) \mod m(x) = x^7 + x^5 + x^4 + x^3 + 1 $$

\section*{Lecture 4: Hardware implementations}

\paragraph{Slide 21} min memory S1 = $2^8 \times 8=2048$, min memory S2 = $(2^4\times 4) \times 6=384$
$$S1 = 88\times LB1 = 8\times LB2$$
$$S2 = 12\times LB1 = 6\times LB2$$



\section*{Lecture 5: Software implementations}

\paragraph{Slide 13} 
\begin{itemize}
    \item $E_{cycle} =\frac{P}{f} = 6nJ = \frac{6\times 10^{-3}}{10^6}J$
    \item $E_{cycle} = 24nJ$
\end{itemize}

\paragraph{Slide 19}

Remark: it is $T_0(a_0)\oplus T_1(a_1)\oplus T_2(a_2)\oplus T_3(a_3)$.

\paragraph{Slide 15}
Does it make sense to move the S-box in RAM?

Moving the S-box from ROM to RAM requires moving all 256 bytes one by one (3 cycles to read from ROM, 2 cycles to write to RAM), for a total of 1280 cycles.

Then, AES requires accessing 16 times the S-box per round, for 10 rounds, or a total of 160 accesses.
If we use ROM, it will take $3\cdot 160$ cycles per encryption operation.
If we use RAM, it will take $2\cdot 160$ cycles.
Thus, it is beneficial to use the RAM instead of the ROM if the number $N$ of encryptions done is such that
\[ 1280 + 2 \cdot 160 \cdot N \le 3 \cdot 160 \cdot N \]
or $N \ge 8$. For a microcontroller on an authentication chip, which usually performs only a few encryptions/decryptions, it is not worth it, and we can keep the S-box in ROM.

\paragraph{Slide 16}
With bitslicing, we need 17 cycles per bit, thus $17\cdot 8$ cycles. But, the bus is $n$ bits wide, so we can reduce it to:
\[\frac{17\cdot 8}{n}\]
With LUTs (i.e., access a table in memory), we need 5 cycles per 8 bits, independently of the bus width. Bit slicing is better if
\[ \frac{17 \cdot 8}{n} \le 5 \]
which happens if $n \ge 27.2$, or for a bus width of 32 bits.

Note: an advantage of bitslicing over table lookup happens when considering that the table is stored inside memory, and so may be subject to caches and varying timing of access, which can leak information!

\paragraph{Slide 17}
Cost of precomputing xtime: essentially, uses memory (ROM) space of size $256\cdot 8=2048$ bits.
Also, reading from ROM/RAM requires only 3/2 cycles.
Doing this computation in software doesn't require using a LUT in memory, but may require more cycles and even branches.

\section*{Lecture 6: Side-channel attack I}

\paragraph{Slide 18}
\begin{itemize}
    \item Improve measurement setup or combine different channels
    \item Adaptive selection of the traces 
    \item Improved leakage model with profiling, characterization;
    \item Exploit multiple samples, multivariate statistics (e.g. choose y and z): higher order attack, template attack
    \item Different statistical tests: difference of mean, correlation analyser, Bayesian classification
    \item Try to remove the noise, filtering
    \item Improve the model (Hamming weight) with profiling, supervised machine learning
\end{itemize}

\paragraph{Slide 26}
\begin{itemize}
    \item 32-bit $\rightarrow$ $N = 40$
    \item 128-bit $\rightarrow$ $N = 160$
\end{itemize}
This is not completely correct because the value of c will vary according to 2 things: 
\begin{itemize}
    \item decrease when the granularity increases
    \item level of confidence on the traces (this is what I heard)
\end{itemize}


\section*{Lecture 7: Side-channel attack II: counter-measures}

\paragraph{Slide 4} 
\begin{itemize}
    \item unprotected implementation: $\epsilon = 0$
    \item d-share encoding: $\epsilon = d-1$
    \item $M = 2^{n\times d}\times n$ because the output of $\mathrm{corr}(y_1,y_2,\dots,y_d)$ is of size $n$ and there are $2^{nd}$ possible inputs.
\end{itemize}
\paragraph{Slide 5}  $L(y) = L(y_1) \oplus L(y_2) \oplus ... \oplus L(y_d)$.
Performance overheads: $O(d)$
\paragraph{Slide 6} 
\begin{itemize}
    \item It is correct 
    \item It is not 2-probing secure since if we manage to learn $c_1 = a_1b$ and if $c_1=1$ then we know that $a_1=1$ and $b=1$.
\end{itemize}

\paragraph{Slide 7} The d factor appears because every share is going to be used d times. An attacker could thus reduce the noise by a factor d by averaging the noise. 

\paragraph{Slide 7} $O(d^2)$
Randomise before compression:

$$\begin{pmatrix}
0 & r_1 & r_2\\
-r1 & 0 & r_3\\
-r2 & -r3 & 0
\end{pmatrix}$$

\paragraph{Slide 9} 
$$N = \frac{c}{MI(Y_i:L_{Y_i})^d}$$
It is a good countermeasure because we pay a quadratic factor and we obtain a an exponential order in d.\\
How to ensure sufficiently noise shares?
\begin{itemize}
    \item By adding algorithmic noises
    \item By adding physical noise
    \item By decreasing the signal (SNR)
\end{itemize}

\paragraph{Slide 10} $\epsilon =0$



\section{Lecture 8: fault attacks}
% Added by J-M V

\paragraph{Slide 3: How to introduce a fault?}
\begin{itemize}
    \item Reduce the supply voltage
    \item Increase clock frequency
    \item Increase the temperature
    \item Insert glitches: in the I/O, in the power supply. The advantage of glitches is that they are well defined in time to insert precise faults
\end{itemize}

\paragraph{Slide 4: Drawbacks?}
\begin{itemize}
    \item Requires precise faults
    \item Requires as much faults as the number of bits in the key
\end{itemize}

\paragraph{Slide 5: Where to inject? At the end}
It's useless

\paragraph{Slide 6: Where to inject? Between ShiftRow\#10 and AddRoundKey\#10}
With fault model 3 (single bit set to zero), there is an attack by using a XOR to recover the bit

With fault model 2 (single bit toggled) or 1 (single byte random), there is none: we only see a random bit independently of the value of the key.

\paragraph{Slide 7: Where to inject? Between SubBytes\#10 and ShiftRow\#10}
Nothing changes with the previous proposition.

\paragraph{Slide 8: between ARK\#9 and SB\#10}
There is an attack with model 2: one bit changed at the input of the S-box will manifest in multiple bits changed at the output.

With $z=y\xor k = S(v) \xor k$ ($z$ output of ARK, $y$ output of S-box).
We make a guess for the key $k^*$, then we go back from the two outputs:
\begin{align*}
    v  &= S^{-1}(z  \xor k^*) \\
    v' &= S^{-1}(z' \xor k^*)
\end{align*}
Then, if $k^*$ is an incorrect key, we will see that $HD(v, v')=HW(v\xor v') > 1$.
But for the correct key $k^*$, we will see that $HD(v, v')=1$ (only one bit changed).
There are $8$ possible bits that have flipped, so there are 8 such keys out of $256$ that are possible.
We went from $8$ bits of entropy to just $3$.
With a second fault, we can reduce further and finally find one byte of the key.
With $16\cdot 2=32$ faults, we can recover the whole $128$-bit key.

There is no attack with model 1, as we just see a byte that is as random and as unrelated to anything else as the pseudo-random correct byte.

\paragraph{Slide 9: between MC\#9 and ARK\#9}
No difference with the previous.

\paragraph{Slide 10: between SR\#9 and MC\#9}
There is an attack for model 1 (random byte fault).

MixColumn is linear, so $MC(a\xor \Delta, b, c, d)=MC(a, b, c, d) \xor MC(\Delta, 0, 0, 0)$.
So, we can do the same thing as before: guess a part of the key for the column,
then go backward in the cipher for the two outputs to arrive at the beginning of MC,
then compare the two inputs: for the correct key there will be only one byte of difference.

This reduces the key space from $2^{32}$ to $4\cdot (2^8-1)=1020$ keys, or $22$ bits of entropy reduced.
A second fault will allow us to recover the keys for the full column, or $32$ bits.
With $4\cdot 2=8$ faults, we can recover the whole $128$-bit key.

\paragraph{Slide 11: between MC\#8 and SR\#9}
Same as previous, but tracking the path of the S-box is hard.

\paragraph{Slide 12: between SR\#8 and MC\#8}
There is a better attack then, again for model 1.

This time, a fault inserted before MixColumn\#8 will contaminate the whole column, which will then be shifted by ShiftRow into different columns, which will then contaminate all the S-box by MixColumn\#9.
So, with a single fault, we will change all the bytes at the output; in effect, we have like 4 times in parallel the previous fault.

This reduces the key space from $2^{128}$ to $2^8-1=255$. A second fault will recover the key.
However, we somehow need to explorate all the keys.

Farther up the cipher, we have the problem that there will be too much noise.
Also, if the fault is before MixColumn\#7, we will not be able to distinguish it from a fault inserted after it, so the attack falls appart.

\end{document}
