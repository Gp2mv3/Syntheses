\clearpage{}
\section{Discuss issues with testing safety-critical systems. Describe the
principles of safety cases and FMEA analysis. Define and discuss the merits
of software diversity and formal verification.}


\subsection{Issues with testing safety-critical systems}
A safety-critical system is a system in which a failure can harm or kill people (e.g.\ airplane, nuclear plant, medical device, etc.). \newline

Safety-critical systems demand very high reliability:
${10}^{-9}$ failures per hour = once per 100 000 years \newline
$\Rightarrow$ It cannot be tested directly!

\subsection{Principles of safety cases and FMEA analysis}

\subsubsection{Safety case}
We can decompose the safety goals and assign failure rates or constraints to each
component of the design, so that satisfying each lower-level goal will “roll up” to allow us to meet safety goals for the entire system. In this way, we make a safety case for the system, making explicit the ways in which our software meets performance goals for safety-critical systems. \newline

\textbf{In the slide:} A structured argument, supported by evidence, intended to justify that a system is 
acceptably safe. \newline

\subsubsection{Failure Modes and Effects Analysis (FMEA)}

A failure mode, is a situation which contains risks.
FMEA, analyse the failures mode (e.g.\ by using a fault tree), to look after some
unknown system effect. A system effect is a hazardous situation which cans lead to a crash. By default (because we don’t know) we considers this situation as a crash. \newline

FMEA is highly labour-intensive and based on the experience of the analysts. It usually involves our performing an initial analysis of the software design, abstracting modes that might lead to failures. Then we look at how combinations of the basic failure modes might lead to actual failures. \newline

Summary: Identify failure modes, analyse system effects.

\subsection{Merits of software diversity and formal verification}

\subsubsection{Design diversity}
The same system is built according to the same requirements specification but in several independent ways, each according to a different design. Each system runs in parallel with the others, and a voting scheme coordinates actions when one system’s results differ from the others’. \newline

The underlying assumption is that it is unlikely that at least three of the five groups of developers will write incorrect software for a given requirement. \newline

However, there is empirical evidence suggesting that independently developed software versions will not fail independently; diverse designs do not always offer reliability higher than of a single version.

\subsubsection{Formal verification}

Idea: usage of formal verification techniques with our requirements, designs, and code. \newline
But formal evaluation of natural language is impossible, and important information may be lost if we translate natural language to mathematical symbols. Even formal proofs of specification and design are not infallible, because mistakes are sometimes made in the proofs.
